

<!DOCTYPE html>
<html lang="vi" data-default-color-scheme=auto>



<head>
  <meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="/apple-touch-icon.png">
  <link rel="icon" href="/favicon.ico">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5.0, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="author" content="Vũ Đức Duy">
  <meta name="keywords" content="ký sự AI, lập trình, programming, công nghệ phần mềm, software engineering, AI, trí tuệ nhân tạo, data science, khoa học dữ liệu">
  
    <meta name="description" content="Trong bài viết này, mình sẽ giới thiệu và hướng dẫn bạn cách triển khai Triton trên GKE để chạy các mô hình Deep Learning có sử dụng GPU.">
<meta property="og:type" content="article">
<meta property="og:title" content="Triển khai Triton Inference Server trên Google Kubernetes Engine">
<meta property="og:url" content="https://www.kysuai.com/2023/01/26/Trien-khai-Triton-Inference-Server-tren-Google-Kubernetes-Engine/index.html">
<meta property="og:site_name" content="Ký sự AI">
<meta property="og:description" content="Trong bài viết này, mình sẽ giới thiệu và hướng dẫn bạn cách triển khai Triton trên GKE để chạy các mô hình Deep Learning có sử dụng GPU.">
<meta property="og:locale" content="vi_VN">
<meta property="og:image" content="https://www.kysuai.com/images/scott-webb-3LsocYqXWpM-unsplash-small.jpg">
<meta property="article:published_time" content="2023-01-26T20:42:00.000Z">
<meta property="article:modified_time" content="2023-01-27T08:03:48.127Z">
<meta property="article:author" content="Vũ Đức Duy">
<meta property="article:tag" content="Machine Learning">
<meta property="article:tag" content="Deep Learning">
<meta property="article:tag" content="K8S">
<meta property="article:tag" content="Artificial Intelligence">
<meta property="article:tag" content="Triton Inference Server">
<meta property="article:tag" content="Google Kubernetes Engine">
<meta property="article:tag" content="MLOps">
<meta property="article:tag" content="Model Serving">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="https://www.kysuai.com/images/scott-webb-3LsocYqXWpM-unsplash-small.jpg">
  
  
  
  <title>Triển khai Triton Inference Server trên Google Kubernetes Engine - Ký sự AI</title>

  <link  rel="stylesheet" href="https://lib.baomitu.com/twitter-bootstrap/4.6.1/css/bootstrap.min.css" />



  <link  rel="stylesheet" href="https://lib.baomitu.com/github-markdown-css/4.0.0/github-markdown.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/hint.css/2.7.0/hint.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css" />



<!-- 主题依赖的图标库，不要自行修改 -->
<!-- Do not modify the link that theme dependent icons -->

<link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_hj8rtnfg7um.css">



<link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_lbnruvf0jn.css">


<link  rel="stylesheet" href="/css/main.css" />


  <link id="highlight-css" rel="stylesheet" href="/css/highlight.css" />
  
    <link id="highlight-css-dark" rel="stylesheet" href="/css/highlight-dark.css" />
  




  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    Fluid.ctx = Object.assign({}, Fluid.ctx)
    var CONFIG = {"hostname":"www.kysuai.com","root":"/","version":"1.9.4","typing":{"enable":true,"typeSpeed":70,"cursorChar":"_","loop":false,"scope":[]},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"left","visible":"hover","icon":""},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"code_language":{"enable":true,"default":"TEXT"},"copy_btn":true,"image_caption":{"enable":true},"image_zoom":{"enable":true,"img_url_replace":["",""]},"toc":{"enable":true,"placement":"right","headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":2},"lazyload":{"enable":true,"loading_img":"/img/loading.gif","onlypost":false,"offset_factor":2},"web_analytics":{"enable":true,"follow_dnt":true,"baidu":null,"google":null,"gtag":"G-1CPE7Q03HT","tencent":{"sid":null,"cid":null},"woyaola":null,"cnzz":null,"leancloud":{"app_id":null,"app_key":null,"server_url":null,"path":"window.location.pathname","ignore_local":false}},"search_path":"/local-search.xml"};

    if (CONFIG.web_analytics.follow_dnt) {
      var dntVal = navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack;
      Fluid.ctx.dnt = dntVal && (dntVal.startsWith('1') || dntVal.startsWith('yes') || dntVal.startsWith('on'));
    }
  </script>
  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>
  

  

  

  
    <!-- Google gtag.js -->
    <script async>
      if (!Fluid.ctx.dnt) {
        Fluid.utils.createScript('https://www.googletagmanager.com/gtag/js?id=G-1CPE7Q03HT', function() {
          window.dataLayer = window.dataLayer || [];
          function gtag(){dataLayer.push(arguments);}
          gtag('js', new Date());
          gtag('config', 'G-1CPE7Q03HT');
        });
      }
    </script>
  

  

  

  

  



  
<meta name="generator" content="Hexo 5.3.0"><link rel="alternate" href="/atom.xml" title="Ký sự AI" type="application/atom+xml">
</head>


<body>
  

  <header>
    

<div class="header-inner" style="height: 70vh;">
  <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand" href="/">
      <strong>Ký sự AI</strong>
    </a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/">
                <i class="iconfont icon-home-fill"></i>
                <span>Home</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/">
                <i class="iconfont icon-archive-fill"></i>
                <span>Archives</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/">
                <i class="iconfont icon-category-fill"></i>
                <span>Categories</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/">
                <i class="iconfont icon-tags-fill"></i>
                <span>Tags</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/">
                <i class="iconfont icon-user-fill"></i>
                <span>About</span>
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search">
              <i class="iconfont icon-search"></i>
            </a>
          </li>
          
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle">
              <i class="iconfont icon-dark" id="color-toggle-icon"></i>
            </a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

  

<div id="banner" class="banner" parallax=true
     style="background: url('/images/scott-webb-3LsocYqXWpM-unsplash-large.jpg') no-repeat center center; background-size: cover;">
  <div class="full-bg-img">
    <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.5)">
      <div class="banner-text text-center fade-in-up">
        <div class="h2">
          
            <span id="subtitle" data-typed-text="Triển khai Triton Inference Server trên Google Kubernetes Engine"></span>
          
        </div>

        
          
  <div class="mt-3">
    
    
      <span class="post-meta">
        <i class="iconfont icon-date-fill" aria-hidden="true"></i>
        <time datetime="2023-01-26 20:42" pubdate>
          26 tháng 1 năm 2023
        </time>
      </span>
    
  </div>

  <div class="mt-1">
    

    
      <span class="post-meta mr-2">
        <i class="iconfont icon-clock-fill"></i>
        
        
        
          48 phút
        
      </span>
    

    
    
  </div>


        
      </div>

      
    </div>
  </div>
</div>

</div>

  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="side-col d-none d-lg-block col-lg-2">
      

    </div>

    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div id="board">
          <article class="post-content mx-auto">
            <!-- SEO header -->
            <h1 style="display: none">Triển khai Triton Inference Server trên Google Kubernetes Engine</h1>
            
            
              <div class="markdown-body">
                
                <h1 id="Tai-sao-can-dung-Triton"><a href="#Tai-sao-can-dung-Triton" class="headerlink" title="Tại sao cần dùng Triton?"></a>Tại sao cần dùng Triton?</h1><p>Khi triển khai mô hình Deep Learning lên môi trường K8S, chúng ta có thể áp dụng phương pháp giống như đối với các chương trình thông thường, về cơ bản thì sẽ gồm những bước như sau:</p>
<ol>
<li>Đóng gói code và mô hình vào Docker image.</li>
<li>Đẩy image lên registry.</li>
<li>Tạo deployment và service trên K8S.</li>
<li>Tạo ingress nối đến service vừa tạo.</li>
</ol>
<p>Phương pháp này rất đơn giản và hiệu quả đối với những mô hình gọn nhẹ không cần đến GPU, ví dụ như mô hình phân loại văn bản bằng LSTM, các mô hình Machine Learning truyền thống như SVM hay Random Forest. Nhưng khi mô hình lớn đến mức không đáp ứng được các yêu cầu về latency hoặc throughput thì triển khai lên GPU là điều cần thiết. Nếu chúng ta vẫn áp dụng phương pháp kể trên thì có những nhược điểm như sau:</p>
<ol>
<li>Các image dùng được GPU thường có kích thước lớn, cộng với việc mô hình cũng có kích thước lớn khiến cho <strong>image đầu ra nặng đến mức làm chậm đáng kể thời gian push và pull image trong quá trình triển khai</strong>. Điều này gây khó khăn nếu mô hình thường xuyên được cập nhật với dữ liệu mới.</li>
<li><strong>Kubernetes không cung cấp cơ chế native cho việc cấp phát 1 GPU cho nhiều container</strong>. Không giống như khi cấp phát CPU, container khi yêu cầu K8S cấp phát GPU chỉ có thể được cấp nguyên cả 1 GPU chứ không được yêu cầu 0.5 hay 0.1 GPU. Vấn đề này có thể được khắc phục nhờ vào một số giải pháp như <a target="_blank" rel="noopener" href="https://cloud.google.com/kubernetes-engine/docs/how-to/gpus-multi">multi-instance GPUs</a> (chỉ hỗ trợ dòng A100) hoặc <a target="_blank" rel="noopener" href="https://cloud.google.com/kubernetes-engine/docs/concepts/timesharing-gpus">time-sharing GPUs</a>, nhưng đều phải phụ thuộc vào giải pháp của bên thứ 3, đồng nghĩa với việc migrate sẽ phức tạp hơn (giả sử như bạn muốn chuyển qua AWS nhưng họ chưa hỗ trợ hoặc cung cấp giải pháp khác thì sao?).</li>
</ol>
<p><a target="_blank" rel="noopener" href="https://github.com/triton-inference-server/server">Triton</a> có thể giải quyết được những nhược điểm này. Nó là 1 phần mềm mã nguồn mở dành cho vai trò inference các mô hình Machine Learning, được tạo bởi đội ngũ của Nvidia. Triton cho phép triển khai nhiều mô hình đến từ nhiều framework khác nhau, bao gồm TensorRT, TensorFlow, PyTorch, ONNX, OpenVINO, Python, RAPIDS FIL,… Triton hỗ trợ nhiều hình thức truy vấn khác nhau, bao gồm truy vấn real time, theo batched, ensembles, và audio/video streaming. Chúng đều được tối ưu để có hiệu năng cao.</p>
<p>Vậy thì Triton giải quyết những vấn đề trên như thế nào?</p>
<ol>
<li>Khi triển khai Triton lên K8S, chúng ta không cần phải đóng gói image kèm với mô hình. Thay vào đó, mô hình được mount từ 1 file system vào 1 thư mục cụ thể, hoặc kết nối đến cloud storage như S3 hay GCS. Khi khởi động, Triton sẽ tải mô hình từ cloud storage về local và bắt đầu chạy. Vì thế nên kích thước của image sẽ nhẹ hơn và không cần phải pull lại image khi cập nhật mô hình mà chỉ cần tải lại file mô hình từ cloud storage.</li>
<li>Cơ chế của Triton là quản lý tập trung nhiều mô hình khác nhau trong cùng 1 container. Trong đó, các mô hình có thể cùng chia sẻ tài nguyên của 1 GPU, giúp cho việc sử dụng GPU tối ưu hơn. Giải pháp của bên thứ 3 vì vậy trở nên không cần thiết nên việc migrate sẽ dễ dàng hơn.</li>
</ol>
<p>Trong phần tiếp theo, mình sẽ hướng dẫn cách triển khai Triton trên Google Kubernetes Engine.</p>
<h1 id="Trien-khai-Triton-tren-GKE"><a href="#Trien-khai-Triton-tren-GKE" class="headerlink" title="Triển khai Triton trên GKE"></a>Triển khai Triton trên GKE</h1><p>Trước khi bắt đầu triển khai, chúng ta hãy cùng phân tích kiến trúc của Triton trên GKE.</p>
<h2 id="Kien-truc-tong-quan"><a href="#Kien-truc-tong-quan" class="headerlink" title="Kiến trúc tổng quan"></a>Kiến trúc tổng quan</h2><p><img src="/2023/01/26/Trien-khai-Triton-Inference-Server-tren-Google-Kubernetes-Engine/triton-architecture.jpg" srcset="/img/loading.gif" lazyload alt="Kiến trúc tổng quan của Triton trên GKE"></p>
<p>Như đã nói ở phần trước, Triton cần phải mount từ 1 file system hoặc cloud storage để có thể tải mô hình lên GPU. GKE đều cung cấp cả 2 cách mount này, nhưng mount từ file system sẽ gây khó khăn trong việc tải mô hình lên disk trong khi đó thì GCS cho phép tải, chỉnh sửa, xoá file một cách dễ dàng. Hơn nữa là chi phí của GCS rẻ hơn so với dùng disk, GCS tính phí theo phương án “dùng nhiêu trả nhiêu”, còn disk thì ta phải cấp phát lượng dung lượng nhất định không tránh khỏi dư thừa.</p>
<p>Mặc dù Triton cho phép chạy custom code Python để preprocess input và postprocess output, giúp cho nó có thể xử lý request từ đầu đến cuối. Nhưng theo mình thì Triton chỉ nên được sử dụng cho mục đích inference mô hình mà thôi. Các công đoạn như preprocess, postprocess, monitor nên được giao cho pod khác mà mình gọi là API Service trong hình trên. Như thế sẽ tách rời được vai trò giữa các service, theo nguyên tắc thiết kế của microservice.</p>
<p>API Service là nơi nhận request từ bên ngoài, preprocess, gửi data đến Triton, nhận kết quả inference, postprocess và trả kết quả về. Nó còn có nhiệm vụ theo dõi các metric như latency, request per second, throughput, confident score. Một lợi ích khác của việc phân tách vai trò là có thể scale một cách linh hoạt hơn. Giả sử như bạn có 1 module preprocess rất nặng và chậm, bạn có thể scale pod API Service trên 1 node khác không cần GPU nhưng có nhiều tài nguyên hơn mà không cần phải scale luôn cả Triton.</p>
<h2 id="Tien-hanh-trien-khai"><a href="#Tien-hanh-trien-khai" class="headerlink" title="Tiến hành triển khai"></a>Tiến hành triển khai</h2><h3 id="Tao-GCS-bucket"><a href="#Tao-GCS-bucket" class="headerlink" title="Tạo GCS bucket"></a>Tạo GCS bucket</h3><p>Việc đầu tiên chúng ta cần phải làm là tạo 1 bucket trên GCS. Nếu bạn đã có sẵn bucket rồi thì có thể bỏ qua phần này.</p>
<ol>
<li>Trong phần navigation, chọn <strong>Cloud Storage</strong> &gt; <strong>Buckets</strong>.</li>
<li>Click <strong>Create</strong>.</li>
<li>Chọn tên cho bucket. Trong bài viết này mình sẽ giả sử tên của bucket là <strong>triton-models</strong>, nhưng bạn nên chọn tên khác vì tên bucket là globally unique. Trong các đoạn code bên dưới, bạn cần thay tên bucket giả sử với tên bucket mà bạn tạo.</li>
<li>Trong mục control access, mình recommend bạn hãy giới hạn quyền truy cập vào bucket này bằng cách check vào ô <strong>Enforce public access prevention on this bucket</strong>. Nó sẽ ngăn model bị public ra bên ngoài.</li>
<li>Click <strong>Create</strong>.</li>
</ol>
<p><img src="/2023/01/26/Trien-khai-Triton-Inference-Server-tren-Google-Kubernetes-Engine/screenshot-1.jpeg" srcset="/img/loading.gif" lazyload alt="Tạo GCS bucket"></p>
<h3 id="Tao-service-account"><a href="#Tao-service-account" class="headerlink" title="Tạo service account"></a>Tạo service account</h3><p>Để Triton có thể truy cập vào bucket của GCS, chúng ta phải cung cấp cho nó key của service account có quyền truy cập vào GCS. Để làm điều này, trước tiên ta phải tạo service account có quyền <strong>Storage Admin</strong>. Chú ý là chỉ nên cấp 1 quyền này cho service account của bạn để giảm thiểu rủi ro an ninh.</p>
<ol>
<li>Truy cập vào <strong>IAM &amp; Admin</strong> &gt; <strong>Service Accounts</strong>.</li>
<li>Click <strong>CREATE SERVICE ACCOUNT</strong>.</li>
<li>Điền các thông tin cần thiết.</li>
<li>Đến phần <strong>Grant this service account access to project</strong>, thêm quyền <strong>Storage Admin</strong>.</li>
<li>Click <strong>Done</strong>.</li>
</ol>
<p>Nếu bạn không có quyền để truy cập <strong>IAM &amp; Admin</strong> &gt; <strong>Service Accounts</strong>, bạn có thể nhờ admin của project để tạo thay.</p>
<p><img src="/2023/01/26/Trien-khai-Triton-Inference-Server-tren-Google-Kubernetes-Engine/screenshot-2.jpeg" srcset="/img/loading.gif" lazyload alt="Tạo service account"></p>
<p>Sau khi tạo xong service account, bạn chọn service account vừa tạo và chọn tab <strong>KEYS</strong>. Ở đây liệt kê các key dùng để authenticate với quyền của service account này, click vào <strong>ADD KEY</strong> và chọn <strong>Create new key</strong>, chọn key type là JSON và click <strong>CREATE</strong>.</p>
<p><img src="/2023/01/26/Trien-khai-Triton-Inference-Server-tren-Google-Kubernetes-Engine/screenshot-3.jpeg" srcset="/img/loading.gif" lazyload alt="Tạo key của service account"></p>
<p>Tải file key với tên là <code>key.json</code> về môi trường kubectl của bạn và dùng lệnh sau để tạo secret trên K8S:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">kubectl create secret generic triton-service-account --from-file=key.json=./key.json<br></code></pre></td></tr></table></figure>
<p>Secret này sẽ được mount vào container của Triton để authenticate với GCS.</p>
<h3 id="Trien-khai-Triton"><a href="#Trien-khai-Triton" class="headerlink" title="Triển khai Triton"></a>Triển khai Triton</h3><p>Dưới đây là cấu hình deployment của Triton:</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br></pre></td><td class="code"><pre><code class="hljs yaml"><span class="hljs-attr">apiVersion:</span> <span class="hljs-string">apps/v1</span><br><span class="hljs-attr">kind:</span> <span class="hljs-string">Deployment</span><br><span class="hljs-attr">metadata:</span><br>  <span class="hljs-attr">name:</span> <span class="hljs-string">triton</span><br>  <span class="hljs-attr">labels:</span><br>    <span class="hljs-attr">app.kubernetes.io/name:</span> <span class="hljs-string">triton</span><br>    <span class="hljs-attr">app.kubernetes.io/instance:</span> <span class="hljs-string">triton</span><br><span class="hljs-attr">spec:</span><br>  <span class="hljs-attr">replicas:</span> <span class="hljs-number">1</span><br>  <span class="hljs-attr">selector:</span><br>    <span class="hljs-attr">matchLabels:</span><br>      <span class="hljs-attr">app.kubernetes.io/name:</span> <span class="hljs-string">triton</span><br>      <span class="hljs-attr">app.kubernetes.io/instance:</span> <span class="hljs-string">triton</span><br>  <span class="hljs-comment"># Loại bỏ đoạn này nếu bạn có nhiều hơn 1 GPU.</span><br>  <span class="hljs-comment"># Đoạn này có tác dụng ngăn tình trạng không thể tạo pod mới thay thế pod cũ khi chỉ có 1 GPU.</span><br>  <span class="hljs-attr">strategy:</span><br>    <span class="hljs-attr">rollingUpdate:</span><br>      <span class="hljs-attr">maxSurge:</span> <span class="hljs-number">0</span><br>      <span class="hljs-attr">maxUnavailable:</span> <span class="hljs-number">1</span><br>    <span class="hljs-attr">type:</span> <span class="hljs-string">RollingUpdate</span><br>  <span class="hljs-attr">template:</span><br>    <span class="hljs-attr">metadata:</span><br>      <span class="hljs-attr">labels:</span><br>        <span class="hljs-attr">app.kubernetes.io/name:</span> <span class="hljs-string">triton</span><br>        <span class="hljs-attr">app.kubernetes.io/instance:</span> <span class="hljs-string">triton</span><br>    <span class="hljs-attr">spec:</span><br>      <span class="hljs-attr">containers:</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">triton</span><br>        <span class="hljs-attr">image:</span> <span class="hljs-string">nvcr.io/nvidia/tritonserver:22.12-py3</span><br>        <span class="hljs-attr">imagePullPolicy:</span> <span class="hljs-string">IfNotPresent</span><br>        <span class="hljs-attr">command:</span><br>        <span class="hljs-bullet">-</span> <span class="hljs-string">tritonserver</span><br>        <span class="hljs-attr">args:</span><br>        <span class="hljs-bullet">-</span> <span class="hljs-string">--model-repository=gs://triton-models/</span><br>        <span class="hljs-comment"># Mount service account key vào thư mục /var/secrets/google</span><br>        <span class="hljs-attr">volumeMounts:</span><br>        <span class="hljs-bullet">-</span> <span class="hljs-attr">mountPath:</span> <span class="hljs-string">/var/secrets/google</span><br>          <span class="hljs-attr">name:</span> <span class="hljs-string">google-cloud-key</span><br>        <span class="hljs-comment"># Chỉ định vị trí của service account key cho Triton</span><br>        <span class="hljs-attr">env:</span><br>        <span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">GOOGLE_APPLICATION_CREDENTIALS</span><br>          <span class="hljs-attr">value:</span> <span class="hljs-string">/var/secrets/google/key.json</span><br>        <span class="hljs-comment"># Các port của Triton</span><br>        <span class="hljs-attr">ports:</span><br>        <span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">http</span><br>          <span class="hljs-attr">containerPort:</span> <span class="hljs-number">8000</span><br>          <span class="hljs-attr">protocol:</span> <span class="hljs-string">TCP</span><br>        <span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">grpc</span><br>          <span class="hljs-attr">containerPort:</span> <span class="hljs-number">8001</span><br>          <span class="hljs-attr">protocol:</span> <span class="hljs-string">TCP</span><br>        <span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">prometheus</span><br>          <span class="hljs-attr">containerPort:</span> <span class="hljs-number">8002</span><br>          <span class="hljs-attr">protocol:</span> <span class="hljs-string">TCP</span><br>        <span class="hljs-comment"># Bắt buộc phải khai báo cấp phát GPU để được cấp</span><br>        <span class="hljs-attr">resources:</span><br>          <span class="hljs-attr">requests:</span><br>            <span class="hljs-attr">nvidia.com/gpu:</span> <span class="hljs-string">&quot;1&quot;</span><br>          <span class="hljs-attr">limits:</span><br>            <span class="hljs-attr">nvidia.com/gpu:</span> <span class="hljs-string">&quot;1&quot;</span><br>      <span class="hljs-comment"># Dùng secret vừa tạo ở bước trên để tạo thành volume mount</span><br>      <span class="hljs-attr">volumes:</span><br>        <span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">google-cloud-key</span><br>          <span class="hljs-attr">secret:</span><br>            <span class="hljs-attr">secretName:</span> <span class="hljs-string">triton-service-account</span><br></code></pre></td></tr></table></figure>
<p>Copy đoạn code trên vào file <code>deployment.yaml</code> và chạy lệnh:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">kubectl apply -f deployment.yaml<br></code></pre></td></tr></table></figure>
<p>Tiếp theo là tạo file service <code>service.yaml</code>:</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs yaml"><span class="hljs-attr">apiVersion:</span> <span class="hljs-string">v1</span><br><span class="hljs-attr">kind:</span> <span class="hljs-string">Service</span><br><span class="hljs-attr">metadata:</span><br>  <span class="hljs-attr">name:</span> <span class="hljs-string">triton</span><br>  <span class="hljs-attr">labels:</span><br>    <span class="hljs-attr">app.kubernetes.io/name:</span> <span class="hljs-string">triton</span><br>    <span class="hljs-attr">app.kubernetes.io/instance:</span> <span class="hljs-string">triton</span><br><span class="hljs-attr">spec:</span><br>  <span class="hljs-attr">type:</span> <span class="hljs-string">ClusterIP</span><br>  <span class="hljs-attr">ports:</span><br>  <span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">GRPC</span><br>    <span class="hljs-attr">protocol:</span> <span class="hljs-string">TCP</span><br>    <span class="hljs-attr">port:</span> <span class="hljs-number">8001</span><br>    <span class="hljs-attr">targetPort:</span> <span class="hljs-string">grpc</span><br>  <span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">HTTP</span><br>    <span class="hljs-attr">protocol:</span> <span class="hljs-string">TCP</span><br>    <span class="hljs-attr">port:</span> <span class="hljs-number">8000</span><br>    <span class="hljs-attr">targetPort:</span> <span class="hljs-string">http</span><br>  <span class="hljs-attr">selector:</span><br>    <span class="hljs-attr">app.kubernetes.io/name:</span> <span class="hljs-string">triton</span><br>    <span class="hljs-attr">app.kubernetes.io/instance:</span> <span class="hljs-string">triton</span><br></code></pre></td></tr></table></figure>
<p>Tạo service bằng lệnh:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">kubectl apply -f service.yaml<br></code></pre></td></tr></table></figure>
<p>Sau khi hoàn tất, bạn có thể gọi service triton từ các pod khác trong cluster thông qua endpoint <code>triton:8000</code> đối với HTTP hoặc <code>triton:8001</code> đối với GRPC.</p>
<p>Nếu muốn gọi trực tiếp Triton từ ngoài cluster thì bạn có thể tạo file <code>ingress.yaml</code>, nếu dùng NGINX Ingress Controller thì file cấu hình cơ bản sẽ tương tự như sau:</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs yaml"><span class="hljs-attr">apiVersion:</span> <span class="hljs-string">networking.k8s.io/v1</span><br><span class="hljs-attr">kind:</span> <span class="hljs-string">Ingress</span><br><span class="hljs-attr">metadata:</span><br>  <span class="hljs-attr">name:</span> <span class="hljs-string">triton</span><br>  <span class="hljs-attr">namespace:</span> <span class="hljs-string">default</span><br>  <span class="hljs-attr">annotations:</span><br>    <span class="hljs-attr">nginx.ingress.kubernetes.io/rewrite-target:</span> <span class="hljs-string">/$2</span><br><span class="hljs-attr">spec:</span><br>  <span class="hljs-attr">ingressClassName:</span> <span class="hljs-string">nginx</span><br>  <span class="hljs-attr">rules:</span><br>    <span class="hljs-bullet">-</span> <span class="hljs-attr">host:</span> <span class="hljs-string">&lt;your-domain&gt;</span><br>      <span class="hljs-attr">http:</span><br>        <span class="hljs-attr">paths:</span><br>          <span class="hljs-bullet">-</span> <span class="hljs-attr">pathType:</span> <span class="hljs-string">Prefix</span><br>            <span class="hljs-attr">path:</span> <span class="hljs-string">/triton(/|$)(.*)</span><br>            <span class="hljs-attr">backend:</span><br>              <span class="hljs-attr">service:</span><br>                <span class="hljs-attr">name:</span> <span class="hljs-string">triton</span><br>                <span class="hljs-attr">port:</span><br>                  <span class="hljs-attr">number:</span> <span class="hljs-number">8000</span><br></code></pre></td></tr></table></figure>
<p>Rồi dùng lệnh:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">kubectl apply -f ingress.yaml<br></code></pre></td></tr></table></figure>
<p>Ingress này sẽ điều hướng request URL có prefix dạng <code>http://&lt;your-domain&gt;/triton</code> đến service triton vào port HTTP.</p>
<h3 id="Chay-mo-hinh"><a href="#Chay-mo-hinh" class="headerlink" title="Chạy mô hình"></a>Chạy mô hình</h3><p>Do bucket vừa mới tạo chưa có gì nên chúng ta chưa thể chạy được mô hình nào cả. Trước tiên, bạn cần đưa mô hình của bạn lên bucket theo đúng chuẩn do Triton quy định, tham khảo ở <a target="_blank" rel="noopener" href="https://github.com/triton-inference-server/server/blob/main/docs/user_guide/model_repository.md">đây</a>. Để diễn giải cho phần này, mình giả sử ở đây đang có 1 mô hình BERT cho bài toán phân loại văn bản.</p>
<p>Nếu bạn đã đọc document tham khảo của Triton, hãy thử xem qua file config của BERT:</p>
<figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><code class="hljs text">name: &quot;bert_text_classification&quot;<br>platform: &quot;onnxruntime_onnx&quot;<br>max_batch_size: 0<br>input [<br>  &#123;<br>    name: &quot;input_ids&quot;<br>    data_type: TYPE_INT32<br>    dims: [-1, -1]<br>  &#125;,<br>  &#123;<br>    name: &quot;attention_mask&quot;<br>    data_type: TYPE_INT32<br>    dims: [-1, -1]<br>  &#125;<br>]<br><br>output [<br>  &#123;<br>    name: &quot;logits&quot;<br>    data_type: TYPE_FP32<br>    dims: [-1, 2]<br>  &#125;<br>]<br><br>instance_group [<br>  &#123;<br>    count: 1<br>    kind: KIND_GPU<br>  &#125;<br>]<br></code></pre></td></tr></table></figure>
<p>Để giao tiếp với Triton, có 2 protocol là HTTP và gRPC. gRPC có hiệu suất tốt hơn so với HTTP nên mình chọn protocol này cho code API Service. Triton cung cấp cho chúng ta thư viện Python để đơn giản hoá việc gọi mô hình (<a target="_blank" rel="noopener" href="https://github.com/triton-inference-server/client">Github</a>).</p>
<p>Dưới đây là đoạn code tham khảo để gọi mô hình BERT cho text classification:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> math<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> scipy.special<br><span class="hljs-keyword">from</span> typing <span class="hljs-keyword">import</span> <span class="hljs-type">List</span><br><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer<br><span class="hljs-keyword">import</span> tritonclient.grpc <span class="hljs-keyword">as</span> grpcclient<br><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Predictor</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self,</span><br><span class="hljs-params">                 model_name: <span class="hljs-built_in">str</span>,</span><br><span class="hljs-params">                 tokenizer: AutoTokenizer,</span><br><span class="hljs-params">                 triton_url: <span class="hljs-built_in">str</span> = <span class="hljs-string">&#x27;triton:8001&#x27;</span>,</span><br><span class="hljs-params">                 batch_size: <span class="hljs-built_in">int</span> = <span class="hljs-number">64</span></span>):<br>        self.model_name = model_name<br>        self.tokenizer = tokenizer<br>        self.triton_url = triton_url<br>        self.batch_size = batch_size<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">predict_batch</span>(<span class="hljs-params">self, batch_items: <span class="hljs-type">List</span>[<span class="hljs-built_in">str</span>]</span>):<br>        <span class="hljs-comment"># Tokenize &amp; encode</span><br>        inputs = self.tokenizer.batch_encode_plus(batch_items,<br>                                                  add_special_tokens=<span class="hljs-literal">True</span>,<br>                                                  max_length=<span class="hljs-number">256</span>,<br>                                                  truncation=<span class="hljs-literal">True</span>,<br>                                                  pad_to_max_length=<span class="hljs-literal">True</span>)<br>        input_ids = np.array(inputs[<span class="hljs-string">&#x27;input_ids&#x27;</span>]).astype(np.int32)<br>        attention_mask = np.array(inputs[<span class="hljs-string">&#x27;attention_mask&#x27;</span>]).astype(np.int32)<br><br>        <span class="hljs-comment"># Setup inference</span><br>        triton_client = grpcclient.InferenceServerClient(url=self.triton_url, verbose=<span class="hljs-literal">False</span>)<br>        outputs = [grpcclient.InferRequestedOutput(<span class="hljs-string">&#x27;logits&#x27;</span>)]<br>        y_pred = []<br>        n_batches = math.ceil(<span class="hljs-built_in">len</span>(batch_items) / self.batch_size)<br><br>        <span class="hljs-comment"># Infer in batches</span><br>        <span class="hljs-keyword">for</span> x0, x1 <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(np.array_split(input_ids, n_batches),<br>                          np.array_split(attention_mask, n_batches)):<br>            inputs = [<br>                grpcclient.InferInput(<span class="hljs-string">&#x27;input_ids&#x27;</span>, x0.shape, <span class="hljs-string">&#x27;INT32&#x27;</span>),<br>                grpcclient.InferInput(<span class="hljs-string">&#x27;attention_mask&#x27;</span>, x1.shape, <span class="hljs-string">&#x27;INT32&#x27;</span>),<br>            ]<br><br>            inputs[<span class="hljs-number">0</span>].set_data_from_numpy(x0)<br>            inputs[<span class="hljs-number">1</span>].set_data_from_numpy(x1)<br><br>            results = triton_client.infer(<br>                model_name=self.model_name,<br>                inputs=inputs,<br>                outputs=outputs)<br><br>            logits = results.as_numpy(<span class="hljs-string">&#x27;logits&#x27;</span>)<br>            output_prob = scipy.special.softmax(logits, axis=<span class="hljs-number">1</span>)<br>            y_pred.extend(output_prob.tolist())<br><br>        <span class="hljs-keyword">return</span> y_pred<br></code></pre></td></tr></table></figure>
<p>Đoạn code này chỉ là phần core của API Service, những thành phần khác như server, text preprocess, postprocess thì bạn tham khảo ở bên ngoài nhé.</p>
<h1 id="Cac-van-de-nay-sinh"><a href="#Cac-van-de-nay-sinh" class="headerlink" title="Các vấn đề nảy sinh"></a>Các vấn đề nảy sinh</h1><h2 id="Kich-thuoc-image-con-kha-lon"><a href="#Kich-thuoc-image-con-kha-lon" class="headerlink" title="Kích thước image còn khá lớn"></a>Kích thước image còn khá lớn</h2><p>Nếu bạn dùng spot node như mình thì hay xảy ra trường hợp bị downtime khá lâu khi node bị preemptible. Nguyên nhân chủ yếu là do image của Triton vẫn còn khá nặng nên thời gian pull về lâu. Có thể giảm kích thước của image bằng cách build custom image chỉ hỗ trợ framework mà bạn hay dùng, như của mình là ONNX nên có thể loại bỏ TF, PyTorch. Xem ở <a target="_blank" rel="noopener" href="https://github.com/triton-inference-server/server/blob/main/docs/customization_guide/compose.md">đây</a> để tham khảo cách build custom image cho framework của bạn.</p>
<h2 id="Tranh-chap-tai-nguyen-giua-cac-mo-hinh"><a href="#Tranh-chap-tai-nguyen-giua-cac-mo-hinh" class="headerlink" title="Tranh chấp tài nguyên giữa các mô hình"></a>Tranh chấp tài nguyên giữa các mô hình</h2><p>Hiện tại chưa có cơ chế giới hạn tài nguyên của mô hình nên nếu có 1 mô hình sử dụng hết tài nguyên của GPU thì các mô hình khác sẽ không thể chạy được. </p>
<h2 id="Kho-scale-theo-chieu-ngang"><a href="#Kho-scale-theo-chieu-ngang" class="headerlink" title="Khó scale theo chiều ngang"></a>Khó scale theo chiều ngang</h2><p>Vì Triton quản lý mô hình theo hình thức tập trung, mỗi pod sẽ chứa ít nhất 1 instance của mỗi mô hình. Khi ta muốn scale 1 mô hình, nếu ta scale số lượng pod thì đồng nghĩa với việc scale tất cả mô hình còn lại, rất là lãng phí. Đối với scale theo chiều dọc thì sẽ dễ dàng hơn vì Triton cho phép tạo nhiều instance của 1 mô hình trên nhiều GPU, xem <a target="_blank" rel="noopener" href="https://github.com/triton-inference-server/server/blob/main/docs/user_guide/model_configuration.md#instance-groups">Instance Groups</a>.</p>
<h1 id="Tong-ket"><a href="#Tong-ket" class="headerlink" title="Tổng kết"></a>Tổng kết</h1><p>Hi vọng sau bài viết này, bạn có thể triển khai mô hình của mình lên Triton trên GKE. Mặc dù bài viết này chỉ tập trung vào GKE, nếu bạn dùng AWS hay onprem thì cơ chế cũng gần tương tự nhau, chỉ cần 1 cloud storage giống như S3 hoặc GCS là có thể chạy được, và tất nhiên là cần GPU nữa.</p>
<p>Happy Coding!</p>

                
              </div>
            
            <hr/>
            <div>
              <div class="post-metas my-3">
  
  
    <div class="post-meta">
      <i class="iconfont icon-tags"></i>
      
        <a href="/tags/Machine-Learning/">#Machine Learning</a>
      
        <a href="/tags/Deep-Learning/">#Deep Learning</a>
      
        <a href="/tags/K8S/">#K8S</a>
      
        <a href="/tags/Artificial-Intelligence/">#Artificial Intelligence</a>
      
        <a href="/tags/Triton-Inference-Server/">#Triton Inference Server</a>
      
        <a href="/tags/Google-Kubernetes-Engine/">#Google Kubernetes Engine</a>
      
        <a href="/tags/MLOps/">#MLOps</a>
      
        <a href="/tags/Model-Serving/">#Model Serving</a>
      
    </div>
  
</div>


              
  

  <div class="license-box my-3">
    <div class="license-title">
      <div>Triển khai Triton Inference Server trên Google Kubernetes Engine</div>
      <div>https://www.kysuai.com/2023/01/26/Trien-khai-Triton-Inference-Server-tren-Google-Kubernetes-Engine/</div>
    </div>
    <div class="license-meta">
      
        <div class="license-meta-item">
          <div>Tác giả</div>
          <div>Vũ Đức Duy</div>
        </div>
      
      
        <div class="license-meta-item license-meta-date">
          <div>Đăng vào</div>
          <div>26 tháng 1 năm 2023</div>
        </div>
      
      
      
        <div class="license-meta-item">
          <div>Licensed under</div>
          <div>
            
              
              
                <a target="_blank" href="https://creativecommons.org/licenses/by/4.0/">
                  <span class="hint--top hint--rounded" aria-label="BY - Attribution">
                    <i class="iconfont icon-by"></i>
                  </span>
                </a>
              
            
          </div>
        </div>
      
    </div>
    <div class="license-icon iconfont"></div>
  </div>



              
                <div class="post-prevnext my-3">
                  <article class="post-prev col-6">
                    
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="/2022/12/28/Trien-khai-GPT-J-6B-Vietnamese-News-tren-Docker-va-K8S/" title="Triển khai GPT-J 6B Vietnamese News trên Docker và K8S">
                        <span class="hidden-mobile">Triển khai GPT-J 6B Vietnamese News trên Docker và K8S</span>
                        <span class="visible-mobile">Sau</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
          </article>
        </div>
      </div>
    </div>

    <div class="side-col d-none d-lg-block col-lg-2">
      
  <aside class="sidebar" style="margin-left: -1rem">
    <div id="toc">
  <p class="toc-header">
    <i class="iconfont icon-list"></i>
    <span>Mục lục</span>
  </p>
  <div class="toc-body" id="toc-body"></div>
</div>



  </aside>


    </div>
  </div>
</div>





  



  



  



  



  







    

    
      <a id="scroll-top-button" aria-label="TOP" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">Tìm kiếm</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v" for="local-search-input">Từ khóa</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>

    

    
  </main>

  <footer>
    <div class="footer-inner">
  
    <div class="footer-content">
       <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a> 
    </div>
  
  
  
  
</div>

  </footer>

  <!-- Scripts -->
  
  <script  src="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://lib.baomitu.com/jquery/3.6.0/jquery.min.js" ></script>
<script  src="https://lib.baomitu.com/twitter-bootstrap/4.6.1/js/bootstrap.min.js" ></script>
<script  src="/js/events.js" ></script>
<script  src="/js/plugins.js" ></script>


  <script  src="https://lib.baomitu.com/typed.js/2.0.12/typed.min.js" ></script>
  <script>
    (function (window, document) {
      var typing = Fluid.plugins.typing;
      var subtitle = document.getElementById('subtitle');
      if (!subtitle || !typing) {
        return;
      }
      var text = subtitle.getAttribute('data-typed-text');
      
        typing(text);
      
    })(window, document);
  </script>




  
    <script  src="/js/img-lazyload.js" ></script>
  




  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/tocbot/4.18.2/tocbot.min.js', function() {
    var toc = jQuery('#toc');
    if (toc.length === 0 || !window.tocbot) { return; }
    var boardCtn = jQuery('#board-ctn');
    var boardTop = boardCtn.offset().top;

    window.tocbot.init(Object.assign({
      tocSelector     : '#toc-body',
      contentSelector : '.markdown-body',
      linkClass       : 'tocbot-link',
      activeLinkClass : 'tocbot-active-link',
      listClass       : 'tocbot-list',
      isCollapsedClass: 'tocbot-is-collapsed',
      collapsibleClass: 'tocbot-is-collapsible',
      scrollSmooth    : true,
      includeTitleTags: true,
      headingsOffset  : -boardTop,
    }, CONFIG.toc));
    if (toc.find('.toc-list-item').length > 0) {
      toc.css('visibility', 'visible');
    }

    Fluid.events.registerRefreshCallback(function() {
      if ('tocbot' in window) {
        tocbot.refresh();
        var toc = jQuery('#toc');
        if (toc.length === 0 || !tocbot) {
          return;
        }
        if (toc.find('.toc-list-item').length > 0) {
          toc.css('visibility', 'visible');
        }
      }
    });
  });
</script>


  <script src=https://lib.baomitu.com/clipboard.js/2.0.11/clipboard.min.js></script>

  <script>Fluid.plugins.codeWidget();</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/anchor-js/4.3.1/anchor.min.js', function() {
    window.anchors.options = {
      placement: CONFIG.anchorjs.placement,
      visible  : CONFIG.anchorjs.visible
    };
    if (CONFIG.anchorjs.icon) {
      window.anchors.options.icon = CONFIG.anchorjs.icon;
    }
    var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
    var res = [];
    for (var item of el) {
      res.push('.markdown-body > ' + item.trim());
    }
    if (CONFIG.anchorjs.placement === 'left') {
      window.anchors.options.class = 'anchorjs-link-left';
    }
    window.anchors.add(res.join(', '));

    Fluid.events.registerRefreshCallback(function() {
      if ('anchors' in window) {
        anchors.removeAll();
        var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
        var res = [];
        for (var item of el) {
          res.push('.markdown-body > ' + item.trim());
        }
        if (CONFIG.anchorjs.placement === 'left') {
          anchors.options.class = 'anchorjs-link-left';
        }
        anchors.add(res.join(', '));
      }
    });
  });
</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js', function() {
    Fluid.plugins.fancyBox();
  });
</script>


  <script>Fluid.plugins.imageCaption();</script>

  <script  src="/js/local-search.js" ></script>





<!-- 主题的启动项，将它保持在最底部 -->
<!-- the boot of the theme, keep it at the bottom -->
<script  src="/js/boot.js" ></script>


  

  <noscript>
    <div class="noscript-warning">Blog works best with JavaScript enabled</div>
  </noscript>
</body>
</html>
