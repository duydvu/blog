

<!DOCTYPE html>
<html lang="vi" data-default-color-scheme=auto>



<head>
  <meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="/apple-touch-icon.png">
  <link rel="icon" href="/favicon.ico">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5.0, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="author" content="Vũ Đức Duy">
  <meta name="keywords" content="ký sự AI, lập trình, programming, công nghệ phần mềm, software engineering, AI, trí tuệ nhân tạo, data science, khoa học dữ liệu">
  
    <meta name="description" content="Thời gian gần đây đang nổi lên 1 con AI tên là ChatGPT có khả năng giao tiếp như người thật, biết làm thơ, viết luận văn, giải toán, dịch tiếng Anh sang tiếng Việt, ngay cả viết và đọc hiểu code. Thậm">
<meta property="og:type" content="article">
<meta property="og:title" content="Triển khai GPT-J 6B Vietnamese News trên Docker và K8S">
<meta property="og:url" content="https://www.kysuai.com/2022/12/28/Trien-khai-GPT-J-6B-Vietnamese-News-tren-Docker-va-K8S/index.html">
<meta property="og:site_name" content="Ký sự AI">
<meta property="og:description" content="Thời gian gần đây đang nổi lên 1 con AI tên là ChatGPT có khả năng giao tiếp như người thật, biết làm thơ, viết luận văn, giải toán, dịch tiếng Anh sang tiếng Việt, ngay cả viết và đọc hiểu code. Thậm">
<meta property="og:locale" content="vi_VN">
<meta property="og:image" content="https://www.kysuai.com/images/possessed-photography-U3sOwViXhkY-unsplash.jpg">
<meta property="article:published_time" content="2022-12-28T11:28:00.000Z">
<meta property="article:modified_time" content="2023-11-22T14:03:20.629Z">
<meta property="article:author" content="Vũ Đức Duy">
<meta property="article:tag" content="Machine Learning">
<meta property="article:tag" content="Deep Learning">
<meta property="article:tag" content="Artificial Intelligence">
<meta property="article:tag" content="Docker">
<meta property="article:tag" content="GPT-J">
<meta property="article:tag" content="K8S">
<meta property="article:tag" content="Natural Language Generation">
<meta property="article:tag" content="Language Model">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="https://www.kysuai.com/images/possessed-photography-U3sOwViXhkY-unsplash.jpg">
  
  
  
  <title>Triển khai GPT-J 6B Vietnamese News trên Docker và K8S - Ký sự AI</title>

  <link  rel="stylesheet" href="https://lib.baomitu.com/twitter-bootstrap/4.6.1/css/bootstrap.min.css" />



  <link  rel="stylesheet" href="https://lib.baomitu.com/github-markdown-css/4.0.0/github-markdown.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/hint.css/2.7.0/hint.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css" />



<!-- 主题依赖的图标库，不要自行修改 -->
<!-- Do not modify the link that theme dependent icons -->

<link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_hj8rtnfg7um.css">



<link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_lbnruvf0jn.css">


<link  rel="stylesheet" href="/css/main.css" />


  <link id="highlight-css" rel="stylesheet" href="/css/highlight.css" />
  
    <link id="highlight-css-dark" rel="stylesheet" href="/css/highlight-dark.css" />
  




  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    Fluid.ctx = Object.assign({}, Fluid.ctx)
    var CONFIG = {"hostname":"www.kysuai.com","root":"/","version":"1.9.4","typing":{"enable":true,"typeSpeed":70,"cursorChar":"_","loop":false,"scope":[]},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"left","visible":"hover","icon":""},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"code_language":{"enable":true,"default":"TEXT"},"copy_btn":true,"image_caption":{"enable":true},"image_zoom":{"enable":true,"img_url_replace":["",""]},"toc":{"enable":true,"placement":"right","headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":2},"lazyload":{"enable":true,"loading_img":"/img/loading.gif","onlypost":false,"offset_factor":2},"web_analytics":{"enable":true,"follow_dnt":true,"baidu":null,"google":null,"gtag":"G-1CPE7Q03HT","tencent":{"sid":null,"cid":null},"woyaola":null,"cnzz":null,"leancloud":{"app_id":null,"app_key":null,"server_url":null,"path":"window.location.pathname","ignore_local":false}},"search_path":"/local-search.xml"};

    if (CONFIG.web_analytics.follow_dnt) {
      var dntVal = navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack;
      Fluid.ctx.dnt = dntVal && (dntVal.startsWith('1') || dntVal.startsWith('yes') || dntVal.startsWith('on'));
    }
  </script>
  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>
  

  

  

  
    <!-- Google gtag.js -->
    <script async>
      if (!Fluid.ctx.dnt) {
        Fluid.utils.createScript('https://www.googletagmanager.com/gtag/js?id=G-1CPE7Q03HT', function() {
          window.dataLayer = window.dataLayer || [];
          function gtag(){dataLayer.push(arguments);}
          gtag('js', new Date());
          gtag('config', 'G-1CPE7Q03HT');
        });
      }
    </script>
  

  

  

  

  



  
<!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hexo-math@4.0.0/dist/style.css">
<!-- hexo injector head_end end --><meta name="generator" content="Hexo 5.3.0"><link rel="alternate" href="/atom.xml" title="Ký sự AI" type="application/atom+xml">
</head>


<body>
  

  <header>
    

<div class="header-inner" style="height: 70vh;">
  <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand" href="/">
      <strong>Ký sự AI</strong>
    </a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/">
                <i class="iconfont icon-home-fill"></i>
                <span>Home</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/">
                <i class="iconfont icon-archive-fill"></i>
                <span>Archives</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/">
                <i class="iconfont icon-category-fill"></i>
                <span>Categories</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/">
                <i class="iconfont icon-tags-fill"></i>
                <span>Tags</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/">
                <i class="iconfont icon-user-fill"></i>
                <span>About</span>
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search">
              <i class="iconfont icon-search"></i>
            </a>
          </li>
          
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle">
              <i class="iconfont icon-dark" id="color-toggle-icon"></i>
            </a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

  

<div id="banner" class="banner" parallax=true
     style="background: url('/images/possessed-photography-U3sOwViXhkY-unsplash.jpg') no-repeat center center; background-size: cover;">
  <div class="full-bg-img">
    <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.5)">
      <div class="banner-text text-center fade-in-up">
        <div class="h2">
          
            <span id="subtitle" data-typed-text="Triển khai GPT-J 6B Vietnamese News trên Docker và K8S"></span>
          
        </div>

        
          
  <div class="mt-3">
    
    
      <span class="post-meta">
        <i class="iconfont icon-date-fill" aria-hidden="true"></i>
        <time datetime="2022-12-28 11:28" pubdate>
          28 tháng 12 năm 2022
        </time>
      </span>
    
  </div>

  <div class="mt-1">
    

    
      <span class="post-meta mr-2">
        <i class="iconfont icon-clock-fill"></i>
        
        
        
          27 phút
        
      </span>
    

    
    
  </div>


        
      </div>

      
    </div>
  </div>
</div>

</div>

  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="side-col d-none d-lg-block col-lg-2">
      

    </div>

    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div id="board">
          <article class="post-content mx-auto">
            <!-- SEO header -->
            <h1 style="display: none">Triển khai GPT-J 6B Vietnamese News trên Docker và K8S</h1>
            
            
              <div class="markdown-body">
                
                <p>Thời gian gần đây đang nổi lên 1 con AI tên là ChatGPT có khả năng giao tiếp như người thật, biết làm thơ, viết luận văn, giải toán, dịch tiếng Anh sang tiếng Việt, ngay cả viết và đọc hiểu code. Thậm chí nó có thể “giả lập” máy ảo linux và “chat với 1 ChatGPT khác trong máy ảo đó” (Đọc thêm ở <a target="_blank" rel="noopener" href="https://www.engraved.blog/building-a-virtual-machine-inside/">đây</a>). Bản chất bên dưới của hệ thống này là 1 mô hình Generative Pre-trained Transformer 3 (GPT-3) với số lượng tham số khổng lồ (175 tỷ), chỉ riêng việc lưu mô hình này thôi cũng cần đến 800 GB! Ngay cả khi OpenAI công bố mô hình này cho cộng đồng thì cũng không thể tự sử dụng được với kinh phí khiêm tốn.</p>
<p>May mắn là có một mô hình GPT khác đến từ cộng đồng AI Việt Nam, tên là <a target="_blank" rel="noopener" href="https://huggingface.co/VietAI/gpt-j-6B-vietnamese-news">GPT-J 6B Vietnamese News</a>, được train bởi VietAI. Mô hình này chỉ có 6 tỷ tham số, đủ nhỏ để chạy trên những con GPU giá rẻ. Trong bài viết này, mình sẽ hướng dẫn cách triển khai mô hình này lên môi trường Docker và K8S, sử dụng thông qua API để lấy kết quả.</p>
<p>Link tới Github repo chứa code trong bài viết này: <a target="_blank" rel="noopener" href="https://github.com/duydvu/gpt-j-6B-vietnamese-news-api">https://github.com/duydvu/gpt-j-6B-vietnamese-news-api</a></p>
<p><escape><a id="more"></a></escape></p>
<h1 id="Load-va-chay-thu-mo-hinh"><a href="#Load-va-chay-thu-mo-hinh" class="headerlink" title="Load và chạy thử mô hình"></a>Load và chạy thử mô hình</h1><p>Trước khi chạy thử mô hình này, bạn cần đảm bảo đủ bộ nhớ GPU để load mô hình lên máy. Yêu cầu tối thiểu là khoảng 17 GB. Nếu bạn có nhiều hơn 1 GPU và tổng bộ nhớ nhiều hơn con số này thì vẫn có thể chạy được. Mình đã thử thành công trên 2 card GTX 1080Ti 12GB.</p>
<p>Bước đầu tiên là load tokenizer và tham số của mô hình:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer, AutoModelForCausalLM<br><br><span class="hljs-comment"># Load tokenizer</span><br>tokenizer = AutoTokenizer.from_pretrained(model_path)<br><br><span class="hljs-comment"># Load tham số mô hình</span><br>model = AutoModelForCausalLM.from_pretrained(model_path,<br>                                             torch_dtype=torch.float16,<br>                                             low_cpu_mem_usage=<span class="hljs-literal">True</span>)<br>model.parallelize() <span class="hljs-comment"># Chia nhỏ mô hình và phân bổ lên nhiều GPU để tránh bị lỗi OOM</span><br></code></pre></td></tr></table></figure>
<p>Trong đoạn code trên, mình thực hiện 2 phương pháp tối ưu:</p>
<ol>
<li>Sử dụng kiểu dữ liệu float16 thay vì float32 để giảm dung lượng bộ nhớ trên GPU. Vì float16 tương ứng với 2 byte còn float32 tới 4 byte nên tiết kiệm được 50% dung lượng.</li>
<li>Vì mô hình này vẫn rất lớn so với dung lượng bộ nhớ của các loại GPU phổ biến, nếu bạn có nhiều GPU thì có thể phân bổ các tham số của mô hình trên nhiều GPU thay vì chỉ chạy trên 1 con. Phương pháp này có tên là <strong>Model Parallel</strong>.</li>
</ol>
<p>Sau khi đã xong bước 1, chạy thử mô hình để kiểm tra xem có bị lỗi gì không:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># Convert đoạn text từ dạng string sang dãy số integer </span><br>input_ids = tokenizer.encode(<span class="hljs-string">&quot;Tiềm năng của trí tuệ nhân tạo&quot;</span>, return_tensors=<span class="hljs-string">&#x27;pt&#x27;</span>).to(<span class="hljs-string">&#x27;cuda:0&#x27;</span>)<br><br><span class="hljs-comment"># Chạy mô hình</span><br>outputs = model.generate(<br>  input_ids,<br>  max_length=<span class="hljs-number">256</span>,<br>  do_sample=<span class="hljs-literal">True</span>,<br>  top_k=<span class="hljs-number">50</span>,<br>  top_p=<span class="hljs-number">0.9</span>,<br>  num_return_sequences=<span class="hljs-number">1</span>,<br>)<br><br><span class="hljs-comment"># Decode kết quả của mô hình từ dãy số integer sang dạng string và in ra màn hình</span><br><span class="hljs-keyword">for</span> output <span class="hljs-keyword">in</span> outputs:<br>  <span class="hljs-built_in">print</span>(tokenizer.decode(output, skip_special_tokens=<span class="hljs-literal">True</span>))<br></code></pre></td></tr></table></figure>
<p>Vì thuật toán sinh văn bản mà mình đang sử dụng là lấy mẫu dựa trên xác suất nên sau mỗi lần chạy, mô hình sẽ cho ra kết quả khác nhau. Kết quả thu được trên máy của mình là:</p>
<figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs text">Tiềm năng của trí tuệ nhân tạo là rất lớn, nhiều ứng dụng có thể ra đời trong tương lai không xa, và điều đó đòi hỏi sự nỗ lực của cả cộng đồng.<br><br>Một điểm khác cần lưu ý là trí tuệ nhân tạo là một lĩnh vực phát triển hoàn toàn mới và không thể chỉ dựa vào mỗi việc nghiên cứu của các trường, viện mà phải kết hợp với các doanh nghiệp, và phải có sự kết nối mạnh mẽ với các doanh nghiệp.<br><br>Về việc chuẩn bị nhân lực cho cuộc cách mạng công nghiệp lần thứ 4, Phó Thủ tướng lưu ý các trường cần có sự đổi mới về cơ chế, phương pháp, mô hình dạy và học nhằm tạo môi trường tốt nhất cho trí tuệ nhân tạo.<br><br>&quot;Nếu cứ làm theo cách cũ thì các trường sẽ như &quot;rúc thóc&quot; vào bao, nhưng nếu áp dụng phương pháp mới mà các trường chưa có, mới ở giai đoạn đầu mà có quy mô lớn hơn nhiều lần thì sẽ rất khó khăn&quot;, Phó Thủ tướng chia sẻ.<br><br>Phó Thủ tướng Vũ Đức Đam đề nghị Bộ KH&amp;CN tiếp tục có sự phối hợp với các bộ, ngành, trước hết là Bộ KH&amp;CN xây dựng chiến lược, quy hoạch phát triển, thực hiện đề án tăng cường.<br></code></pre></td></tr></table></figure>
<p>Sau khi chạy thử thành công, mình viết lại đoạn code trên thành 1 class trong file <code>src/predictor.py</code> và đóng gói toàn bộ code bao gồm cả phần API server vào trong thư mục <code>src</code>.</p>
<h1 id="Tao-Docker-image"><a href="#Tao-Docker-image" class="headerlink" title="Tạo Docker image"></a>Tạo Docker image</h1><p>Để build được Docker, trước hết bạn cần phải tải mô hình về máy theo các bước sau:</p>
<ol>
<li>Cài đặt <a target="_blank" rel="noopener" href="https://git-lfs.com/">git-lfs</a></li>
<li>Chạy lệnh <code>git clone https://huggingface.co/VietAI/gpt-j-6B-vietnamese-news</code></li>
</ol>
<p>Lệnh clone sẽ tải mô hình về và đặt ở thư mục hiện tại trên terminal.</p>
<p>Sau khi tải xong, dùng lệnh <code>mv</code> để đưa thư mục vừa clone về vào thư mục của repo API:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">mv</span> ./gpt-j-6B-vietnamese-news ./gpt-j-6B-vietnamese-news-api<br></code></pre></td></tr></table></figure>
<p>Cuối cùng là dùng lệnh <code>build</code> Docker image:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">docker build -t gpt-j .<br></code></pre></td></tr></table></figure>
<p>Tiến hành chạy thử bằng việc tạo 1 container và map tới port 5000 của máy:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">docker run -it --<span class="hljs-built_in">rm</span> -p 5000:5000 gpt-j<br></code></pre></td></tr></table></figure>
<p>Gọi thử bằng lệnh <code>curl</code>:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs bash">curl --location --request POST <span class="hljs-string">&#x27;http://localhost:5000/predict&#x27;</span> \<br>  --header <span class="hljs-string">&#x27;Content-Type: application/json&#x27;</span> \<br>  --data-raw <span class="hljs-string">&#x27;&#123;</span><br><span class="hljs-string">    &quot;text&quot;: &quot;Tiềm năng của trí tuệ nhân tạo&quot;,</span><br><span class="hljs-string">    &quot;n_samples&quot;: 1</span><br><span class="hljs-string">  &#125;&#x27;</span><br></code></pre></td></tr></table></figure>
<h1 id="Trien-khai-len-moi-truong-K8S-voi-Helm-Chart"><a href="#Trien-khai-len-moi-truong-K8S-voi-Helm-Chart" class="headerlink" title="Triển khai lên môi trường K8S với Helm Chart"></a>Triển khai lên môi trường K8S với Helm Chart</h1><h2 id="Mot-chut-phan-tich"><a href="#Mot-chut-phan-tich" class="headerlink" title="Một chút phân tích"></a>Một chút phân tích</h2><p>Trong bài viết này, mình chọn Google Cloud Platform (GCP) là nhà cung cấp dịch vụ cloud để triển khai mô hình lên K8S vì mình thường xuyên dùng GCP trong công việc. Dù vậy, nếu bạn có sử dụng nhà cung cấp khác thì cũng không thành vấn đề, quan trọng là họ có GPU cho K8S là được.</p>
<p>Sau khi nghiên cứu các mức giá GPU của GCP, mình quyết định chọn Nvidia T4 bởi 2 tiêu chí:</p>
<ol>
<li>Mức giá - giá thuê hàng tháng của T4 là gần 180 USD, nếu dùng spot VM thì giá chỉ còn 80 USD, cộng với chi phí của CPU, RAM và disk thì khoảng 90 USD, thấp thứ 2 chỉ sau dòng K80.</li>
<li>Tốc độ xử lý - Lý do mình không chọn K80 là vì nó không hỗ trợ FP16 (<a target="_blank" rel="noopener" href="https://docs.nvidia.com/deeplearning/tensorrt/support-matrix/index.html#hardware-precision-matrix">nguồn tham khảo</a>), giúp giảm bộ nhớ cũng như tăng tốc độ chạy mô hình.</li>
</ol>
<p>Với dung lượng 16 GB, cần tới 2 card T4 thì mới có thể chạy được mô hình GPT-J này. Như vậy chi phí hàng tháng nếu duy trì liên tục là 90 x 2=180 USD. Nếu chỉ thỉnh thoảng chạy thì chi phí sẽ còn thấp hơn nữa.</p>
<h2 id="Bat-dau-trien-khai"><a href="#Bat-dau-trien-khai" class="headerlink" title="Bắt đầu triển khai"></a>Bắt đầu triển khai</h2><p>Helm là một công cụ rất tuyệt vời cho việc đóng gói ứng dụng mà chúng ta vừa tạo để đưa lên K8S. Mình đã tạo Helm Chart và để trong thư mục <code>k8s/chart</code>. Chart này bao gồm 2 thành phần:</p>
<ol>
<li>Deployment: Tạo deployment chứa pod chạy container gpt-j.</li>
<li>Service: Tạo service kết nối tới pod trong deployment ở trên.</li>
</ol>
<p>Trong phần deployment có 2 phần quan trọng cần lưu ý, một là:</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs YAML"><span class="hljs-attr">strategy:</span><br>  <span class="hljs-attr">rollingUpdate:</span><br>    <span class="hljs-attr">maxSurge:</span> <span class="hljs-number">0</span><br>    <span class="hljs-attr">maxUnavailable:</span> <span class="hljs-number">1</span><br>  <span class="hljs-attr">type:</span> <span class="hljs-string">RollingUpdate</span><br></code></pre></td></tr></table></figure>
<p>Mặc định trong K8S khi cập nhật deployment thì sẽ tạo thêm 1 pod mới chạy song song với pod cũ, nhưng trong trường hợp này mình chỉ có đủ GPU để chạy cho 1 pod nên K8S sẽ không thể thay thế được pod cũ vì không có GPU để chạy pod mới. Vì vậy mình thay đổi strategy để khi cập nhật deployment thì K8S sẽ xóa pod cũ trước khi tạo pod mới. Như vậy thì sẽ không bị hiện tượng trên, nhưng sẽ bị vấn đề khác là xảy ra downtime trong quá trình deploy.</p>
<p>Hai là:</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs YAML"><span class="hljs-attr">resources:</span><br>  <span class="hljs-attr">requests:</span><br>    <span class="hljs-attr">cpu:</span> <span class="hljs-string">500m</span><br>    <span class="hljs-attr">memory:</span> <span class="hljs-string">8000Mi</span><br>    <span class="hljs-attr">nvidia.com/gpu:</span> <span class="hljs-string">&quot;2&quot;</span><br>  <span class="hljs-attr">limits:</span><br>    <span class="hljs-attr">memory:</span> <span class="hljs-string">16000Mi</span><br>    <span class="hljs-attr">nvidia.com/gpu:</span> <span class="hljs-string">&quot;2&quot;</span><br></code></pre></td></tr></table></figure>
<p>Có 2 dòng quan trọng là <code>nvidia.com/gpu: &quot;2&quot;</code> dùng để cấp phát tài nguyên GPU cho pod. Bắt buộc phải có 2 dòng này thì pod mới có thể dùng GPU được. Một điểm trừ là hiện tại GCP chỉ cho phép 1 GPU được cấp phát tới 1 pod nên nhiều pod không thể chia sẽ cùng 1 GPU được. Nếu có nhiều mô hình khác cần dùng tới GPU thì tốt nhất bạn nên dùng các giải pháp chạy mô hình tập trung như <a target="_blank" rel="noopener" href="https://github.com/triton-inference-server/server">Triton</a> để có thể chạy nhiều mô hình trên cùng 1 GPU.</p>
<p>Bước cuối cùng là cài đặt Helm Chart này lên K8S thông qua lệnh sau:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">helm install --<span class="hljs-built_in">set</span> namespace=default --<span class="hljs-built_in">set</span> image=gpt-j --<span class="hljs-built_in">set</span> version=latest gpt-j ./k8s/chart<br></code></pre></td></tr></table></figure>
<p>Như vậy là chúng ta đã thành công trong việc triển khai GPT-J lên K8S rồi đó. Chúc bạn cũng thành công như mình nhé!</p>

                
              </div>
            
            <hr/>
            <div>
              <div class="post-metas my-3">
  
  
    <div class="post-meta">
      <i class="iconfont icon-tags"></i>
      
        <a href="/tags/Machine-Learning/">#Machine Learning</a>
      
        <a href="/tags/Deep-Learning/">#Deep Learning</a>
      
        <a href="/tags/Artificial-Intelligence/">#Artificial Intelligence</a>
      
        <a href="/tags/Docker/">#Docker</a>
      
        <a href="/tags/GPT-J/">#GPT-J</a>
      
        <a href="/tags/K8S/">#K8S</a>
      
        <a href="/tags/Natural-Language-Generation/">#Natural Language Generation</a>
      
        <a href="/tags/Language-Model/">#Language Model</a>
      
    </div>
  
</div>


              
  

  <div class="license-box my-3">
    <div class="license-title">
      <div>Triển khai GPT-J 6B Vietnamese News trên Docker và K8S</div>
      <div>https://www.kysuai.com/2022/12/28/Trien-khai-GPT-J-6B-Vietnamese-News-tren-Docker-va-K8S/</div>
    </div>
    <div class="license-meta">
      
        <div class="license-meta-item">
          <div>Tác giả</div>
          <div>Vũ Đức Duy</div>
        </div>
      
      
        <div class="license-meta-item license-meta-date">
          <div>Đăng vào</div>
          <div>28 tháng 12 năm 2022</div>
        </div>
      
      
      
        <div class="license-meta-item">
          <div>Licensed under</div>
          <div>
            
              
              
                <a target="_blank" href="https://creativecommons.org/licenses/by/4.0/">
                  <span class="hint--top hint--rounded" aria-label="BY - Attribution">
                    <i class="iconfont icon-by"></i>
                  </span>
                </a>
              
            
          </div>
        </div>
      
    </div>
    <div class="license-icon iconfont"></div>
  </div>



              
                <div class="post-prevnext my-3">
                  <article class="post-prev col-6">
                    
                    
                      <a href="/2023/01/26/Trien-khai-Triton-Inference-Server-tren-Google-Kubernetes-Engine/" title="Triển khai Triton Inference Server trên Google Kubernetes Engine">
                        <i class="iconfont icon-arrowleft"></i>
                        <span class="hidden-mobile">Triển khai Triton Inference Server trên Google Kubernetes Engine</span>
                        <span class="visible-mobile">Trước</span>
                      </a>
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="/2021/01/10/Cau-hinh-GPU-trong-Docker/" title="Cấu hình GPU trong Docker">
                        <span class="hidden-mobile">Cấu hình GPU trong Docker</span>
                        <span class="visible-mobile">Sau</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
          </article>
        </div>
      </div>
    </div>

    <div class="side-col d-none d-lg-block col-lg-2">
      
  <aside class="sidebar" style="margin-left: -1rem">
    <div id="toc">
  <p class="toc-header">
    <i class="iconfont icon-list"></i>
    <span>Mục lục</span>
  </p>
  <div class="toc-body" id="toc-body"></div>
</div>



  </aside>


    </div>
  </div>
</div>





  



  



  



  



  







    

    
      <a id="scroll-top-button" aria-label="TOP" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">Tìm kiếm</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v" for="local-search-input">Từ khóa</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>

    

    
  </main>

  <footer>
    <div class="footer-inner">
  
    <div class="footer-content">
       <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a> 
    </div>
  
  
  
  
</div>

  </footer>

  <!-- Scripts -->
  
  <script  src="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://lib.baomitu.com/jquery/3.6.0/jquery.min.js" ></script>
<script  src="https://lib.baomitu.com/twitter-bootstrap/4.6.1/js/bootstrap.min.js" ></script>
<script  src="/js/events.js" ></script>
<script  src="/js/plugins.js" ></script>


  <script  src="https://lib.baomitu.com/typed.js/2.0.12/typed.min.js" ></script>
  <script>
    (function (window, document) {
      var typing = Fluid.plugins.typing;
      var subtitle = document.getElementById('subtitle');
      if (!subtitle || !typing) {
        return;
      }
      var text = subtitle.getAttribute('data-typed-text');
      
        typing(text);
      
    })(window, document);
  </script>




  
    <script  src="/js/img-lazyload.js" ></script>
  




  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/tocbot/4.18.2/tocbot.min.js', function() {
    var toc = jQuery('#toc');
    if (toc.length === 0 || !window.tocbot) { return; }
    var boardCtn = jQuery('#board-ctn');
    var boardTop = boardCtn.offset().top;

    window.tocbot.init(Object.assign({
      tocSelector     : '#toc-body',
      contentSelector : '.markdown-body',
      linkClass       : 'tocbot-link',
      activeLinkClass : 'tocbot-active-link',
      listClass       : 'tocbot-list',
      isCollapsedClass: 'tocbot-is-collapsed',
      collapsibleClass: 'tocbot-is-collapsible',
      scrollSmooth    : true,
      includeTitleTags: true,
      headingsOffset  : -boardTop,
    }, CONFIG.toc));
    if (toc.find('.toc-list-item').length > 0) {
      toc.css('visibility', 'visible');
    }

    Fluid.events.registerRefreshCallback(function() {
      if ('tocbot' in window) {
        tocbot.refresh();
        var toc = jQuery('#toc');
        if (toc.length === 0 || !tocbot) {
          return;
        }
        if (toc.find('.toc-list-item').length > 0) {
          toc.css('visibility', 'visible');
        }
      }
    });
  });
</script>


  <script src=https://lib.baomitu.com/clipboard.js/2.0.11/clipboard.min.js></script>

  <script>Fluid.plugins.codeWidget();</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/anchor-js/4.3.1/anchor.min.js', function() {
    window.anchors.options = {
      placement: CONFIG.anchorjs.placement,
      visible  : CONFIG.anchorjs.visible
    };
    if (CONFIG.anchorjs.icon) {
      window.anchors.options.icon = CONFIG.anchorjs.icon;
    }
    var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
    var res = [];
    for (var item of el) {
      res.push('.markdown-body > ' + item.trim());
    }
    if (CONFIG.anchorjs.placement === 'left') {
      window.anchors.options.class = 'anchorjs-link-left';
    }
    window.anchors.add(res.join(', '));

    Fluid.events.registerRefreshCallback(function() {
      if ('anchors' in window) {
        anchors.removeAll();
        var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
        var res = [];
        for (var item of el) {
          res.push('.markdown-body > ' + item.trim());
        }
        if (CONFIG.anchorjs.placement === 'left') {
          anchors.options.class = 'anchorjs-link-left';
        }
        anchors.add(res.join(', '));
      }
    });
  });
</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js', function() {
    Fluid.plugins.fancyBox();
  });
</script>


  <script>Fluid.plugins.imageCaption();</script>

  <script  src="/js/local-search.js" ></script>





<!-- 主题的启动项，将它保持在最底部 -->
<!-- the boot of the theme, keep it at the bottom -->
<script  src="/js/boot.js" ></script>


  

  <noscript>
    <div class="noscript-warning">Blog works best with JavaScript enabled</div>
  </noscript>
</body>
</html>
