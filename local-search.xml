<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>Drafting the high-level architecture of future AI agents</title>
    <link href="/2023/11/22/Drafting-the-high-level-architecture-of-future-AI-agents/"/>
    <url>/2023/11/22/Drafting-the-high-level-architecture-of-future-AI-agents/</url>
    
    <content type="html"><![CDATA[<p>Inspired by Bill Gates’s recent article <a href="https://www.gatesnotes.com/AI-agents">The Future of Agents</a>, I have been thinking about how AI agents will transform our lives in the near future. As Bill Gates said, everyone will have a virtual personal assistant that does things by telling them in everyday language. They can do any task on your device for you, from writing &amp; sending an email to placing an order on Amazon.</p><p>This sounds like science fiction, but with the current development of Large Language Models (LLMs) such as GPT-4, and Llama, I too believe that we will have AI agents that can do most of the tasks in our daily lives (on a computer) in the next 5-10 years. In this article, I will try to sketch my vision of how these agents will work.</p><h1 id="AI-agents-of-today"><a href="#AI-agents-of-today" class="headerlink" title="AI agents of today"></a>AI agents of today</h1><p>Today, with ChatGPT &amp; GPT-4 API, you can build a bot that can write an email to send to your clients, import data from PDF to Google Sheets, and write HTML code from a website screenshot. All you have to do is command them to do the task via a UI, or more advanced - speak to them. These applications can be installed on your smartphone with an internet connection.</p><p>Another method is using open-sourced LLM such as Llama or Mistral hosted on your powerful PC. These models might not be as good as the commercial competitors, but they will keep getting better and better over time, as well as the hardware will become more powerful and less expensive. So soon, intelligent LLMs will become lightweight enough to run on your smartphone or laptop.</p><p>These AI agents are capable of working with a given set of “tools”, for example, web search, code interpreter, and APIs. They can only do a task if you give them the tools they need to accomplish it. So when you say to them: “Send an email for me”, they will happily do it because Gmail is such a popular platform that it must be one of the basic integrations.</p><p>But when you say to them: “Write an article about the future of AI agents on Substack”, can they do this? Well, of course, they cannot if they don’t know how to call the API of Substack unless you have already integrated them with Substack, which should take some effort. Even so, you will have to guide them on which API to call for which task and how to call them.</p><pre><code class=" mermaid">sequenceDiagram    actor User    participant AI as AI agentparticipant GM as Gmailparticipant St as Substack    User-&gt;&gt;+AI: &quot;Send an email for me&quot;    AI--)User: &quot;Roger that!&quot;    AI--)+GM: send_email(content, recipient)AI-&gt;&gt;-User: &quot;Done&quot;User-&gt;&gt;+AI: &quot;Write an article about the future of AI agents on Substack&quot;AI-&gt;&gt;-User: &quot;Ugh... How do I do that?&quot;</code></pre><p>How about integrating all platforms first then? Would you want to write on Substack forever?  There will always be alternatives for everything, so this is not an option. Therefore, <strong>the AI agent of today can only work with a specific set of “tools” that it knows “how to use” them</strong>.</p><p>Another problem of the current generation of AI agents is they can’t do complex tasks such as planning a trip for your vacation, which would require multiple skills in time management, expense management, and knowledge about locations &amp; weather. Sure, GPT-4 might have the ability to do it with some plugins but the majority of the LLM landscape still cannot.</p><p>In fact, there have been many studies conducted by AI researchers on the planning capability of LLMs, one of which is the paper <a href="https://arxiv.org/abs/2206.10498">“Large Language Models Still Can’t Plan (A Benchmark for LLMs on Planning and Reasoning about Change)”</a>, which showed that <strong>LLMs still can’t plan, for now</strong>.</p><h1 id="AI-agents-of-the-future"><a href="#AI-agents-of-the-future" class="headerlink" title="AI agents of the future"></a>AI agents of the future</h1><p>Imagine in the next few years, you are watching a movie and someone just sent a message to you. Too lazy to grab the phone, you simply say “I’m busy now” to your personal assistant on your phone. The assistant will carry the message to the sender and you can keep watching your favorite movie without being distracted. Sound cool, right?</p><p>Not only that, they can do tasks with more complexity than they can today, just as shown in Bill Gates’s article. All within a single device, an internet connection is not mandatory unless you are interacting with some platforms from the internet.</p><p>The most interesting part is that now, <strong>the AI agents can interact with any “tools” that we command them to use</strong>.</p><p>You can tell the agent to place an order on an e-commerce website you just visited, even though the agent doesn’t have any prior knowledge of the website.</p><p>You can also tell them to write an article on a platform you just registered, without having to integrate them into your agent.</p><p>This can be done by 2 methods:</p><ol><li>Give an instruction on how to use the tool - <strong>Agents talk to Systems</strong></li><li>Talk to another agent responsible for interacting with the tool - <strong>Agents talk to Agents</strong></li></ol><p>Before diving into each method, let’s consider an analogous example.</p><p>Imagine you are the owner of a small factory with many machines, you are also the only operator of the factory. You know how to use every machine in the factory. One day, you decide that you will not operate the factory anymore, but hire a personal assistant to do that for you. The newly hired assistant will now have to be able to operate the factory.</p><p>In this example:</p><ul><li>The hired assistant represents your AI agent</li><li>The machine represents the tools your AI agent interacts with</li></ul><p>With these analogies, let’s dive in.</p><h1 id="Agents-talk-to-Systems"><a href="#Agents-talk-to-Systems" class="headerlink" title="Agents talk to Systems"></a>Agents talk to Systems</h1><p>When the assistant operates the machines (the AI agent interacts with the tools), they must first know how to use them. One way is to give the assistant an instruction manual for the machine.</p><p>To understand the manual, the assistant must also have fundamental knowledge such as how to read technical instructions and understand the technical terms &amp; definitions. By doing this, the assistant will know how to operate the machine properly.</p><p>Mapping to our scenario, in the previous example where the AI agent can’t understand the request “Write an article about the future of AI agents on Substack”, it can now learn how to use the APIs with the instructions provided by Substack. It reads the instructions, selects the appropriate endpoint, and sends the request.</p><pre><code class=" mermaid">sequenceDiagram    actor User    participant AI as AI agentparticipant St as SubstackUser-&gt;&gt;+AI: &quot;Write an article about the future of AI agents on Substack&quot;AI--)User: &quot;Will do!&quot;AI-&gt;&gt;+St: Give me your instructionSt--)AI: Here they areAI-&gt;&gt;St: POST /articlesSt--)-AI: 200AI--)-User: &quot;Done&quot;</code></pre><p>So what kind of instructions can be understood by AI? <a href="https://swagger.io/specification/">OpenAPI Specification</a> might be a good candidate if the APIs are well designed. But I don’t think it would be enough for AI to understand completely on any platform.</p><p>Sometimes, APIs are not called individually but in a specific order to get things done such as OAuth or creating a cart with multiple items. So there should be a better way to instruct AI to use the APIs, an “API of the API”, but it doesn’t exist yet.</p><p>It could be something like this:</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs yaml"><span class="hljs-attr">name:</span> <span class="hljs-string">Substack</span> <span class="hljs-string">API</span><br><span class="hljs-attr">version:</span> <span class="hljs-number">1.0</span><span class="hljs-number">.0</span><br><span class="hljs-attr">openapi:</span> <span class="hljs-string">&lt;openapi-spec&gt;</span><br><span class="hljs-attr">tasks:</span><br>  <span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">Post</span> <span class="hljs-string">an</span> <span class="hljs-string">article</span><br>    <span class="hljs-attr">actions:</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">Login</span><br>        <span class="hljs-attr">action:</span> <span class="hljs-string">POST</span> <span class="hljs-string">/login</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">Create</span> <span class="hljs-string">an</span> <span class="hljs-string">article</span><br>        <span class="hljs-attr">action:</span> <span class="hljs-string">POST</span> <span class="hljs-string">/articles</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">Publish</span> <span class="hljs-string">the</span> <span class="hljs-string">article</span><br>        <span class="hljs-attr">action:</span> <span class="hljs-string">POST</span> <span class="hljs-string">/articles/:id/publish</span><br></code></pre></td></tr></table></figure><p>When the AI agent reads this, it will know the execution order of the API calls to post an article.</p><p>So my prediction is that <strong>there will be a new standard similar to OpenAPI Specification that allows AI to understand how to interact with a software system</strong>. SaaS providers must implement the standard if they want the users’ AI agent to interact with their platform.</p><h1 id="Agents-talk-to-Agents"><a href="#Agents-talk-to-Agents" class="headerlink" title="Agents talk to Agents"></a>Agents talk to Agents</h1><p>In the first method, your assistant can learn how to operate the machine by reading its instruction manual. But what if the machine is so sophisticated that only you or someone with specific knowledge can operate it?</p><p>We haven’t had AGI yet, and I believe there is still a long way before reaching it. So at the moment, let’s assume that AI agents cannot be good at any tasks we give to them.</p><p>There will be many AI agents that are specialists in different fields. There will be an AI agent for personal assistant. In an online store, an AI agent will guide you through the products and give recommendations based on your interests. There will be an AI agent specializing in diagnostics to check your health once in a while.</p><p>So when the assistant cannot understand how to operate the machine, what can they do?</p><p>It’s easy, just hire another operator who knows how to do it. This time, the assistant only needs to give the request to the operator and they will do the rest. If the task you gave the assistant involves many machines, the assistant will separate the task into many subtasks atomically, each of which only requires one machine. The assistant then assigns the subtasks to the machine and only cares about the input &amp; output of the machines. All the details are handled by the operators. The assistant’s job becomes more like a project manager.</p><p>Mapping to our scenario, instead of letting your AI agent learn how to use the APIs before interacting with Substack, it only has to interact with another AI agent trained specifically for working with Substack’s APIs. Your AI agent will provide your identity and the content of the article and the Substack AI agent will do the rest.</p><pre><code class=" mermaid">sequenceDiagram    actor User    participant AI as Personal AI agentparticipant SAI as Substack AI agentparticipant St as SubstackUser-&gt;&gt;+AI: &quot;Write an article about the future of AI agents on Substack&quot;AI--)User: &quot;Will do!&quot;AI-&gt;&gt;+SAI: Hello, could you post an article for &lt;user&gt;?SAI--)AI: Okay, just give me the content.AI-&gt;&gt;SAI: &lt;content&gt;SAI-&gt;&gt;+St: POST /articlesSt--)SAI: 200SAI--)-AI: &quot;Done&quot;AI--)-User: &quot;Done&quot;</code></pre><p>Here is a more complex task that your AI agent might not be able to handle alone. You are a business owner who uses many services to manage your customers on an online store such as E-commerce service and CRM service.</p><p>If you want to create a coupon in the E-commerce service and then send it to your customers in the CRM service, you would have to do it by hand. The time it takes for this process depends on how deep the integration between the 2 services is, but in the end, it still takes some effort.</p><p>Instead, you give the request to your AI agent and it will talk to the respective AI agents to accomplish the task.</p><pre><code class=" mermaid">sequenceDiagram    actor A as Admin    participant PVA as Personal AI agent    participant EVA as E-commerce AI agent    participant E-commerce    participant CVA as CRM AI agent    participant CRM    A-&gt;&gt;+PVA: &quot;Create a coupon and send it to my customers via email&quot;    PVA--)A: &quot;Roger that!&quot;    PVA-&gt;&gt;+EVA: &quot;Create a coupon&quot;    EVA-&gt;&gt;+E-commerce: create_coupon()    E-commerce--)-EVA: Coupon ID    EVA--)-PVA: &quot;Coupon ID: xxxx&quot;    PVA-&gt;&gt;+CVA: &quot;Send coupon with ID xxxx to my customers&quot;    CVA-)+CRM: send_coupon_by_email(coupon_id)    deactivate CRM    CVA--)-PVA: &quot;Done!&quot;    PVA--)-A: &quot;Done!&quot;</code></pre><p>With this architecture, each AI agent doesn’t have to know everything, it only needs to know one job and do it well. This is somewhat similar to the microservice architecture in software, should I call it “micro-AI” architecture? Notion AI, Github Copilot Chat can be considered as a draft version of this kind.</p><p>This approach also comes with a price. In the example, you will have to pay a salary for every operator you hire. The more operators you have, the bigger the cost.</p><p>Another problem is who is going to build these micro-AIs. You, the companies, or the community?</p><p>If it is the companies that build the micro-AIs, the biggest issue is that it will cost a fortune for anyone other than the rich companies to build and operate them. Imagine running a micro-AI that handles 10 million requests per day, assume each request costs $0.003 (equal to 1K input tokens + 1K output tokens to ChatGPT API). It would cost $30,000 per day or $900,000 per month to run. This is something not many companies can afford.</p><p>You? Never!</p><p>The community? Maybe. The community has been an integral part of many ecosystems, from the App Store, Google Play Store, and Steam to Github, Shopify, and GPTs. There could be a new ecosystem where anyone can upload their AI agents for everyone to use, commercially or non-commercially.</p><h1 id="Which-one-will-be-the-future"><a href="#Which-one-will-be-the-future" class="headerlink" title="Which one will be the future?"></a>Which one will be the future?</h1><p>The above 2 methods have their advantages and disadvantages. Let’s summarize it:</p><table><thead><tr><th></th><th>Pros</th><th>Cons</th></tr></thead><tbody><tr><td>Agents talk to Systems</td><td>Only need one agent per user</td><td>The agent might not interact well with all systems</td></tr><tr><td>Agents talk to Agents</td><td>Each agent only needs to know one job and do it well</td><td>Costly to build &amp; operate</td></tr></tbody></table><p>The winner of this race depends heavily on the process of developing AGI. If AGI is still far to come, “Agents talk to Agents” will get ahead first, but they won’t be widely adopted due to cost considerations unless a new ecosystem appears just as I said earlier. Otherwise, “Agents talk to Systems” will win.</p><p>At the end of the road, “Agents talk to Systems” will still win.</p><p>My reasoning is that if you, who are a human, can already do the tasks on your own without any help, your AI agent will eventually be able to do so. AI will one day do anything that we can do and even surpass us. The assistant in our example will finally operate the factory on their own without any operators.</p><p>This doesn’t mean that your AI agent will not talk to your friend’s AI agent. It is just how they interact with a software system. After the Internet, the “Internet of Things” emerged, then comes the “Internet of Everything” (for physical devices), will there be an “Internet of …Agents”?</p><h1 id="Internet-of-…Agents"><a href="#Internet-of-…Agents" class="headerlink" title="Internet of …Agents?"></a>Internet of …Agents?</h1><p><img src="/2023/11/22/Drafting-the-high-level-architecture-of-future-AI-agents/internet-of-agents.jpeg" alt="Internet of Agents - Drawn by Bing Image Creator"></p><p>A new network where each node is not a computer but an agent and the agents contact each other via the Internet’s infrastructure. If you want to contact your friend but they are busy, you simply let your agent talk to their agent, and they will arrange a meeting for you and your friend.</p><p>There are 2 ways for the agents to contact each other:</p><ol><li>Directly, like calling by phone number.</li><li>Indirectly via a third-party broker, like Gmail or Messenger.</li></ol><p>When talking directly, they must first find where the other one is, similar to how you must know your friend’s phone number before calling them. If the other end is not connected to the Internet, the message will not be received. This is a peer-to-peer connection so encryption must be taken seriously, you must have your friend’s public key first before contacting them, or someone else may pretend to be your friend to talk to you.</p><p>On the other hand, if the agents talk to each other via a broker, all messages are stored in that broker. The agents can send messages asynchronously, and then check again if the other one has replied later.</p><pre><code class=" mermaid">sequenceDiagram    participant A as Agent Aparticipant Broker    participant B as Agent B    A-)Broker: &quot;Hello!&quot;B-)Broker: &quot;Hi!&quot;A-)Broker: &quot;Let&#x27;s arrange a meeting.&quot;B-)Broker: &quot;Okay! When?&quot;</code></pre><p>Given the popularity of today’s third-party services, I think they will again be the dominant communication method. A new hub will appear where your agent will send and receive messages from other agents. Or maybe, some familiar platforms will someday introduce a new feature to support your agent, it can be Messenger, Telegram, or something else.</p><p>In either way, it will be a huge risk if the agents are not self-guarded. Computers can be hacked to become a bot in a botnet for a DDOS attack. Similarly, today’s AI can be tricked into producing harmful content. If a malicious actor can behave like an agent and manipulate other agents using just natural language, they can become a dangerous army. Since the future agents will be able to do much more than generating texts, they may do damage to the real world, much worse than a DDOS attack.</p><h1 id="Final-thoughts"><a href="#Final-thoughts" class="headerlink" title="Final thoughts"></a>Final thoughts</h1><p>The future of AI agents is both exciting and worrying. On the one hand, they will revolutionize the way we live &amp; the way we work like the way smartphones did. On the other hand, they also open new doors for bad actors, criminals will have new tools to harm society. Therefore, it’s crucial to control this technology in the hands of the right people and mitigate the downside of it. One things is certain, AI agents will become one of the most important inventions of humankind.</p><p>In the next few years, we will see the first generation of AI agents living inside your devices that can do basic tasks with a limited set of tools. Then, the second generation will do more complex tasks with an open set of tools. And more will come.</p>]]></content>
    
    
    
    <tags>
      
      <tag>Artificial Intelligence</tag>
      
      <tag>AI agent</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Các công thức cần nhớ cho mô hình Transformer</title>
    <link href="/2023/10/27/Cac-cong-thuc-can-nho-cho-mo-hinh-Transformer/"/>
    <url>/2023/10/27/Cac-cong-thuc-can-nho-cho-mo-hinh-Transformer/</url>
    
    <content type="html"><![CDATA[<h1 id="Tinh-so-luong-tham-so"><a href="#Tinh-so-luong-tham-so" class="headerlink" title="Tính số lượng tham số"></a>Tính số lượng tham số</h1><h2 id="Cong-thuc-“gan”-chinh-xac"><a href="#Cong-thuc-“gan”-chinh-xac" class="headerlink" title="Công thức “gần” chính xác"></a>Công thức “gần” chính xác</h2><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>P</mi><mo>=</mo><mi>V</mi><mi>H</mi><mo>+</mo><mi>L</mi><mo stretchy="false">(</mo><mn>12</mn><msup><mi>H</mi><mn>2</mn></msup><mo>+</mo><mn>13</mn><mi>H</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">P = VH + L(12H^2 + 13H)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.76666em;vertical-align:-0.08333em;"></span><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="mord mathnormal" style="margin-right:0.08125em;">H</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1.1141079999999999em;vertical-align:-0.25em;"></span><span class="mord mathnormal">L</span><span class="mopen">(</span><span class="mord">1</span><span class="mord">2</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.08125em;">H</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8641079999999999em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">1</span><span class="mord">3</span><span class="mord mathnormal" style="margin-right:0.08125em;">H</span><span class="mclose">)</span></span></span></span></span><p>Trong đó:</p><ul><li>P: số lượng tham số của mô hình</li><li>V: số lượng từ trong từ điển</li><li>H: số chiều của hidden state</li><li>L: số lượng layer</li></ul><p>Công thức này “gần” chính xác vì nó không tính đến số lượng tham số của các layer normalization và các layer khác. Hơn nữa, các LLM hiện nay có 1 số thay đổi nhỏ trên kiến trúc gốc của Transformer (LLaMA, GPT) nên kết quả của công thức này cũng không chính xác 100%.</p><p>Ví dụ với mô hình <a href="https://github.com/VinAIResearch/PhoBERT">PhoBERT-base</a></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoModel<br>model = AutoModel.from_pretrained(<span class="hljs-string">&#x27;vinai/phobert-base&#x27;</span>)<br><span class="hljs-built_in">sum</span>(p.numel() <span class="hljs-keyword">for</span> p <span class="hljs-keyword">in</span> model.parameters())<br></code></pre></td></tr></table></figure><p>Chạy đoạn code trên sẽ cho ta con số chính xác là 134 998 272.</p><p>Áp dụng công thức trên với V = 64001, H = 768, L = 12:</p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>P</mi><mo>=</mo><mn>64001</mn><mo>∗</mo><mn>768</mn><mo>+</mo><mn>12</mn><mo>∗</mo><mo stretchy="false">(</mo><mn>12</mn><mo>∗</mo><mn>76</mn><msup><mn>8</mn><mn>2</mn></msup><mo>+</mo><mn>13</mn><mo>∗</mo><mn>768</mn><mo stretchy="false">)</mo><mo>=</mo><mn>134207232</mn></mrow><annotation encoding="application/x-tex">P = 64001 * 768 + 12 * (12 * 768^2 + 13 * 768) = 134207232</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">6</span><span class="mord">4</span><span class="mord">0</span><span class="mord">0</span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.72777em;vertical-align:-0.08333em;"></span><span class="mord">7</span><span class="mord">6</span><span class="mord">8</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span><span class="mord">2</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord">1</span><span class="mord">2</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.9474379999999999em;vertical-align:-0.08333em;"></span><span class="mord">7</span><span class="mord">6</span><span class="mord"><span class="mord">8</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8641079999999999em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span><span class="mord">3</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">7</span><span class="mord">6</span><span class="mord">8</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span><span class="mord">3</span><span class="mord">4</span><span class="mord">2</span><span class="mord">0</span><span class="mord">7</span><span class="mord">2</span><span class="mord">3</span><span class="mord">2</span></span></span></span></span><p>Như vậy thì con số chính xác cao hơn kết quả của công thức 791 040 tham số, tương đương 0.58% tỷ lệ sai số.</p><h2 id="Cong-thuc-xap-xi"><a href="#Cong-thuc-xap-xi" class="headerlink" title="Công thức xấp xỉ"></a>Công thức xấp xỉ</h2><p>Đối với các LLM với hàng tỷ tham số như hiện nay thì <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>H</mi><mn>2</mn></msup></mrow><annotation encoding="application/x-tex">H^2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141079999999999em;vertical-align:0em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.08125em;">H</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span> lớn hơn nhiều so với <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>H</mi></mrow><annotation encoding="application/x-tex">H</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.08125em;">H</span></span></span></span> nên ta có thể đơn giản hoá công thức trên để tính xấp xỉ như sau:</p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>P</mi><mo>=</mo><mn>12</mn><mi>L</mi><msup><mi>H</mi><mn>2</mn></msup></mrow><annotation encoding="application/x-tex">P = 12LH^2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.8641079999999999em;vertical-align:0em;"></span><span class="mord">1</span><span class="mord">2</span><span class="mord mathnormal">L</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.08125em;">H</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8641079999999999em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span></span><p>Nếu áp dụng công thức này với PhoBERT-base thì ta sẽ nhận được kết quả là 84M tham số, tương đương 37% tỷ lệ sai số. Sai số lớn này là do đối với các mô hình nhỏ thì tỷ lệ tham số của ma trận token embeddings còn khá lớn.</p><p>Thử áp dụng với mô hình LLaMA, ta có được bảng sau:</p><table><thead><tr><th>Mô hình</th><th align="center">H</th><th align="center">L</th><th align="center">P xấp xỉ</th><th align="center">P chính xác</th><th align="center">Tỷ lệ sai số</th></tr></thead><tbody><tr><td>LLaMA 7B</td><td align="center">4096</td><td align="center">32</td><td align="center">6.4B</td><td align="center">6.7B</td><td align="center">4.4%</td></tr><tr><td>LLaMA 13B</td><td align="center">5120</td><td align="center">40</td><td align="center">12.6B</td><td align="center">13.0B</td><td align="center">3.2%</td></tr><tr><td>LLaMA 33B</td><td align="center">6656</td><td align="center">60</td><td align="center">31.9B</td><td align="center">32.5B</td><td align="center">1.8%</td></tr><tr><td>LLaMA 65B</td><td align="center">8192</td><td align="center">80</td><td align="center">64.4B</td><td align="center">65.2B</td><td align="center">1.2%</td></tr></tbody></table><p>Như vậy thì khi mô hình càng lớn thì tỷ lệ sai số càng giảm.</p><h1 id="Tinh-chi-phi-cho-huan-luyen"><a href="#Tinh-chi-phi-cho-huan-luyen" class="headerlink" title="Tính chi phí cho huấn luyện"></a>Tính chi phí cho huấn luyện</h1><p>Chi phí tính toán để huấn luyện mô hình Transformer, không bao gồm các phương pháp PEFT như LoRA.</p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>C</mi><mo>≈</mo><mi>τ</mi><mi>T</mi><mo>=</mo><mn>6</mn><mi>P</mi><mi>D</mi></mrow><annotation encoding="application/x-tex">C \approx \tau T = 6PD</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">C</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">≈</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.1132em;">τ</span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord">6</span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span></span></span></span></span><p>Trong đó:</p><ul><li>C: chi phí tính toán, tính bằng Floating Point Operations</li><li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>τ</mi></mrow><annotation encoding="application/x-tex">\tau</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.1132em;">τ</span></span></span></span>: tổng sức mạnh tính toán của hệ thống, tính bằng FLOPs</li><li>T: Thời gian huấn luyện, tính bằng giây</li><li>P: số lượng tham số của mô hình</li><li>D: kích thước tập dữ liệu, tính bằng số token</li></ul><h1 id="Tinh-yeu-cau-bo-nho-cho-huan-luyen"><a href="#Tinh-yeu-cau-bo-nho-cho-huan-luyen" class="headerlink" title="Tính yêu cầu bộ nhớ cho huấn luyện"></a>Tính yêu cầu bộ nhớ cho huấn luyện</h1><p>Công thức tính yêu cầu bộ nhớ không cố định mà phụ thuộc vào các cài đặt khi huấn luyện mô hình, nhưng về cơ bản thì gồm có 4 thành phần chính:</p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>m</mi><mi>e</mi><mi>m</mi><mi>o</mi><mi>r</mi><msub><mi>y</mi><mrow><mi>t</mi><mi>r</mi><mi>a</mi><mi>i</mi><mi>n</mi><mi>i</mi><mi>n</mi><mi>g</mi></mrow></msub><mo>=</mo><mi>m</mi><mi>e</mi><mi>m</mi><mi>o</mi><mi>r</mi><msub><mi>y</mi><mrow><mi>m</mi><mi>o</mi><mi>d</mi><mi>e</mi><mi>l</mi></mrow></msub><mo>+</mo><mi>m</mi><mi>e</mi><mi>m</mi><mi>o</mi><mi>r</mi><msub><mi>y</mi><mrow><mi>o</mi><mi>p</mi><mi>t</mi><mi>i</mi><mi>m</mi><mi>i</mi><mi>z</mi><mi>e</mi><mi>r</mi></mrow></msub><mo>+</mo><mi>m</mi><mi>e</mi><mi>m</mi><mi>o</mi><mi>r</mi><msub><mi>y</mi><mrow><mi>g</mi><mi>r</mi><mi>a</mi><mi>d</mi><mi>i</mi><mi>e</mi><mi>n</mi><mi>t</mi></mrow></msub><mo>+</mo><mi>m</mi><mi>e</mi><mi>m</mi><mi>o</mi><mi>r</mi><msub><mi>y</mi><mrow><mi>a</mi><mi>c</mi><mi>t</mi><mi>i</mi><mi>v</mi><mi>a</mi><mi>t</mi><mi>i</mi><mi>o</mi><mi>n</mi></mrow></msub></mrow><annotation encoding="application/x-tex">memory_{training} = memory_{model} + memory_{optimizer} + memory_{gradient} + memory_{activation}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.716668em;vertical-align:-0.286108em;"></span><span class="mord mathnormal">m</span><span class="mord mathnormal">e</span><span class="mord mathnormal">m</span><span class="mord mathnormal">o</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight">n</span><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight">n</span><span class="mord mathnormal mtight" style="margin-right:0.03588em;">g</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.7777700000000001em;vertical-align:-0.19444em;"></span><span class="mord mathnormal">m</span><span class="mord mathnormal">e</span><span class="mord mathnormal">m</span><span class="mord mathnormal">o</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">m</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight">d</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.8694379999999999em;vertical-align:-0.286108em;"></span><span class="mord mathnormal">m</span><span class="mord mathnormal">e</span><span class="mord mathnormal">m</span><span class="mord mathnormal">o</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight">p</span><span class="mord mathnormal mtight">t</span><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight">m</span><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight" style="margin-right:0.04398em;">z</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.8694379999999999em;vertical-align:-0.286108em;"></span><span class="mord mathnormal">m</span><span class="mord mathnormal">e</span><span class="mord mathnormal">m</span><span class="mord mathnormal">o</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361079999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">g</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight">d</span><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight">n</span><span class="mord mathnormal mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathnormal">m</span><span class="mord mathnormal">e</span><span class="mord mathnormal">m</span><span class="mord mathnormal">o</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight">c</span><span class="mord mathnormal mtight">t</span><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight" style="margin-right:0.03588em;">v</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight">t</span><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight">n</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span><p>Trong đó:</p><ul><li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>m</mi><mi>e</mi><mi>m</mi><mi>o</mi><mi>r</mi><msub><mi>y</mi><mrow><mi>t</mi><mi>r</mi><mi>a</mi><mi>i</mi><mi>n</mi><mi>i</mi><mi>n</mi><mi>g</mi></mrow></msub></mrow><annotation encoding="application/x-tex">memory_{training}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.716668em;vertical-align:-0.286108em;"></span><span class="mord mathnormal">m</span><span class="mord mathnormal">e</span><span class="mord mathnormal">m</span><span class="mord mathnormal">o</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight">n</span><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight">n</span><span class="mord mathnormal mtight" style="margin-right:0.03588em;">g</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span>: bộ nhớ để huấn luyện mô hình</li><li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>m</mi><mi>e</mi><mi>m</mi><mi>o</mi><mi>r</mi><msub><mi>y</mi><mrow><mi>m</mi><mi>o</mi><mi>d</mi><mi>e</mi><mi>l</mi></mrow></msub></mrow><annotation encoding="application/x-tex">memory_{model}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathnormal">m</span><span class="mord mathnormal">e</span><span class="mord mathnormal">m</span><span class="mord mathnormal">o</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">m</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight">d</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>: bộ nhớ để lưu trữ tham số của mô hình</li><li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>m</mi><mi>e</mi><mi>m</mi><mi>o</mi><mi>r</mi><msub><mi>y</mi><mrow><mi>o</mi><mi>p</mi><mi>t</mi><mi>i</mi><mi>m</mi><mi>i</mi><mi>z</mi><mi>e</mi><mi>r</mi></mrow></msub></mrow><annotation encoding="application/x-tex">memory_{optimizer}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.716668em;vertical-align:-0.286108em;"></span><span class="mord mathnormal">m</span><span class="mord mathnormal">e</span><span class="mord mathnormal">m</span><span class="mord mathnormal">o</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight">p</span><span class="mord mathnormal mtight">t</span><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight">m</span><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight" style="margin-right:0.04398em;">z</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span>: bộ nhớ để lưu trữ trạng thái của optimizer</li><li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>m</mi><mi>e</mi><mi>m</mi><mi>o</mi><mi>r</mi><msub><mi>y</mi><mrow><mi>g</mi><mi>r</mi><mi>a</mi><mi>d</mi><mi>i</mi><mi>e</mi><mi>n</mi><mi>t</mi></mrow></msub></mrow><annotation encoding="application/x-tex">memory_{gradient}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.716668em;vertical-align:-0.286108em;"></span><span class="mord mathnormal">m</span><span class="mord mathnormal">e</span><span class="mord mathnormal">m</span><span class="mord mathnormal">o</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361079999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">g</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight">d</span><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight">n</span><span class="mord mathnormal mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span>: bộ nhớ để lưu trữ giá trị gradient</li><li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>m</mi><mi>e</mi><mi>m</mi><mi>o</mi><mi>r</mi><msub><mi>y</mi><mrow><mi>a</mi><mi>c</mi><mi>t</mi><mi>i</mi><mi>v</mi><mi>a</mi><mi>t</mi><mi>i</mi><mi>o</mi><mi>n</mi></mrow></msub></mrow><annotation encoding="application/x-tex">memory_{activation}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathnormal">m</span><span class="mord mathnormal">e</span><span class="mord mathnormal">m</span><span class="mord mathnormal">o</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight">c</span><span class="mord mathnormal mtight">t</span><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight" style="margin-right:0.03588em;">v</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight">t</span><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight">n</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>: bộ nhớ để lưu trữ giá trị của các hàm activation</li></ul><h2 id="Model-Memory"><a href="#Model-Memory" class="headerlink" title="Model Memory"></a>Model Memory</h2><p>Khi huấn luyện, có 3 loại dữ liệu để lưu trữ tham số của mô hình là fp32, fp16 và mixed-precision. Mỗi dạng sẽ có mức sử dụng bộ nhớ khác nhau:</p><ul><li><p>fp32:</p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>m</mi><mi>e</mi><mi>m</mi><mi>o</mi><mi>r</mi><msub><mi>y</mi><mrow><mi>m</mi><mi>o</mi><mi>d</mi><mi>e</mi><mi>l</mi></mrow></msub><mo>=</mo><mn>4</mn><mi>P</mi></mrow><annotation encoding="application/x-tex">memory_{model} = 4P</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathnormal">m</span><span class="mord mathnormal">e</span><span class="mord mathnormal">m</span><span class="mord mathnormal">o</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">m</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight">d</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord">4</span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span></span></span></span></span></li><li><p>fp16 và mixed-precision:</p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>m</mi><mi>e</mi><mi>m</mi><mi>o</mi><mi>r</mi><msub><mi>y</mi><mrow><mi>m</mi><mi>o</mi><mi>d</mi><mi>e</mi><mi>l</mi></mrow></msub><mo>=</mo><mn>2</mn><mi>P</mi></mrow><annotation encoding="application/x-tex">memory_{model} = 2P</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathnormal">m</span><span class="mord mathnormal">e</span><span class="mord mathnormal">m</span><span class="mord mathnormal">o</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">m</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight">d</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord">2</span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span></span></span></span></span></li></ul><h2 id="Optimizer-Memory"><a href="#Optimizer-Memory" class="headerlink" title="Optimizer Memory"></a>Optimizer Memory</h2><p>Mỗi optimizer có mức sử dụng bộ nhớ khác nhau:</p><ul><li><p>AdamW:</p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>m</mi><mi>e</mi><mi>m</mi><mi>o</mi><mi>r</mi><msub><mi>y</mi><mrow><mi>o</mi><mi>p</mi><mi>t</mi><mi>i</mi><mi>m</mi><mi>i</mi><mi>z</mi><mi>e</mi><mi>r</mi></mrow></msub><mo>=</mo><mn>12</mn><mi>P</mi></mrow><annotation encoding="application/x-tex">memory_{optimizer} = 12P</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.716668em;vertical-align:-0.286108em;"></span><span class="mord mathnormal">m</span><span class="mord mathnormal">e</span><span class="mord mathnormal">m</span><span class="mord mathnormal">o</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight">p</span><span class="mord mathnormal mtight">t</span><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight">m</span><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight" style="margin-right:0.04398em;">z</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord">1</span><span class="mord">2</span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span></span></span></span></span></li><li><p>SGD:</p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>m</mi><mi>e</mi><mi>m</mi><mi>o</mi><mi>r</mi><msub><mi>y</mi><mrow><mi>o</mi><mi>p</mi><mi>t</mi><mi>i</mi><mi>m</mi><mi>i</mi><mi>z</mi><mi>e</mi><mi>r</mi></mrow></msub><mo>=</mo><mn>8</mn><mi>P</mi></mrow><annotation encoding="application/x-tex">memory_{optimizer} = 8P</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.716668em;vertical-align:-0.286108em;"></span><span class="mord mathnormal">m</span><span class="mord mathnormal">e</span><span class="mord mathnormal">m</span><span class="mord mathnormal">o</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight">p</span><span class="mord mathnormal mtight">t</span><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight">m</span><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight" style="margin-right:0.04398em;">z</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord">8</span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span></span></span></span></span></li><li><p>Bitsandbytes:</p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>m</mi><mi>e</mi><mi>m</mi><mi>o</mi><mi>r</mi><msub><mi>y</mi><mrow><mi>o</mi><mi>p</mi><mi>t</mi><mi>i</mi><mi>m</mi><mi>i</mi><mi>z</mi><mi>e</mi><mi>r</mi></mrow></msub><mo>=</mo><mn>6</mn><mi>P</mi></mrow><annotation encoding="application/x-tex">memory_{optimizer} = 6P</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.716668em;vertical-align:-0.286108em;"></span><span class="mord mathnormal">m</span><span class="mord mathnormal">e</span><span class="mord mathnormal">m</span><span class="mord mathnormal">o</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight">p</span><span class="mord mathnormal mtight">t</span><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight">m</span><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight" style="margin-right:0.04398em;">z</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord">6</span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span></span></span></span></span></li></ul><h2 id="Gradient-Memory"><a href="#Gradient-Memory" class="headerlink" title="Gradient Memory"></a>Gradient Memory</h2><p>Tương tự model, gradient cũng có thể được lưu dưới dạng fp32, fp16 hoặc mixed-precision:</p><ul><li><p>fp32:</p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>m</mi><mi>e</mi><mi>m</mi><mi>o</mi><mi>r</mi><msub><mi>y</mi><mrow><mi>g</mi><mi>r</mi><mi>a</mi><mi>d</mi><mi>i</mi><mi>e</mi><mi>n</mi><mi>t</mi></mrow></msub><mo>=</mo><mn>4</mn><mi>P</mi></mrow><annotation encoding="application/x-tex">memory_{gradient} = 4P</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.716668em;vertical-align:-0.286108em;"></span><span class="mord mathnormal">m</span><span class="mord mathnormal">e</span><span class="mord mathnormal">m</span><span class="mord mathnormal">o</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361079999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">g</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight">d</span><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight">n</span><span class="mord mathnormal mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord">4</span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span></span></span></span></span></li><li><p>fp16 và mixed-precision:</p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>m</mi><mi>e</mi><mi>m</mi><mi>o</mi><mi>r</mi><msub><mi>y</mi><mrow><mi>g</mi><mi>r</mi><mi>a</mi><mi>d</mi><mi>i</mi><mi>e</mi><mi>n</mi><mi>t</mi></mrow></msub><mo>=</mo><mn>2</mn><mi>P</mi></mrow><annotation encoding="application/x-tex">memory_{gradient} = 2P</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.716668em;vertical-align:-0.286108em;"></span><span class="mord mathnormal">m</span><span class="mord mathnormal">e</span><span class="mord mathnormal">m</span><span class="mord mathnormal">o</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361079999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">g</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight">d</span><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight">n</span><span class="mord mathnormal mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord">2</span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span></span></span></span></span></li></ul><h2 id="Activation-Memory"><a href="#Activation-Memory" class="headerlink" title="Activation Memory"></a>Activation Memory</h2><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>m</mi><mi>e</mi><mi>m</mi><mi>o</mi><mi>r</mi><msub><mi>y</mi><mrow><mi>a</mi><mi>c</mi><mi>t</mi><mi>i</mi><mi>v</mi><mi>a</mi><mi>t</mi><mi>i</mi><mi>o</mi><mi>n</mi></mrow></msub><mo>=</mo><mi>s</mi><mi>b</mi><mi>H</mi><mi>L</mi><mo stretchy="false">(</mo><mn>10</mn><mo>+</mo><mfrac><mn>24</mn><mi>t</mi></mfrac><mo>+</mo><mn>5</mn><mfrac><mrow><mi>a</mi><mo>∗</mo><mi>s</mi></mrow><mrow><mi>H</mi><mo>∗</mo><mi>t</mi></mrow></mfrac><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">memory_{activation} = sbHL(10 + \frac {24} t + 5\frac {a*s} {H*t})</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathnormal">m</span><span class="mord mathnormal">e</span><span class="mord mathnormal">m</span><span class="mord mathnormal">o</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight">c</span><span class="mord mathnormal mtight">t</span><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight" style="margin-right:0.03588em;">v</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight">t</span><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight">n</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">s</span><span class="mord mathnormal">b</span><span class="mord mathnormal" style="margin-right:0.08125em;">H</span><span class="mord mathnormal">L</span><span class="mopen">(</span><span class="mord">1</span><span class="mord">0</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:2.00744em;vertical-align:-0.686em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.32144em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal">t</span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">2</span><span class="mord">4</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.686em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1.82828em;vertical-align:-0.686em;"></span><span class="mord">5</span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.14228em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.08125em;">H</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord mathnormal">t</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal">a</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord mathnormal">s</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.686em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mclose">)</span></span></span></span></span><p>Trong đó:</p><ul><li>s: độ dài của chuỗi đầu vào, tính bằng số token</li><li>b: batch size</li><li>H: số chiều của hidden state</li><li>L: số lượng layer</li><li>a: số attention head</li><li>t: mức độ của tensor parallelism (nếu không dùng tensor parallelism thì t = 1)</li></ul><p>Batch size khi huấn luyện các LLM thường rất lớn nên bộ nhớ sử dụng cũng lớn theo. Tuy nhiên, ta có thể giảm bộ nhớ sử dụng cho activation bằng cách tính lại giá trị của các hàm activation thay vì lưu trữ chúng, với cái giá phải trả là làm tăng chi phí tính toán. Cách làm này được gọi là “activation recomputation/checkpointing”.</p><p>Có 2 cách để tính lại giá trị của các hàm activation:</p><ul><li><strong>Tính lại toàn bộ activation</strong>, cách này sẽ giảm rất nhiều bộ nhớ sử dụng.<span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>m</mi><mi>e</mi><mi>m</mi><mi>o</mi><mi>r</mi><msub><mi>y</mi><mrow><mi>a</mi><mi>c</mi><mi>t</mi><mi>i</mi><mi>v</mi><mi>a</mi><mi>t</mi><mi>i</mi><mi>o</mi><mi>n</mi></mrow></msub><mo>=</mo><mn>2</mn><mi>s</mi><mi>b</mi><mi>H</mi><mi>L</mi></mrow><annotation encoding="application/x-tex">memory_{activation} = 2sbHL</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathnormal">m</span><span class="mord mathnormal">e</span><span class="mord mathnormal">m</span><span class="mord mathnormal">o</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight">c</span><span class="mord mathnormal mtight">t</span><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight" style="margin-right:0.03588em;">v</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight">t</span><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight">n</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord">2</span><span class="mord mathnormal">s</span><span class="mord mathnormal">b</span><span class="mord mathnormal" style="margin-right:0.08125em;">H</span><span class="mord mathnormal">L</span></span></span></span></span></li><li><strong>Tính lại một phần activation</strong>, cách này sẽ giảm bộ nhớ sử dụng ít hơn so với cách trên nhưng vẫn giảm được một phần.<span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>m</mi><mi>e</mi><mi>m</mi><mi>o</mi><mi>r</mi><msub><mi>y</mi><mrow><mi>a</mi><mi>c</mi><mi>t</mi><mi>i</mi><mi>v</mi><mi>a</mi><mi>t</mi><mi>i</mi><mi>o</mi><mi>n</mi></mrow></msub><mo>=</mo><mi>s</mi><mi>b</mi><mi>H</mi><mi>L</mi><mo stretchy="false">(</mo><mn>10</mn><mo>+</mo><mfrac><mn>24</mn><mi>t</mi></mfrac><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">memory_{activation} = sbHL(10 + \frac {24} t)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathnormal">m</span><span class="mord mathnormal">e</span><span class="mord mathnormal">m</span><span class="mord mathnormal">o</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight">c</span><span class="mord mathnormal mtight">t</span><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight" style="margin-right:0.03588em;">v</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight">t</span><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight">n</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">s</span><span class="mord mathnormal">b</span><span class="mord mathnormal" style="margin-right:0.08125em;">H</span><span class="mord mathnormal">L</span><span class="mopen">(</span><span class="mord">1</span><span class="mord">0</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:2.00744em;vertical-align:-0.686em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.32144em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal">t</span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">2</span><span class="mord">4</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.686em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mclose">)</span></span></span></span></span></li></ul><h1 id="Tai-lieu-tham-khao"><a href="#Tai-lieu-tham-khao" class="headerlink" title="Tài liệu tham khảo"></a>Tài liệu tham khảo</h1><ul><li>Counting the Number of Parameters in Deep Learning. Yekun’s Note. <a href="https://ychai.uk/notes/2019/10/11/NN/Counting-the-number-of-parameters-in-deep-learning/">https://ychai.uk/notes/2019/10/11/NN/Counting-the-number-of-parameters-in-deep-learning/</a></li><li>Transformer Math 101. (2023). EleutherAI. <a href="https://blog.eleuther.ai/transformer-math/">https://blog.eleuther.ai/transformer-math/</a></li><li>Touvron, Hugo &amp; Lavril, Thibaut &amp; Izacard, Gautier &amp; Martinet, Xavier &amp; Lachaux, Marie-Anne &amp; Lacroix, Timothée &amp; Rozière, Baptiste &amp; Goyal, Naman &amp; Hambro, Eric &amp; Azhar, Faisal &amp; Rodriguez, Aurelien &amp; Joulin, Armand &amp; Grave, Edouard &amp; Lample, Guillaume. (2023). LLaMA: Open and Efficient Foundation Language Models. 10.48550/arXiv.2302.13971. </li></ul>]]></content>
    
    
    
    <tags>
      
      <tag>Machine Learning</tag>
      
      <tag>Transformer</tag>
      
      <tag>Large Language Model</tag>
      
      <tag>Artificial Intelligence</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Giới thiệu về Data Version Control dùng cho các dự án AI/ML</title>
    <link href="/2023/10/16/Ung-dung-Data-Version-Control-cho-du-an-AI-ML/"/>
    <url>/2023/10/16/Ung-dung-Data-Version-Control-cho-du-an-AI-ML/</url>
    
    <content type="html"><![CDATA[<p>Một trong những vấn đề quan trọng nhất trong các dự án AI/ML là quản lý dữ liệu và mô hình. Các dự án AI/ML thường có nhiều người tham gia và thường xuyên phải thay đổi. Những thay đổi có thể là thay đổi về dữ liệu, về kiến trúc mô hình, thay đổi tham số, thay đổi cách thức huấn luyện, thay đổi cách thức đánh giá mô hình, thay đổi cách thức triển khai mô hình, v.v…</p><p>Nếu chúng ta không quản lý dữ liệu và mô hình một cách hiệu quả thì sẽ dễ dẫn đến nhiều tình huống không mong muốn. Ví dụ như:</p><ul><li><p>Tình huống 1:</p><ul><li>Bạn train một mô hình với một tập dữ liệu.</li><li>Bạn chỉnh sửa tập dữ liệu và train lại mô hình nhưng không lưu lại phiên bản cũ.</li><li>Khi đánh giá mô hình, bạn nhận thấy mô hình mới không tốt bằng mô hình cũ.</li><li>Bạn muốn quay lại phiên bản tập dữ liệu cũ để tìm ra nguyên nhân nhưng không thể vì bạn đã xóa nó đi rồi 😰</li><li>Tất nhiên là việc lưu 1 bản backup mỗi khi chỉnh sửa tập dữ liệu sẽ giúp tránh được tình huống này. Nhưng khi số lần chỉnh sửa nhiều lên khiến cho số bản backup càng nhiều, bạn sẽ rất khó quản lý chúng.</li></ul></li><li><p>Tình huống 2: Bạn vừa được tham gia vào 1 dự án đang trong quá trình phát triển. Dự án này trước đây được phụ trách bởi 1 anh đồng nghiệp trong team. Bạn nhận code &amp; data từ ảnh về và bắt đầu công việc.</p><ul><li>Bạn: “Em đã thay đổi tham số và train lại model. Model mới có độ chính xác cao hơn model cũ mà anh train cách đây 3 tháng.”</li><li>Anh đồng nghiệp: “Tuyệt vời! Để anh đánh giá model của em trước khi deploy nó lên prod nhé.”</li><li>Anh đồng nghiệp: “Hmmm… Model của em có vẻ không chính xác bằng model của anh. Model của em là 96% trong khi của anh là 98%.”</li><li>Bạn: “Sao lại thế ạ? Trong report của anh về model được train 3 tháng trước thì độ chính xác chỉ là 94% thôi mà!”</li><li>Anh đồng nghiệp: “Lạ nhỉ? À anh nhớ rồi. Trước khi em join project này cách đây 1 tuần thì anh có làm sạch tập test nên khiến cho model chính xác hơn. Chưa kịp update report thì em đã train lại rồi. 😅”</li><li>Bạn: “…”</li></ul><p>Ở đây, việc không tracking thay đổi của tập dữ liệu khiến cho bạn không biết được rằng model trước đây được đánh giá trên tập dữ liệu như thế nào.</p></li></ul><p>Trước đây, mình đã từng đặt tên cho các tập dữ liệu và mô hình với những cái tên như: model_v1, model_v2, model_new, data_raw, data_cleaned, data_preprocessed, v.v… Rồi 1 thời gian sau, mình lại quên mình đã làm gì với những tập dữ liệu và mô hình này. model_v1 train bằng tập dữ liệu nào? learning rate là bao nhiêu? Rồi cả tỷ câu hỏi khác mà bây giờ chỉ có cách là dùng máy du hành thời gian của Doraemon mới có thể trả lời được 😂.</p><p>Qua những ví dụ trên, chắc hẳn bạn đã phần nào hình dung được tầm quan trọng của việc quản lý dữ liệu và mô hình trong các dự án AI/ML.</p><p>Để giải quyết vấn đề này, có rất nhiều công cụ được phát triển nhưng trong bài viết này, mình sẽ giới thiệu về <a href="https://dvc.org/">Data Version Control (DVC)</a>.</p><h1 id="Data-Version-Control-la-gi"><a href="#Data-Version-Control-la-gi" class="headerlink" title="Data Version Control là gì?"></a>Data Version Control là gì?</h1><p>Data Version Control (DVC) là một công cụ mã nguồn mở dùng để quản lý phiên bản cho dữ liệu và mô hình. Trong phát triển phần mềm thông thường, chúng ta đã quá quen thuộc với việc sử dụng Git để quản lý phiên bản cho code. Tuy nhiên, Git không phù hợp để quản lý phiên bản cho dữ liệu và mô hình. DVC ra đời để giải quyết vấn đề này.</p><p>DVC được thiết kế để hoạt động dựa trên Git. Điều này có nghĩa là trong cùng 1 repo, bạn vừa có thể dùng Git để quản lý code, vừa có thể dùng DVC để quản lý dữ liệu và mô hình.</p><p>Nhờ hoạt động dựa trên Git, DVC tận dụng được các tính năng mạnh mẽ của Git như: branch, tag. Bạn có thể tạo nhiều branch, mỗi branch chứa 1 tập dữ liệu khác nhau. Bạn có thể tạo tag mỗi khi train xong 1 mô hình.</p><p><img src="/2023/10/16/Ung-dung-Data-Version-Control-cho-du-an-AI-ML/dvc.png" alt="Nguồn: dvc.org"></p><h1 id="Bat-dau-su-dung-DVC"><a href="#Bat-dau-su-dung-DVC" class="headerlink" title="Bắt đầu sử dụng DVC"></a>Bắt đầu sử dụng DVC</h1><p>Bạn có thể bắt đầu sử dụng DVC ngay bây giờ bằng việc cài đặt theo hướng dẫn ở link sau: <a href="https://dvc.org/doc/install">https://dvc.org/doc/install</a>.</p><p>Hoặc nếu bạn dùng pip, bạn có thể cài đặt DVC bằng lệnh sau:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">pip install dvc<br></code></pre></td></tr></table></figure><p>Sau khi cài đặt, trong thư mục chứa project repo của bạn, tiến hành khởi tạo project DVC bằng lệnh:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">dvc init<br></code></pre></td></tr></table></figure><h1 id="Lam-quen-voi-quan-ly-phien-ban-du-lieu"><a href="#Lam-quen-voi-quan-ly-phien-ban-du-lieu" class="headerlink" title="Làm quen với quản lý phiên bản dữ liệu"></a>Làm quen với quản lý phiên bản dữ liệu</h1><p>Khi sử dụng Git với code, thông thường bạn sẽ thay đổi code trong file rồi commit file đó vào index của Git. Cách này phù hợp với code vì các file code thường có kích thước rất nhỏ và dễ theo dõi những thay đổi về nội dung của chúng.</p><p>Khác với code, dữ liệu thường có kích thước lớn và thay đổi rất nhiều. Nếu commit file dữ liệu vào repo, nó sẽ trở nên rất nặng. Bạn cũng không thể biết được rằng file dữ liệu này đã được thay đổi như thế nào.</p><p>DVC tiếp cận vấn đề này bằng cách sử dụng 1 file meta để lưu lại thông tin về file dữ liệu. File meta này có kích thước nhỏ và được lưu trữ trong repo của Git. Khi bạn thay đổi file dữ liệu, DVC sẽ cập nhật file meta này. Khi bạn muốn lấy lại file dữ liệu, DVC sẽ dựa vào file meta này để tìm ra file dữ liệu cần lấy.</p><p>Ví dụ, bạn có 1 file CSV chứa dữ liệu training. Bạn muốn lưu file này vào repo của Git. Bạn sẽ làm như sau:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">dvc add train.csv<br></code></pre></td></tr></table></figure><p>Lệnh này sẽ tạo ra file <code>train.csv.dvc</code> chứa thông tin meta của file dữ liệu. Nội dung của nó có cấu trúc giống như thế này:</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs yaml"><span class="hljs-attr">outs:</span><br><span class="hljs-bullet">-</span> <span class="hljs-attr">md5:</span> <span class="hljs-string">9da9c6d8d622f096132838c67e7685b6</span><br>  <span class="hljs-attr">size:</span> <span class="hljs-number">298046</span><br>  <span class="hljs-attr">hash:</span> <span class="hljs-string">md5</span><br>  <span class="hljs-attr">path:</span> <span class="hljs-string">train.csv</span><br></code></pre></td></tr></table></figure><p>Về cơ bản, lệnh <code>dvc add</code> sẽ tính toán ra giá trị hash của file dữ liệu và lưu vào file <code>train.csv.dvc</code>. Hàm hash sẽ đảm bảo rằng nếu file dữ liệu thay đổi thì giá trị hash cũng sẽ thay đổi.</p><p>Sau khi có được file <code>train.csv.dvc</code>, bạn commit file này vào repo của Git. File này đóng vai trò như là 1 con trỏ, nó sẽ trỏ tới file dữ liệu thật. File dữ liệu thật sẽ được lưu trữ trong thư mục <code>.dvc/cache</code>.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">git add train.csv.dvc<br>git commit -m <span class="hljs-string">&quot;Add train.csv&quot;</span><br></code></pre></td></tr></table></figure><p>Bây giờ, bạn thử edit file <code>train.csv</code> và lưu lại. Sau đó, bạn chạy lệnh sau:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">dvc status<br></code></pre></td></tr></table></figure><p>Lệnh <code>dvc status</code> có chức năng giống như <code>git status</code> nhưng dành cho dữ liệu. Lệnh này sẽ kiểm tra xem file dữ liệu đã được thay đổi hay chưa. Nếu file dữ liệu đã được thay đổi, lệnh này sẽ thông báo cho bạn biết:</p><figure class="highlight nestedtext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs nestedtext"><span class="hljs-attribute">train.csv.dvc</span><span class="hljs-punctuation">:</span><br>        <span class="hljs-attribute">changed outs</span><span class="hljs-punctuation">:</span><br>                <span class="hljs-attribute">modified</span><span class="hljs-punctuation">:</span> <span class="hljs-string">          train.csv</span><br></code></pre></td></tr></table></figure><p>Vì file dữ liệu đã thay đổi, file <code>train.csv.dvc</code> không còn trỏ đến đúng file dữ liệu nữa. Bạn cần phải update lại file này bằng lệnh:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">dvc commit train.csv.dvc<br></code></pre></td></tr></table></figure><p>DVC sẽ hỏi là bạn có muốn commit file này hay không. Nhập <code>y</code> và Enter để tiếp tục.</p><p>Lúc này, DVC sẽ tính toán lại giá trị hash của file dữ liệu và cập nhật lại file <code>train.csv.dvc</code>. Sau đó, bạn commit file vào Git.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">git add train.csv.dvc<br>git commit -m <span class="hljs-string">&quot;Update train.csv&quot;</span><br></code></pre></td></tr></table></figure><p>Giả sử như bạn muốn lấy lại file dữ liệu cũ. Bạn có thể làm theo cách sau:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">git checkout HEAD~1 -- train.csv.dvc<br>dvc checkout train.csv<br></code></pre></td></tr></table></figure><p>Lệnh <code>git checkout</code> sẽ lấy lại file <code>train.csv.dvc</code> từ commit trước đó. Như hồi nãy mình đã nói, file meta đóng vai trò như là 1 con trỏ để trỏ tới dữ liệu thật. Lúc này, file <code>train.csv.dvc</code> không còn trỏ đến file <code>train.csv</code> trong thư mục chính nữa mà đang trỏ tới file cũ đang nằm trong <code>.dvc/cache</code>.</p><p>Khi tới câu lệnh <code>dvc checkout</code>, DVC sẽ dựa vào file meta để tìm ra file dữ liệu thật và đem file này về thư mục chính. Thế là bạn đã lấy lại được file dữ liệu cũ rồi!</p><p>Giống như Git, DVC cũng hỗ trợ lưu trữ remote nhưng thay vì là Github, Gitlab thì ta có S3, Google Cloud Storage, Google Drive, HDFS, v.v… Nhưng mình sẽ không đi sâu vào phần này, nếu muốn thì bạn có thể xem thêm tại <a href="https://dvc.org/doc/user-guide/data-management/remote-storage">https://dvc.org/doc/user-guide/data-management/remote-storage</a>.</p><p>Như vậy là mình đã cover được khái niệm cơ bản về quản lý phiên bản dữ liệu của DVC rồi đấy. Đối với mô hình thì về cơ bản nó cũng chỉ là 1 hoặc nhiều file có thể được <code>dvc add</code> và track bằng file <code>.dvc</code> mà thôi.</p><p>Đợi đã! Nhưng chúng ta chưa giải quyết được bài toán làm thế nào để xác định 1 mô hình được train bằng dữ liệu gì và tham số như thế nào mà, đúng không???</p><p>Việc quản lý phiên bản dữ liệu chỉ là bước khởi đầu cho quản lý phiên bản mô hình. Mình sẽ đi sâu hơn về vấn đề này trong bài viết tiếp theo. Còn bây giờ thì tạm thời dừng ở đây nhé :v.</p><p>Happy Coding!</p>]]></content>
    
    
    
    <tags>
      
      <tag>Machine Learning</tag>
      
      <tag>Artificial Intelligence</tag>
      
      <tag>Data Science</tag>
      
      <tag>Data Version Control</tag>
      
      <tag>Tool</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Quick Note #1: LoRA cho bài toán fine-tuning LLM</title>
    <link href="/2023/05/28/Quick-Note-1-LoRA-cho-bai-toan-fine-tuning-LLM/"/>
    <url>/2023/05/28/Quick-Note-1-LoRA-cho-bai-toan-fine-tuning-LLM/</url>
    
    <content type="html"><![CDATA[<h1 id="Low-Rank-Adaptation"><a href="#Low-Rank-Adaptation" class="headerlink" title="Low-Rank Adaptation"></a>Low-Rank Adaptation</h1><ul><li>Phần lớn tính toán trong các mô hình ngôn ngữ lớn nói riêng và các mô hình Deep Learning nói chung là những phép nhân ma trận. Nếu tối ưu được quá trình này thì sẽ giảm được chi phí đáng kể.</li><li>Bản chất của quá trình fine-tune là tạo ra 1 bộ tham số <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">Δ</mi><mi>W</mi></mrow><annotation encoding="application/x-tex">\Delta W</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord">Δ</span><span class="mord mathnormal" style="margin-right:0.13889em;">W</span></span></span></span> để cộng nó vào <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>W</mi><mn>0</mn></msub></mrow><annotation encoding="application/x-tex">W_0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> - bộ tham số đã được pre-trained - để tạo ra bộ tham số mới <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>W</mi><mo>=</mo><msub><mi>W</mi><mn>0</mn></msub><mo>+</mo><mi mathvariant="normal">Δ</mi><mi>W</mi></mrow><annotation encoding="application/x-tex">W = W_0 + \Delta W</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord">Δ</span><span class="mord mathnormal" style="margin-right:0.13889em;">W</span></span></span></span>.</li><li>Giả thuyết được đặt ra: <strong><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">Δ</mi><mi>W</mi></mrow><annotation encoding="application/x-tex">\Delta W</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord">Δ</span><span class="mord mathnormal" style="margin-right:0.13889em;">W</span></span></span></span> là một ma trận có rank (hạng) thấp</strong>.</li><li>Rank của ma trận càng nhỏ thì số lượng tham số cần tối ưu càng ít. Suy ra, cần ít bộ nhớ để lưu trữ và tài nguyên để tính toán hơn.</li><li>Công thức trên có thể được biểu diễn lại bằng <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>W</mi><mo>=</mo><msub><mi>W</mi><mn>0</mn></msub><mo>+</mo><mi mathvariant="normal">Δ</mi><mi>W</mi><mo>=</mo><msub><mi>W</mi><mn>0</mn></msub><mo>+</mo><mi>B</mi><mi>A</mi></mrow><annotation encoding="application/x-tex">W = W_0 + \Delta W = W_0 + BA</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord">Δ</span><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="mord mathnormal">A</span></span></span></span> với <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>B</mi></mrow><annotation encoding="application/x-tex">B</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span></span></span></span> và <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi></mrow><annotation encoding="application/x-tex">A</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal">A</span></span></span></span> là 2 ma trận có số chiều thấp hơn nhiều so với <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>W</mi><mn>0</mn></msub></mrow><annotation encoding="application/x-tex">W_0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>.</li><li>Ví dụ: <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>W</mi><mn>0</mn></msub><mo>∈</mo><msup><mi mathvariant="double-struck">R</mi><mrow><mn>1000</mn><mo>×</mo><mn>1000</mn></mrow></msup></mrow><annotation encoding="application/x-tex">W_0 \in \mathbb{R}^{1000 \times 1000}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.8141079999999999em;vertical-align:0em;"></span><span class="mord"><span class="mord"><span class="mord mathbb">R</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span><span class="mord mtight">0</span><span class="mord mtight">0</span><span class="mord mtight">0</span><span class="mbin mtight">×</span><span class="mord mtight">1</span><span class="mord mtight">0</span><span class="mord mtight">0</span><span class="mord mtight">0</span></span></span></span></span></span></span></span></span></span></span></span>, <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>B</mi><mo>∈</mo><msup><mi mathvariant="double-struck">R</mi><mrow><mn>1000</mn><mo>×</mo><mn>10</mn></mrow></msup></mrow><annotation encoding="application/x-tex">B \in \mathbb{R}^{1000 \times 10}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.72243em;vertical-align:-0.0391em;"></span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.8141079999999999em;vertical-align:0em;"></span><span class="mord"><span class="mord"><span class="mord mathbb">R</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span><span class="mord mtight">0</span><span class="mord mtight">0</span><span class="mord mtight">0</span><span class="mbin mtight">×</span><span class="mord mtight">1</span><span class="mord mtight">0</span></span></span></span></span></span></span></span></span></span></span></span>, <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi><mo>∈</mo><msup><mi mathvariant="double-struck">R</mi><mrow><mn>10</mn><mo>×</mo><mn>1000</mn></mrow></msup></mrow><annotation encoding="application/x-tex">A \in \mathbb{R}^{10 \times 1000}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.72243em;vertical-align:-0.0391em;"></span><span class="mord mathnormal">A</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.8141079999999999em;vertical-align:0em;"></span><span class="mord"><span class="mord"><span class="mord mathbb">R</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span><span class="mord mtight">0</span><span class="mbin mtight">×</span><span class="mord mtight">1</span><span class="mord mtight">0</span><span class="mord mtight">0</span><span class="mord mtight">0</span></span></span></span></span></span></span></span></span></span></span></span> thì số lượng tham số cần tối ưu là <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1000</mn><mo>×</mo><mn>10</mn><mo>+</mo><mn>10</mn><mo>×</mo><mn>1000</mn><mo>=</mo><mn>20000</mn></mrow><annotation encoding="application/x-tex">1000 \times 10 + 10 \times 1000 = 20000</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.72777em;vertical-align:-0.08333em;"></span><span class="mord">1</span><span class="mord">0</span><span class="mord">0</span><span class="mord">0</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.72777em;vertical-align:-0.08333em;"></span><span class="mord">1</span><span class="mord">0</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.72777em;vertical-align:-0.08333em;"></span><span class="mord">1</span><span class="mord">0</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span><span class="mord">0</span><span class="mord">0</span><span class="mord">0</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">2</span><span class="mord">0</span><span class="mord">0</span><span class="mord">0</span><span class="mord">0</span></span></span></span> thay vì <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1000</mn><mo>×</mo><mn>1000</mn><mo>=</mo><mn>1000000</mn></mrow><annotation encoding="application/x-tex">1000 \times 1000 = 1000000</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.72777em;vertical-align:-0.08333em;"></span><span class="mord">1</span><span class="mord">0</span><span class="mord">0</span><span class="mord">0</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span><span class="mord">0</span><span class="mord">0</span><span class="mord">0</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span><span class="mord">0</span><span class="mord">0</span><span class="mord">0</span><span class="mord">0</span><span class="mord">0</span><span class="mord">0</span></span></span></span> như trước đây. Tức là giảm đi 98% số lượng tham số cần tối ưu!</li><li>Khi triển khai mô hình LoRA, cần phải tải <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>W</mi><mn>0</mn></msub></mrow><annotation encoding="application/x-tex">W_0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> lẫn <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>B</mi></mrow><annotation encoding="application/x-tex">B</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span></span></span></span> và <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi></mrow><annotation encoding="application/x-tex">A</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal">A</span></span></span></span> vào bộ nhớ và thực hiện phép toán <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>W</mi><mo>=</mo><msub><mi>W</mi><mn>0</mn></msub><mo>+</mo><mi>B</mi><mi>A</mi></mrow><annotation encoding="application/x-tex">W = W_0 + BA</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="mord mathnormal">A</span></span></span></span> để sinh ra bộ tham số cho mô hình đã được fine-tune.</li><li>Nhược điểm:<ul><li>Mỗi mô hình LoRA chỉ có thể xử lý được 1 tác vụ tại 1 thời điểm. Khi cần thực hiện tác vụ khác thì phải thực hiện chuyển đổi bộ tham số.</li><li>Giả sử có nhiều mô hình LoRA được triển khai, nhưng chỉ có 1 instance của <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>W</mi><mn>0</mn></msub></mrow><annotation encoding="application/x-tex">W_0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> được tải vào bộ nhớ. Nếu dữ liệu đầu vào buộc mô hình phải chuyển đổi qua lại giữa các LoRA khác nhau thì sẽ làm tăng chi phí tính toán và giảm hiệu năng của mô hình.</li></ul></li><li>Giải pháp: Dùng <a href="https://arxiv.org/abs/2104.08691">Prompt Tuning</a>.</li></ul><h1 id="Tai-lieu-tham-khao"><a href="#Tai-lieu-tham-khao" class="headerlink" title="Tài liệu tham khảo"></a>Tài liệu tham khảo</h1><ul><li><a href="https://arxiv.org/pdf/2106.09685.pdf">LoRA: Low-Rank Adaptation of Large Language Models</a></li></ul>]]></content>
    
    
    
    <tags>
      
      <tag>Machine Learning</tag>
      
      <tag>Deep Learning</tag>
      
      <tag>Artificial Intelligence</tag>
      
      <tag>LoRA</tag>
      
      <tag>LLM</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Triển khai Triton Inference Server trên Google Kubernetes Engine</title>
    <link href="/2023/01/26/Trien-khai-Triton-Inference-Server-tren-Google-Kubernetes-Engine/"/>
    <url>/2023/01/26/Trien-khai-Triton-Inference-Server-tren-Google-Kubernetes-Engine/</url>
    
    <content type="html"><![CDATA[<h1 id="Tai-sao-can-dung-Triton"><a href="#Tai-sao-can-dung-Triton" class="headerlink" title="Tại sao cần dùng Triton?"></a>Tại sao cần dùng Triton?</h1><p>Khi triển khai mô hình Deep Learning lên môi trường K8S, chúng ta có thể áp dụng phương pháp giống như đối với các chương trình thông thường, về cơ bản thì sẽ gồm những bước như sau:</p><ol><li>Đóng gói code và mô hình vào Docker image.</li><li>Đẩy image lên registry.</li><li>Tạo deployment và service trên K8S.</li><li>Tạo ingress nối đến service vừa tạo.</li></ol><p>Phương pháp này rất đơn giản và hiệu quả đối với những mô hình gọn nhẹ không cần đến GPU, ví dụ như mô hình phân loại văn bản bằng LSTM, các mô hình Machine Learning truyền thống như SVM hay Random Forest. Nhưng khi mô hình lớn đến mức không đáp ứng được các yêu cầu về latency hoặc throughput thì triển khai lên GPU là điều cần thiết. Nếu chúng ta vẫn áp dụng phương pháp kể trên thì có những nhược điểm như sau:</p><ol><li>Các image dùng được GPU thường có kích thước lớn, cộng với việc mô hình cũng có kích thước lớn khiến cho <strong>image đầu ra nặng đến mức làm chậm đáng kể thời gian push và pull image trong quá trình triển khai</strong>. Điều này gây khó khăn nếu mô hình thường xuyên được cập nhật với dữ liệu mới.</li><li><strong>Kubernetes không cung cấp cơ chế native cho việc cấp phát 1 GPU cho nhiều container</strong>. Không giống như khi cấp phát CPU, container khi yêu cầu K8S cấp phát GPU chỉ có thể được cấp nguyên cả 1 GPU chứ không được yêu cầu 0.5 hay 0.1 GPU. Vấn đề này có thể được khắc phục nhờ vào một số giải pháp như <a href="https://cloud.google.com/kubernetes-engine/docs/how-to/gpus-multi">multi-instance GPUs</a> (chỉ hỗ trợ dòng A100) hoặc <a href="https://cloud.google.com/kubernetes-engine/docs/concepts/timesharing-gpus">time-sharing GPUs</a>, nhưng đều phải phụ thuộc vào giải pháp của bên thứ 3, đồng nghĩa với việc migrate sẽ phức tạp hơn (giả sử như bạn muốn chuyển qua AWS nhưng họ chưa hỗ trợ hoặc cung cấp giải pháp khác thì sao?).</li></ol><p><a href="https://github.com/triton-inference-server/server">Triton</a> có thể giải quyết được những nhược điểm này. Nó là 1 phần mềm mã nguồn mở dành cho vai trò inference các mô hình Machine Learning, được tạo bởi đội ngũ của Nvidia. Triton cho phép triển khai nhiều mô hình đến từ nhiều framework khác nhau, bao gồm TensorRT, TensorFlow, PyTorch, ONNX, OpenVINO, Python, RAPIDS FIL,… Triton hỗ trợ nhiều hình thức truy vấn khác nhau, bao gồm truy vấn real time, theo batched, ensembles, và audio/video streaming. Chúng đều được tối ưu để có hiệu năng cao.</p><p>Vậy thì Triton giải quyết những vấn đề trên như thế nào?</p><ol><li>Khi triển khai Triton lên K8S, chúng ta không cần phải đóng gói image kèm với mô hình. Thay vào đó, mô hình được mount từ 1 file system vào 1 thư mục cụ thể, hoặc kết nối đến cloud storage như S3 hay GCS. Khi khởi động, Triton sẽ tải mô hình từ cloud storage về local và bắt đầu chạy. Vì thế nên kích thước của image sẽ nhẹ hơn và không cần phải pull lại image khi cập nhật mô hình mà chỉ cần tải lại file mô hình từ cloud storage.</li><li>Cơ chế của Triton là quản lý tập trung nhiều mô hình khác nhau trong cùng 1 container. Trong đó, các mô hình có thể cùng chia sẻ tài nguyên của 1 GPU, giúp cho việc sử dụng GPU tối ưu hơn. Giải pháp của bên thứ 3 vì vậy trở nên không cần thiết nên việc migrate sẽ dễ dàng hơn.</li></ol><p>Trong phần tiếp theo, mình sẽ hướng dẫn cách triển khai Triton trên Google Kubernetes Engine.</p><h1 id="Trien-khai-Triton-tren-GKE"><a href="#Trien-khai-Triton-tren-GKE" class="headerlink" title="Triển khai Triton trên GKE"></a>Triển khai Triton trên GKE</h1><p>Trước khi bắt đầu triển khai, chúng ta hãy cùng phân tích kiến trúc của Triton trên GKE.</p><h2 id="Kien-truc-tong-quan"><a href="#Kien-truc-tong-quan" class="headerlink" title="Kiến trúc tổng quan"></a>Kiến trúc tổng quan</h2><p><img src="/2023/01/26/Trien-khai-Triton-Inference-Server-tren-Google-Kubernetes-Engine/triton-architecture.jpg" alt="Kiến trúc tổng quan của Triton trên GKE"></p><p>Như đã nói ở phần trước, Triton cần phải mount từ 1 file system hoặc cloud storage để có thể tải mô hình lên GPU. GKE đều cung cấp cả 2 cách mount này, nhưng mount từ file system sẽ gây khó khăn trong việc tải mô hình lên disk trong khi đó thì GCS cho phép tải, chỉnh sửa, xoá file một cách dễ dàng. Hơn nữa là chi phí của GCS rẻ hơn so với dùng disk, GCS tính phí theo phương án “dùng nhiêu trả nhiêu”, còn disk thì ta phải cấp phát lượng dung lượng nhất định không tránh khỏi dư thừa.</p><p>Mặc dù Triton cho phép chạy custom code Python để preprocess input và postprocess output, giúp cho nó có thể xử lý request từ đầu đến cuối. Nhưng theo mình thì Triton chỉ nên được sử dụng cho mục đích inference mô hình mà thôi. Các công đoạn như preprocess, postprocess, monitor nên được giao cho pod khác mà mình gọi là API Service trong hình trên. Như thế sẽ tách rời được vai trò giữa các service, theo nguyên tắc thiết kế của microservice.</p><p>API Service là nơi nhận request từ bên ngoài, preprocess, gửi data đến Triton, nhận kết quả inference, postprocess và trả kết quả về. Nó còn có nhiệm vụ theo dõi các metric như latency, request per second, throughput, confident score. Một lợi ích khác của việc phân tách vai trò là có thể scale một cách linh hoạt hơn. Giả sử như bạn có 1 module preprocess rất nặng và chậm, bạn có thể scale pod API Service trên 1 node khác không cần GPU nhưng có nhiều tài nguyên hơn mà không cần phải scale luôn cả Triton.</p><h2 id="Tien-hanh-trien-khai"><a href="#Tien-hanh-trien-khai" class="headerlink" title="Tiến hành triển khai"></a>Tiến hành triển khai</h2><h3 id="Tao-GCS-bucket"><a href="#Tao-GCS-bucket" class="headerlink" title="Tạo GCS bucket"></a>Tạo GCS bucket</h3><p>Việc đầu tiên chúng ta cần phải làm là tạo 1 bucket trên GCS. Nếu bạn đã có sẵn bucket rồi thì có thể bỏ qua phần này.</p><ol><li>Trong phần navigation, chọn <strong>Cloud Storage</strong> &gt; <strong>Buckets</strong>.</li><li>Click <strong>Create</strong>.</li><li>Chọn tên cho bucket. Trong bài viết này mình sẽ giả sử tên của bucket là <strong>triton-models</strong>, nhưng bạn nên chọn tên khác vì tên bucket là globally unique. Trong các đoạn code bên dưới, bạn cần thay tên bucket giả sử với tên bucket mà bạn tạo.</li><li>Trong mục control access, mình recommend bạn hãy giới hạn quyền truy cập vào bucket này bằng cách check vào ô <strong>Enforce public access prevention on this bucket</strong>. Nó sẽ ngăn model bị public ra bên ngoài.</li><li>Click <strong>Create</strong>.</li></ol><p><img src="/2023/01/26/Trien-khai-Triton-Inference-Server-tren-Google-Kubernetes-Engine/screenshot-1.jpeg" alt="Tạo GCS bucket"></p><h3 id="Tao-service-account"><a href="#Tao-service-account" class="headerlink" title="Tạo service account"></a>Tạo service account</h3><p>Để Triton có thể truy cập vào bucket của GCS, chúng ta phải cung cấp cho nó key của service account có quyền truy cập vào GCS. Để làm điều này, trước tiên ta phải tạo service account có quyền <strong>Storage Admin</strong>. Chú ý là chỉ nên cấp 1 quyền này cho service account của bạn để giảm thiểu rủi ro an ninh.</p><ol><li>Truy cập vào <strong>IAM &amp; Admin</strong> &gt; <strong>Service Accounts</strong>.</li><li>Click <strong>CREATE SERVICE ACCOUNT</strong>.</li><li>Điền các thông tin cần thiết.</li><li>Đến phần <strong>Grant this service account access to project</strong>, thêm quyền <strong>Storage Admin</strong>.</li><li>Click <strong>Done</strong>.</li></ol><p>Nếu bạn không có quyền để truy cập <strong>IAM &amp; Admin</strong> &gt; <strong>Service Accounts</strong>, bạn có thể nhờ admin của project để tạo thay.</p><p><img src="/2023/01/26/Trien-khai-Triton-Inference-Server-tren-Google-Kubernetes-Engine/screenshot-2.jpeg" alt="Tạo service account"></p><p>Sau khi tạo xong service account, bạn chọn service account vừa tạo và chọn tab <strong>KEYS</strong>. Ở đây liệt kê các key dùng để authenticate với quyền của service account này, click vào <strong>ADD KEY</strong> và chọn <strong>Create new key</strong>, chọn key type là JSON và click <strong>CREATE</strong>.</p><p><img src="/2023/01/26/Trien-khai-Triton-Inference-Server-tren-Google-Kubernetes-Engine/screenshot-3.jpeg" alt="Tạo key của service account"></p><p>Tải file key với tên là <code>key.json</code> về môi trường kubectl của bạn và dùng lệnh sau để tạo secret trên K8S:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">kubectl create secret generic triton-service-account --from-file=key.json=./key.json<br></code></pre></td></tr></table></figure><p>Secret này sẽ được mount vào container của Triton để authenticate với GCS.</p><h3 id="Trien-khai-Triton"><a href="#Trien-khai-Triton" class="headerlink" title="Triển khai Triton"></a>Triển khai Triton</h3><p>Dưới đây là cấu hình deployment của Triton:</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br></pre></td><td class="code"><pre><code class="hljs yaml"><span class="hljs-attr">apiVersion:</span> <span class="hljs-string">apps/v1</span><br><span class="hljs-attr">kind:</span> <span class="hljs-string">Deployment</span><br><span class="hljs-attr">metadata:</span><br>  <span class="hljs-attr">name:</span> <span class="hljs-string">triton</span><br>  <span class="hljs-attr">labels:</span><br>    <span class="hljs-attr">app.kubernetes.io/name:</span> <span class="hljs-string">triton</span><br>    <span class="hljs-attr">app.kubernetes.io/instance:</span> <span class="hljs-string">triton</span><br><span class="hljs-attr">spec:</span><br>  <span class="hljs-attr">replicas:</span> <span class="hljs-number">1</span><br>  <span class="hljs-attr">selector:</span><br>    <span class="hljs-attr">matchLabels:</span><br>      <span class="hljs-attr">app.kubernetes.io/name:</span> <span class="hljs-string">triton</span><br>      <span class="hljs-attr">app.kubernetes.io/instance:</span> <span class="hljs-string">triton</span><br>  <span class="hljs-comment"># Loại bỏ đoạn này nếu bạn có nhiều hơn 1 GPU.</span><br>  <span class="hljs-comment"># Đoạn này có tác dụng ngăn tình trạng không thể tạo pod mới thay thế pod cũ khi chỉ có 1 GPU.</span><br>  <span class="hljs-attr">strategy:</span><br>    <span class="hljs-attr">rollingUpdate:</span><br>      <span class="hljs-attr">maxSurge:</span> <span class="hljs-number">0</span><br>      <span class="hljs-attr">maxUnavailable:</span> <span class="hljs-number">1</span><br>    <span class="hljs-attr">type:</span> <span class="hljs-string">RollingUpdate</span><br>  <span class="hljs-attr">template:</span><br>    <span class="hljs-attr">metadata:</span><br>      <span class="hljs-attr">labels:</span><br>        <span class="hljs-attr">app.kubernetes.io/name:</span> <span class="hljs-string">triton</span><br>        <span class="hljs-attr">app.kubernetes.io/instance:</span> <span class="hljs-string">triton</span><br>    <span class="hljs-attr">spec:</span><br>      <span class="hljs-attr">containers:</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">triton</span><br>        <span class="hljs-attr">image:</span> <span class="hljs-string">nvcr.io/nvidia/tritonserver:22.12-py3</span><br>        <span class="hljs-attr">imagePullPolicy:</span> <span class="hljs-string">IfNotPresent</span><br>        <span class="hljs-attr">command:</span><br>        <span class="hljs-bullet">-</span> <span class="hljs-string">tritonserver</span><br>        <span class="hljs-attr">args:</span><br>        <span class="hljs-bullet">-</span> <span class="hljs-string">--model-repository=gs://triton-models/</span><br>        <span class="hljs-comment"># Mount service account key vào thư mục /var/secrets/google</span><br>        <span class="hljs-attr">volumeMounts:</span><br>        <span class="hljs-bullet">-</span> <span class="hljs-attr">mountPath:</span> <span class="hljs-string">/var/secrets/google</span><br>          <span class="hljs-attr">name:</span> <span class="hljs-string">google-cloud-key</span><br>        <span class="hljs-comment"># Chỉ định vị trí của service account key cho Triton</span><br>        <span class="hljs-attr">env:</span><br>        <span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">GOOGLE_APPLICATION_CREDENTIALS</span><br>          <span class="hljs-attr">value:</span> <span class="hljs-string">/var/secrets/google/key.json</span><br>        <span class="hljs-comment"># Các port của Triton</span><br>        <span class="hljs-attr">ports:</span><br>        <span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">http</span><br>          <span class="hljs-attr">containerPort:</span> <span class="hljs-number">8000</span><br>          <span class="hljs-attr">protocol:</span> <span class="hljs-string">TCP</span><br>        <span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">grpc</span><br>          <span class="hljs-attr">containerPort:</span> <span class="hljs-number">8001</span><br>          <span class="hljs-attr">protocol:</span> <span class="hljs-string">TCP</span><br>        <span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">prometheus</span><br>          <span class="hljs-attr">containerPort:</span> <span class="hljs-number">8002</span><br>          <span class="hljs-attr">protocol:</span> <span class="hljs-string">TCP</span><br>        <span class="hljs-comment"># Bắt buộc phải khai báo cấp phát GPU để được cấp</span><br>        <span class="hljs-attr">resources:</span><br>          <span class="hljs-attr">requests:</span><br>            <span class="hljs-attr">nvidia.com/gpu:</span> <span class="hljs-string">&quot;1&quot;</span><br>          <span class="hljs-attr">limits:</span><br>            <span class="hljs-attr">nvidia.com/gpu:</span> <span class="hljs-string">&quot;1&quot;</span><br>      <span class="hljs-comment"># Dùng secret vừa tạo ở bước trên để tạo thành volume mount</span><br>      <span class="hljs-attr">volumes:</span><br>        <span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">google-cloud-key</span><br>          <span class="hljs-attr">secret:</span><br>            <span class="hljs-attr">secretName:</span> <span class="hljs-string">triton-service-account</span><br></code></pre></td></tr></table></figure><p>Copy đoạn code trên vào file <code>deployment.yaml</code> và chạy lệnh:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">kubectl apply -f deployment.yaml<br></code></pre></td></tr></table></figure><p>Tiếp theo là tạo file service <code>service.yaml</code>:</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs yaml"><span class="hljs-attr">apiVersion:</span> <span class="hljs-string">v1</span><br><span class="hljs-attr">kind:</span> <span class="hljs-string">Service</span><br><span class="hljs-attr">metadata:</span><br>  <span class="hljs-attr">name:</span> <span class="hljs-string">triton</span><br>  <span class="hljs-attr">labels:</span><br>    <span class="hljs-attr">app.kubernetes.io/name:</span> <span class="hljs-string">triton</span><br>    <span class="hljs-attr">app.kubernetes.io/instance:</span> <span class="hljs-string">triton</span><br><span class="hljs-attr">spec:</span><br>  <span class="hljs-attr">type:</span> <span class="hljs-string">ClusterIP</span><br>  <span class="hljs-attr">ports:</span><br>  <span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">GRPC</span><br>    <span class="hljs-attr">protocol:</span> <span class="hljs-string">TCP</span><br>    <span class="hljs-attr">port:</span> <span class="hljs-number">8001</span><br>    <span class="hljs-attr">targetPort:</span> <span class="hljs-string">grpc</span><br>  <span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">HTTP</span><br>    <span class="hljs-attr">protocol:</span> <span class="hljs-string">TCP</span><br>    <span class="hljs-attr">port:</span> <span class="hljs-number">8000</span><br>    <span class="hljs-attr">targetPort:</span> <span class="hljs-string">http</span><br>  <span class="hljs-attr">selector:</span><br>    <span class="hljs-attr">app.kubernetes.io/name:</span> <span class="hljs-string">triton</span><br>    <span class="hljs-attr">app.kubernetes.io/instance:</span> <span class="hljs-string">triton</span><br></code></pre></td></tr></table></figure><p>Tạo service bằng lệnh:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">kubectl apply -f service.yaml<br></code></pre></td></tr></table></figure><p>Sau khi hoàn tất, bạn có thể gọi service triton từ các pod khác trong cluster thông qua endpoint <code>triton:8000</code> đối với HTTP hoặc <code>triton:8001</code> đối với GRPC.</p><p>Nếu muốn gọi trực tiếp Triton từ ngoài cluster thì bạn có thể tạo file <code>ingress.yaml</code>, nếu dùng NGINX Ingress Controller thì file cấu hình cơ bản sẽ tương tự như sau:</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs yaml"><span class="hljs-attr">apiVersion:</span> <span class="hljs-string">networking.k8s.io/v1</span><br><span class="hljs-attr">kind:</span> <span class="hljs-string">Ingress</span><br><span class="hljs-attr">metadata:</span><br>  <span class="hljs-attr">name:</span> <span class="hljs-string">triton</span><br>  <span class="hljs-attr">namespace:</span> <span class="hljs-string">default</span><br>  <span class="hljs-attr">annotations:</span><br>    <span class="hljs-attr">nginx.ingress.kubernetes.io/rewrite-target:</span> <span class="hljs-string">/$2</span><br><span class="hljs-attr">spec:</span><br>  <span class="hljs-attr">ingressClassName:</span> <span class="hljs-string">nginx</span><br>  <span class="hljs-attr">rules:</span><br>    <span class="hljs-bullet">-</span> <span class="hljs-attr">host:</span> <span class="hljs-string">&lt;your-domain&gt;</span><br>      <span class="hljs-attr">http:</span><br>        <span class="hljs-attr">paths:</span><br>          <span class="hljs-bullet">-</span> <span class="hljs-attr">pathType:</span> <span class="hljs-string">Prefix</span><br>            <span class="hljs-attr">path:</span> <span class="hljs-string">/triton(/|$)(.*)</span><br>            <span class="hljs-attr">backend:</span><br>              <span class="hljs-attr">service:</span><br>                <span class="hljs-attr">name:</span> <span class="hljs-string">triton</span><br>                <span class="hljs-attr">port:</span><br>                  <span class="hljs-attr">number:</span> <span class="hljs-number">8000</span><br></code></pre></td></tr></table></figure><p>Rồi dùng lệnh:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">kubectl apply -f ingress.yaml<br></code></pre></td></tr></table></figure><p>Ingress này sẽ điều hướng request URL có prefix dạng <code>http://&lt;your-domain&gt;/triton</code> đến service triton vào port HTTP.</p><h3 id="Chay-mo-hinh"><a href="#Chay-mo-hinh" class="headerlink" title="Chạy mô hình"></a>Chạy mô hình</h3><p>Do bucket vừa mới tạo chưa có gì nên chúng ta chưa thể chạy được mô hình nào cả. Trước tiên, bạn cần đưa mô hình của bạn lên bucket theo đúng chuẩn do Triton quy định, tham khảo ở <a href="https://github.com/triton-inference-server/server/blob/main/docs/user_guide/model_repository.md">đây</a>. Để diễn giải cho phần này, mình giả sử ở đây đang có 1 mô hình BERT cho bài toán phân loại văn bản.</p><p>Nếu bạn đã đọc document tham khảo của Triton, hãy thử xem qua file config của BERT:</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><code class="hljs text">name: &quot;bert_text_classification&quot;<br>platform: &quot;onnxruntime_onnx&quot;<br>max_batch_size: 0<br>input [<br>  &#123;<br>    name: &quot;input_ids&quot;<br>    data_type: TYPE_INT32<br>    dims: [-1, -1]<br>  &#125;,<br>  &#123;<br>    name: &quot;attention_mask&quot;<br>    data_type: TYPE_INT32<br>    dims: [-1, -1]<br>  &#125;<br>]<br><br>output [<br>  &#123;<br>    name: &quot;logits&quot;<br>    data_type: TYPE_FP32<br>    dims: [-1, 2]<br>  &#125;<br>]<br><br>instance_group [<br>  &#123;<br>    count: 1<br>    kind: KIND_GPU<br>  &#125;<br>]<br></code></pre></td></tr></table></figure><p>Để giao tiếp với Triton, có 2 protocol là HTTP và gRPC. gRPC có hiệu suất tốt hơn so với HTTP nên mình chọn protocol này cho code API Service. Triton cung cấp cho chúng ta thư viện Python để đơn giản hoá việc gọi mô hình (<a href="https://github.com/triton-inference-server/client">Github</a>).</p><p>Dưới đây là đoạn code tham khảo để gọi mô hình BERT cho text classification:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> math<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> scipy.special<br><span class="hljs-keyword">from</span> typing <span class="hljs-keyword">import</span> <span class="hljs-type">List</span><br><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer<br><span class="hljs-keyword">import</span> tritonclient.grpc <span class="hljs-keyword">as</span> grpcclient<br><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Predictor</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self,</span><br><span class="hljs-params">                 model_name: <span class="hljs-built_in">str</span>,</span><br><span class="hljs-params">                 tokenizer: AutoTokenizer,</span><br><span class="hljs-params">                 triton_url: <span class="hljs-built_in">str</span> = <span class="hljs-string">&#x27;triton:8001&#x27;</span>,</span><br><span class="hljs-params">                 batch_size: <span class="hljs-built_in">int</span> = <span class="hljs-number">64</span></span>):<br>        self.model_name = model_name<br>        self.tokenizer = tokenizer<br>        self.triton_url = triton_url<br>        self.batch_size = batch_size<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">predict_batch</span>(<span class="hljs-params">self, batch_items: <span class="hljs-type">List</span>[<span class="hljs-built_in">str</span>]</span>):<br>        <span class="hljs-comment"># Tokenize &amp; encode</span><br>        inputs = self.tokenizer.batch_encode_plus(batch_items,<br>                                                  add_special_tokens=<span class="hljs-literal">True</span>,<br>                                                  max_length=<span class="hljs-number">256</span>,<br>                                                  truncation=<span class="hljs-literal">True</span>,<br>                                                  pad_to_max_length=<span class="hljs-literal">True</span>)<br>        input_ids = np.array(inputs[<span class="hljs-string">&#x27;input_ids&#x27;</span>]).astype(np.int32)<br>        attention_mask = np.array(inputs[<span class="hljs-string">&#x27;attention_mask&#x27;</span>]).astype(np.int32)<br><br>        <span class="hljs-comment"># Setup inference</span><br>        triton_client = grpcclient.InferenceServerClient(url=self.triton_url, verbose=<span class="hljs-literal">False</span>)<br>        outputs = [grpcclient.InferRequestedOutput(<span class="hljs-string">&#x27;logits&#x27;</span>)]<br>        y_pred = []<br>        n_batches = math.ceil(<span class="hljs-built_in">len</span>(batch_items) / self.batch_size)<br><br>        <span class="hljs-comment"># Infer in batches</span><br>        <span class="hljs-keyword">for</span> x0, x1 <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(np.array_split(input_ids, n_batches),<br>                          np.array_split(attention_mask, n_batches)):<br>            inputs = [<br>                grpcclient.InferInput(<span class="hljs-string">&#x27;input_ids&#x27;</span>, x0.shape, <span class="hljs-string">&#x27;INT32&#x27;</span>),<br>                grpcclient.InferInput(<span class="hljs-string">&#x27;attention_mask&#x27;</span>, x1.shape, <span class="hljs-string">&#x27;INT32&#x27;</span>),<br>            ]<br><br>            inputs[<span class="hljs-number">0</span>].set_data_from_numpy(x0)<br>            inputs[<span class="hljs-number">1</span>].set_data_from_numpy(x1)<br><br>            results = triton_client.infer(<br>                model_name=self.model_name,<br>                inputs=inputs,<br>                outputs=outputs)<br><br>            logits = results.as_numpy(<span class="hljs-string">&#x27;logits&#x27;</span>)<br>            output_prob = scipy.special.softmax(logits, axis=<span class="hljs-number">1</span>)<br>            y_pred.extend(output_prob.tolist())<br><br>        <span class="hljs-keyword">return</span> y_pred<br></code></pre></td></tr></table></figure><p>Đoạn code này chỉ là phần core của API Service, những thành phần khác như server, text preprocess, postprocess thì bạn tham khảo ở bên ngoài nhé.</p><h1 id="Cac-van-de-nay-sinh"><a href="#Cac-van-de-nay-sinh" class="headerlink" title="Các vấn đề nảy sinh"></a>Các vấn đề nảy sinh</h1><h2 id="Kich-thuoc-image-con-kha-lon"><a href="#Kich-thuoc-image-con-kha-lon" class="headerlink" title="Kích thước image còn khá lớn"></a>Kích thước image còn khá lớn</h2><p>Nếu bạn dùng spot node như mình thì hay xảy ra trường hợp bị downtime khá lâu khi node bị preemptible. Nguyên nhân chủ yếu là do image của Triton vẫn còn khá nặng nên thời gian pull về lâu. Có thể giảm kích thước của image bằng cách build custom image chỉ hỗ trợ framework mà bạn hay dùng, như của mình là ONNX nên có thể loại bỏ TF, PyTorch. Xem ở <a href="https://github.com/triton-inference-server/server/blob/main/docs/customization_guide/compose.md">đây</a> để tham khảo cách build custom image cho framework của bạn.</p><h2 id="Tranh-chap-tai-nguyen-giua-cac-mo-hinh"><a href="#Tranh-chap-tai-nguyen-giua-cac-mo-hinh" class="headerlink" title="Tranh chấp tài nguyên giữa các mô hình"></a>Tranh chấp tài nguyên giữa các mô hình</h2><p>Hiện tại chưa có cơ chế giới hạn tài nguyên của mô hình nên nếu có 1 mô hình sử dụng hết tài nguyên của GPU thì các mô hình khác sẽ không thể chạy được. </p><h2 id="Kho-scale-theo-chieu-ngang"><a href="#Kho-scale-theo-chieu-ngang" class="headerlink" title="Khó scale theo chiều ngang"></a>Khó scale theo chiều ngang</h2><p>Vì Triton quản lý mô hình theo hình thức tập trung, mỗi pod sẽ chứa ít nhất 1 instance của mỗi mô hình. Khi ta muốn scale 1 mô hình, nếu ta scale số lượng pod thì đồng nghĩa với việc scale tất cả mô hình còn lại, rất là lãng phí. Đối với scale theo chiều dọc thì sẽ dễ dàng hơn vì Triton cho phép tạo nhiều instance của 1 mô hình trên nhiều GPU, xem <a href="https://github.com/triton-inference-server/server/blob/main/docs/user_guide/model_configuration.md#instance-groups">Instance Groups</a>.</p><h1 id="Tong-ket"><a href="#Tong-ket" class="headerlink" title="Tổng kết"></a>Tổng kết</h1><p>Hi vọng sau bài viết này, bạn có thể triển khai mô hình của mình lên Triton trên GKE. Mặc dù bài viết này chỉ tập trung vào GKE, nếu bạn dùng AWS hay onprem thì cơ chế cũng gần tương tự nhau, chỉ cần 1 cloud storage giống như S3 hoặc GCS là có thể chạy được, và tất nhiên là cần GPU nữa.</p><p>Happy Coding!</p>]]></content>
    
    
    
    <tags>
      
      <tag>Machine Learning</tag>
      
      <tag>Deep Learning</tag>
      
      <tag>Artificial Intelligence</tag>
      
      <tag>K8S</tag>
      
      <tag>Triton Inference Server</tag>
      
      <tag>Google Kubernetes Engine</tag>
      
      <tag>MLOps</tag>
      
      <tag>Model Serving</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Triển khai GPT-J 6B Vietnamese News trên Docker và K8S</title>
    <link href="/2022/12/28/Trien-khai-GPT-J-6B-Vietnamese-News-tren-Docker-va-K8S/"/>
    <url>/2022/12/28/Trien-khai-GPT-J-6B-Vietnamese-News-tren-Docker-va-K8S/</url>
    
    <content type="html"><![CDATA[<p>Thời gian gần đây đang nổi lên 1 con AI tên là ChatGPT có khả năng giao tiếp như người thật, biết làm thơ, viết luận văn, giải toán, dịch tiếng Anh sang tiếng Việt, ngay cả viết và đọc hiểu code. Thậm chí nó có thể “giả lập” máy ảo linux và “chat với 1 ChatGPT khác trong máy ảo đó” (Đọc thêm ở <a href="https://www.engraved.blog/building-a-virtual-machine-inside/">đây</a>). Bản chất bên dưới của hệ thống này là 1 mô hình Generative Pre-trained Transformer 3 (GPT-3) với số lượng tham số khổng lồ (175 tỷ), chỉ riêng việc lưu mô hình này thôi cũng cần đến 800 GB! Ngay cả khi OpenAI công bố mô hình này cho cộng đồng thì cũng không thể tự sử dụng được với kinh phí khiêm tốn.</p><p>May mắn là có một mô hình GPT khác đến từ cộng đồng AI Việt Nam, tên là <a href="https://huggingface.co/VietAI/gpt-j-6B-vietnamese-news">GPT-J 6B Vietnamese News</a>, được train bởi VietAI. Mô hình này chỉ có 6 tỷ tham số, đủ nhỏ để chạy trên những con GPU giá rẻ. Trong bài viết này, mình sẽ hướng dẫn cách triển khai mô hình này lên môi trường Docker và K8S, sử dụng thông qua API để lấy kết quả.</p><p>Link tới Github repo chứa code trong bài viết này: <a href="https://github.com/duydvu/gpt-j-6B-vietnamese-news-api">https://github.com/duydvu/gpt-j-6B-vietnamese-news-api</a></p><p><escape><a id="more"></a></escape></p><h1 id="Load-va-chay-thu-mo-hinh"><a href="#Load-va-chay-thu-mo-hinh" class="headerlink" title="Load và chạy thử mô hình"></a>Load và chạy thử mô hình</h1><p>Trước khi chạy thử mô hình này, bạn cần đảm bảo đủ bộ nhớ GPU để load mô hình lên máy. Yêu cầu tối thiểu là khoảng 17 GB. Nếu bạn có nhiều hơn 1 GPU và tổng bộ nhớ nhiều hơn con số này thì vẫn có thể chạy được. Mình đã thử thành công trên 2 card GTX 1080Ti 12GB.</p><p>Bước đầu tiên là load tokenizer và tham số của mô hình:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer, AutoModelForCausalLM<br><br><span class="hljs-comment"># Load tokenizer</span><br>tokenizer = AutoTokenizer.from_pretrained(model_path)<br><br><span class="hljs-comment"># Load tham số mô hình</span><br>model = AutoModelForCausalLM.from_pretrained(model_path,<br>                                             torch_dtype=torch.float16,<br>                                             low_cpu_mem_usage=<span class="hljs-literal">True</span>)<br>model.parallelize() <span class="hljs-comment"># Chia nhỏ mô hình và phân bổ lên nhiều GPU để tránh bị lỗi OOM</span><br></code></pre></td></tr></table></figure><p>Trong đoạn code trên, mình thực hiện 2 phương pháp tối ưu:</p><ol><li>Sử dụng kiểu dữ liệu float16 thay vì float32 để giảm dung lượng bộ nhớ trên GPU. Vì float16 tương ứng với 2 byte còn float32 tới 4 byte nên tiết kiệm được 50% dung lượng.</li><li>Vì mô hình này vẫn rất lớn so với dung lượng bộ nhớ của các loại GPU phổ biến, nếu bạn có nhiều GPU thì có thể phân bổ các tham số của mô hình trên nhiều GPU thay vì chỉ chạy trên 1 con. Phương pháp này có tên là <strong>Model Parallel</strong>.</li></ol><p>Sau khi đã xong bước 1, chạy thử mô hình để kiểm tra xem có bị lỗi gì không:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># Convert đoạn text từ dạng string sang dãy số integer </span><br>input_ids = tokenizer.encode(<span class="hljs-string">&quot;Tiềm năng của trí tuệ nhân tạo&quot;</span>, return_tensors=<span class="hljs-string">&#x27;pt&#x27;</span>).to(<span class="hljs-string">&#x27;cuda:0&#x27;</span>)<br><br><span class="hljs-comment"># Chạy mô hình</span><br>outputs = model.generate(<br>  input_ids,<br>  max_length=<span class="hljs-number">256</span>,<br>  do_sample=<span class="hljs-literal">True</span>,<br>  top_k=<span class="hljs-number">50</span>,<br>  top_p=<span class="hljs-number">0.9</span>,<br>  num_return_sequences=<span class="hljs-number">1</span>,<br>)<br><br><span class="hljs-comment"># Decode kết quả của mô hình từ dãy số integer sang dạng string và in ra màn hình</span><br><span class="hljs-keyword">for</span> output <span class="hljs-keyword">in</span> outputs:<br>  <span class="hljs-built_in">print</span>(tokenizer.decode(output, skip_special_tokens=<span class="hljs-literal">True</span>))<br></code></pre></td></tr></table></figure><p>Vì thuật toán sinh văn bản mà mình đang sử dụng là lấy mẫu dựa trên xác suất nên sau mỗi lần chạy, mô hình sẽ cho ra kết quả khác nhau. Kết quả thu được trên máy của mình là:</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs text">Tiềm năng của trí tuệ nhân tạo là rất lớn, nhiều ứng dụng có thể ra đời trong tương lai không xa, và điều đó đòi hỏi sự nỗ lực của cả cộng đồng.<br><br>Một điểm khác cần lưu ý là trí tuệ nhân tạo là một lĩnh vực phát triển hoàn toàn mới và không thể chỉ dựa vào mỗi việc nghiên cứu của các trường, viện mà phải kết hợp với các doanh nghiệp, và phải có sự kết nối mạnh mẽ với các doanh nghiệp.<br><br>Về việc chuẩn bị nhân lực cho cuộc cách mạng công nghiệp lần thứ 4, Phó Thủ tướng lưu ý các trường cần có sự đổi mới về cơ chế, phương pháp, mô hình dạy và học nhằm tạo môi trường tốt nhất cho trí tuệ nhân tạo.<br><br>&quot;Nếu cứ làm theo cách cũ thì các trường sẽ như &quot;rúc thóc&quot; vào bao, nhưng nếu áp dụng phương pháp mới mà các trường chưa có, mới ở giai đoạn đầu mà có quy mô lớn hơn nhiều lần thì sẽ rất khó khăn&quot;, Phó Thủ tướng chia sẻ.<br><br>Phó Thủ tướng Vũ Đức Đam đề nghị Bộ KH&amp;CN tiếp tục có sự phối hợp với các bộ, ngành, trước hết là Bộ KH&amp;CN xây dựng chiến lược, quy hoạch phát triển, thực hiện đề án tăng cường.<br></code></pre></td></tr></table></figure><p>Sau khi chạy thử thành công, mình viết lại đoạn code trên thành 1 class trong file <code>src/predictor.py</code> và đóng gói toàn bộ code bao gồm cả phần API server vào trong thư mục <code>src</code>.</p><h1 id="Tao-Docker-image"><a href="#Tao-Docker-image" class="headerlink" title="Tạo Docker image"></a>Tạo Docker image</h1><p>Để build được Docker, trước hết bạn cần phải tải mô hình về máy theo các bước sau:</p><ol><li>Cài đặt <a href="https://git-lfs.com/">git-lfs</a></li><li>Chạy lệnh <code>git clone https://huggingface.co/VietAI/gpt-j-6B-vietnamese-news</code></li></ol><p>Lệnh clone sẽ tải mô hình về và đặt ở thư mục hiện tại trên terminal.</p><p>Sau khi tải xong, dùng lệnh <code>mv</code> để đưa thư mục vừa clone về vào thư mục của repo API:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">mv</span> ./gpt-j-6B-vietnamese-news ./gpt-j-6B-vietnamese-news-api<br></code></pre></td></tr></table></figure><p>Cuối cùng là dùng lệnh <code>build</code> Docker image:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">docker build -t gpt-j .<br></code></pre></td></tr></table></figure><p>Tiến hành chạy thử bằng việc tạo 1 container và map tới port 5000 của máy:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">docker run -it --<span class="hljs-built_in">rm</span> -p 5000:5000 gpt-j<br></code></pre></td></tr></table></figure><p>Gọi thử bằng lệnh <code>curl</code>:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs bash">curl --location --request POST <span class="hljs-string">&#x27;http://localhost:5000/predict&#x27;</span> \<br>  --header <span class="hljs-string">&#x27;Content-Type: application/json&#x27;</span> \<br>  --data-raw <span class="hljs-string">&#x27;&#123;</span><br><span class="hljs-string">    &quot;text&quot;: &quot;Tiềm năng của trí tuệ nhân tạo&quot;,</span><br><span class="hljs-string">    &quot;n_samples&quot;: 1</span><br><span class="hljs-string">  &#125;&#x27;</span><br></code></pre></td></tr></table></figure><h1 id="Trien-khai-len-moi-truong-K8S-voi-Helm-Chart"><a href="#Trien-khai-len-moi-truong-K8S-voi-Helm-Chart" class="headerlink" title="Triển khai lên môi trường K8S với Helm Chart"></a>Triển khai lên môi trường K8S với Helm Chart</h1><h2 id="Mot-chut-phan-tich"><a href="#Mot-chut-phan-tich" class="headerlink" title="Một chút phân tích"></a>Một chút phân tích</h2><p>Trong bài viết này, mình chọn Google Cloud Platform (GCP) là nhà cung cấp dịch vụ cloud để triển khai mô hình lên K8S vì mình thường xuyên dùng GCP trong công việc. Dù vậy, nếu bạn có sử dụng nhà cung cấp khác thì cũng không thành vấn đề, quan trọng là họ có GPU cho K8S là được.</p><p>Sau khi nghiên cứu các mức giá GPU của GCP, mình quyết định chọn Nvidia T4 bởi 2 tiêu chí:</p><ol><li>Mức giá - giá thuê hàng tháng của T4 là gần 180 USD, nếu dùng spot VM thì giá chỉ còn 80 USD, cộng với chi phí của CPU, RAM và disk thì khoảng 90 USD, thấp thứ 2 chỉ sau dòng K80.</li><li>Tốc độ xử lý - Lý do mình không chọn K80 là vì nó không hỗ trợ FP16 (<a href="https://docs.nvidia.com/deeplearning/tensorrt/support-matrix/index.html#hardware-precision-matrix">nguồn tham khảo</a>), giúp giảm bộ nhớ cũng như tăng tốc độ chạy mô hình.</li></ol><p>Với dung lượng 16 GB, cần tới 2 card T4 thì mới có thể chạy được mô hình GPT-J này. Như vậy chi phí hàng tháng nếu duy trì liên tục là 90 x 2=180 USD. Nếu chỉ thỉnh thoảng chạy thì chi phí sẽ còn thấp hơn nữa.</p><h2 id="Bat-dau-trien-khai"><a href="#Bat-dau-trien-khai" class="headerlink" title="Bắt đầu triển khai"></a>Bắt đầu triển khai</h2><p>Helm là một công cụ rất tuyệt vời cho việc đóng gói ứng dụng mà chúng ta vừa tạo để đưa lên K8S. Mình đã tạo Helm Chart và để trong thư mục <code>k8s/chart</code>. Chart này bao gồm 2 thành phần:</p><ol><li>Deployment: Tạo deployment chứa pod chạy container gpt-j.</li><li>Service: Tạo service kết nối tới pod trong deployment ở trên.</li></ol><p>Trong phần deployment có 2 phần quan trọng cần lưu ý, một là:</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs YAML"><span class="hljs-attr">strategy:</span><br>  <span class="hljs-attr">rollingUpdate:</span><br>    <span class="hljs-attr">maxSurge:</span> <span class="hljs-number">0</span><br>    <span class="hljs-attr">maxUnavailable:</span> <span class="hljs-number">1</span><br>  <span class="hljs-attr">type:</span> <span class="hljs-string">RollingUpdate</span><br></code></pre></td></tr></table></figure><p>Mặc định trong K8S khi cập nhật deployment thì sẽ tạo thêm 1 pod mới chạy song song với pod cũ, nhưng trong trường hợp này mình chỉ có đủ GPU để chạy cho 1 pod nên K8S sẽ không thể thay thế được pod cũ vì không có GPU để chạy pod mới. Vì vậy mình thay đổi strategy để khi cập nhật deployment thì K8S sẽ xóa pod cũ trước khi tạo pod mới. Như vậy thì sẽ không bị hiện tượng trên, nhưng sẽ bị vấn đề khác là xảy ra downtime trong quá trình deploy.</p><p>Hai là:</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs YAML"><span class="hljs-attr">resources:</span><br>  <span class="hljs-attr">requests:</span><br>    <span class="hljs-attr">cpu:</span> <span class="hljs-string">500m</span><br>    <span class="hljs-attr">memory:</span> <span class="hljs-string">8000Mi</span><br>    <span class="hljs-attr">nvidia.com/gpu:</span> <span class="hljs-string">&quot;2&quot;</span><br>  <span class="hljs-attr">limits:</span><br>    <span class="hljs-attr">memory:</span> <span class="hljs-string">16000Mi</span><br>    <span class="hljs-attr">nvidia.com/gpu:</span> <span class="hljs-string">&quot;2&quot;</span><br></code></pre></td></tr></table></figure><p>Có 2 dòng quan trọng là <code>nvidia.com/gpu: &quot;2&quot;</code> dùng để cấp phát tài nguyên GPU cho pod. Bắt buộc phải có 2 dòng này thì pod mới có thể dùng GPU được. Một điểm trừ là hiện tại GCP chỉ cho phép 1 GPU được cấp phát tới 1 pod nên nhiều pod không thể chia sẽ cùng 1 GPU được. Nếu có nhiều mô hình khác cần dùng tới GPU thì tốt nhất bạn nên dùng các giải pháp chạy mô hình tập trung như <a href="https://github.com/triton-inference-server/server">Triton</a> để có thể chạy nhiều mô hình trên cùng 1 GPU.</p><p>Bước cuối cùng là cài đặt Helm Chart này lên K8S thông qua lệnh sau:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">helm install --<span class="hljs-built_in">set</span> namespace=default --<span class="hljs-built_in">set</span> image=gpt-j --<span class="hljs-built_in">set</span> version=latest gpt-j ./k8s/chart<br></code></pre></td></tr></table></figure><p>Như vậy là chúng ta đã thành công trong việc triển khai GPT-J lên K8S rồi đó. Chúc bạn cũng thành công như mình nhé!</p>]]></content>
    
    
    
    <tags>
      
      <tag>Machine Learning</tag>
      
      <tag>Deep Learning</tag>
      
      <tag>Artificial Intelligence</tag>
      
      <tag>Docker</tag>
      
      <tag>GPT-J</tag>
      
      <tag>K8S</tag>
      
      <tag>Natural Language Generation</tag>
      
      <tag>Language Model</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Cấu hình GPU trong Docker</title>
    <link href="/2021/01/10/Cau-hinh-GPU-trong-Docker/"/>
    <url>/2021/01/10/Cau-hinh-GPU-trong-Docker/</url>
    
    <content type="html"><![CDATA[<p>Trong bài <a href="/2021/01/05/Cach-thiet-lap-moi-truong-Docker-cho-server-Jupyter-cua-ban">trước</a>, mình đã trình bày cách thiết lập môi trường Docker để chạy server Jupyter. Với nó, bạn có thể cài đặt bất kỳ package nào mà bạn muốn như scikit-learn, Tensorflow, PyTorch. Nhưng những thư viện này sẽ không thể sử dụng được GPU trong máy bạn như khi cài trực tiếp trên hệ điều hành bởi vì bạn chưa cấu hình GPU cho container của bạn. Trong bài này, mình sẽ hướng dẫn bạn cách để sử dụng được GPU trong Docker.</p><p>Mình giả định rằng máy của bạn đang dùng Nvidia GPU và bạn đã cài driver cần thiết trên hệ điều hành Ubuntu rồi. Nếu bạn chưa cài đặt driver cho GPU thì vào đường link ở <a href="https://www.nvidia.com/Download/index.aspx">đây</a>, chọn tải rồi cài driver trước nhé.</p><p><escape><a id="more"></a></escape></p><h2 id="Cai-dat-nvidia-container-runtime"><a href="#Cai-dat-nvidia-container-runtime" class="headerlink" title="Cài đặt nvidia-container-runtime"></a>Cài đặt nvidia-container-runtime</h2><p>Mở terminal và chạy đoạn lệnh dưới đây:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs bash">curl -s -L https://nvidia.github.io/nvidia-container-runtime/gpgkey | \<br>  sudo apt-key add -<br>distribution=$(. /etc/os-release;<span class="hljs-built_in">echo</span> $ID<span class="hljs-variable">$VERSION_ID</span>)<br>curl -s -L https://nvidia.github.io/nvidia-container-runtime/<span class="hljs-variable">$distribution</span>/nvidia-container-runtime.list | \<br>  sudo <span class="hljs-built_in">tee</span> /etc/apt/sources.list.d/nvidia-container-runtime.list<br>sudo apt-get update<br></code></pre></td></tr></table></figure><p>Sau đó, nhập lệnh sau để cài đặt nvidia-container-runtime:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">sudo apt-get install nvidia-container-runtime<br></code></pre></td></tr></table></figure><p>Khởi động lại Docker server:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">sudo service docker restart<br></code></pre></td></tr></table></figure><p>Thế là xong. Đến bước tiếp theo là khởi động 1 container mới với cấu hình cho phép truy cập GPU.</p><h2 id="Khoi-dong-Docker-container"><a href="#Khoi-dong-Docker-container" class="headerlink" title="Khởi động Docker container"></a>Khởi động Docker container</h2><p>Để sử dụng GPU trong 1 container, bạn phải thêm tham số <code>--gpus</code> trong lệnh chạy <code>docker run</code>. Ví dụ:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">docker run -it -p 8888:8888 --gpus all jupyter-server<br></code></pre></td></tr></table></figure><p>Tham số <code>--gpus</code> có giá trị là <code>all</code> ở đây nghĩa là bạn cho phép container này truy cập vào toàn bộ GPU mà máy bạn đang có. Hoặc là bạn có thể chỉ định những GPU cụ thể được sử dụng trong container.</p><p>Mỗi GPU trong máy được đánh giá trị index bắt đầu từ 0. Ví dụ nếu bạn có 2 GPU thì chúng sẽ được đánh index lần lượt là 0 và 1. Để xem index của từng GPU và các thông số khác như memory, usage thì có thể dùng lệnh <code>nvidia-smi</code>. Ví dụ như trong hình dưới đây:</p><p><img src="/2021/01/10/Cau-hinh-GPU-trong-Docker/Screenshot-2021-01-10-121331.png" alt="Ví dụ chạy lệnh nvidia-smi"></p><p>Ở cột ngoài cùng bên trái, bạn sẽ thấy index của từng GPU. Ở đây có 2 GPU nên được đánh lần lượt 0 và 1. GPU 0 đang sử dụng 4905 MB / 11178 MB, còn GPU 1 thì đang dùng 11140 MB / 11178 MB. Nếu bạn chỉ muốn cấp cho container sử dụng GPU 0 thì dùng lệnh như sau:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">docker run -it -p 8888:8888 --gpus device=0 jupyter-server<br></code></pre></td></tr></table></figure><p>Hoặc nếu bạn có nhiều hơn 2 GPU thì bạn có thể chỉ định bất kỳ GPU nào được dùng trong container như sau:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">docker run -it -p 8888:8888 --gpus device=0,2,4 jupyter-server<br></code></pre></td></tr></table></figure><h2 id="Tong-ket"><a href="#Tong-ket" class="headerlink" title="Tổng kết"></a>Tổng kết</h2><p>Giờ đây bạn có thể cài thư viện Tensorflow GPU hay PyTorch trong server Jupyter là có thể dùng được ngay GPU. Với Docker, bạn có thể tha hồ cài đặt bất kỳ phần mềm nào mà bạn muốn.</p><p>Mình cũng chia sẻ thêm một số package rất hữu ích mà mình hay dùng trong công việc:</p><ul><li><strong>tmux</strong>: cho phép bạn quản lý terminal theo phong cách xịn xò như 1 hacker, bạn có thể chạy 1 chương trình trong terminal và tắt nó đi mà không sợ bị dừng chương trình.</li><li><a href="https://github.com/ohmyzsh/ohmyzsh"><strong>ohmyzsh</strong></a>: terminal đẹp lung linh kèm theo 1 số plugin như git cho phép bạn thao tác trên terminal tiện lợi và thích thú hơn.</li></ul><p>Happy Coding!</p>]]></content>
    
    
    
    <tags>
      
      <tag>Docker</tag>
      
      <tag>Jupyter</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Cách thiết lập môi trường Docker cho server Jupyter của bạn</title>
    <link href="/2021/01/05/Cach-thiet-lap-moi-truong-Docker-cho-server-Jupyter-cua-ban/"/>
    <url>/2021/01/05/Cach-thiet-lap-moi-truong-Docker-cho-server-Jupyter-cua-ban/</url>
    
    <content type="html"><![CDATA[<p>Jupyter Notebook và Jupyter Lab là 2 môi trường tuyệt vời cho data scientist thực hành với dữ liệu của mình. Tuy nhiên, đôi khi việc thực hành với dữ liệu gặp 1 chút khó khăn. Nào là cài đặt Java để chạy VnCoreNLP, cài tensorflow GPU để huấn luyện model, cài cmake để cài CocCoc Tokenizer, quản lý dependency,… Có khi bạn lỡ làm sai gì đó khiến cho máy bạn gặp vấn đề mà không biết giải quyết làm sao, vừa tốn công sức vừa tốn thời gian cho những tác vụ không liên quan. Docker chính là chìa khóa để giái quyết những vấn đề trên. Bài viết này sẽ hướng dẫn bạn cách thiết lập môi trường Docker để chạy server Jupyter của bạn.</p><p><escape><a id="more"></a></escape></p><h2 id="Docker-la-gi"><a href="#Docker-la-gi" class="headerlink" title="Docker là gì?"></a>Docker là gì?</h2><p>Nếu bạn chưa biết về Docker hoặc biết 1 chút và muốn tìm hiểu thêm thì nên đọc phần này, nếu không thì bạn có thể kéo xuống <a href="#Tao-Docker-image">phần tiếp theo</a>.</p><p>Docker là 1 môi trường ảo hóa giống như VirtualBox hay VMware. Nếu bạn đã từng dùng máy ảo để chạy 1 hệ điều hành thì có thể thấy rằng chúng cung cấp cho bạn 1 môi trường độc lập với máy chính, những gì bạn làm trên máy ảo không ảnh hưởng đến máy chính. Nếu bạn lỡ phá gì đó hay dính malware thì chỉ cần reset máy ảo đó đi là xong. Sự tiện lợi này khiến cho máy ảo rất thích hợp cho việc phát triển phần mềm, triển khai phần mềm, test virus,… Nhưng cũng chính sự tiện lợi này khiến cho nó tốn rất nhiều tài nguyên của máy. Vì vậy, việc sử dụng máy ảo tương đối khó khăn.</p><p>Docker ra đời nhằm khắc phục những hạn chế trên của máy ảo. Đối với máy ảo, nó dùng 1 thành phần gọi là hypervisor để mô phỏng phần cứng của nhiều máy trên 1 máy, nhờ đó cho phép nhiều máy ảo chạy trên 1 máy chính duy nhất, mỗi máy ảo có thể chạy hệ điều hành khác nhau. Trong khi đó, Docker tận dụng hệ điều hành của máy chính để chạy các container trên đó, mỗi container là 1 phần mềm được đóng gói chạy hoàn toàn độc lập với nhau. Bạn có thể làm gần như bất cứ điều gì trên container này mà không ảnh hướng đến container khác. Hình dưới đây sẽ giải thích rõ hơn về sự khác nhau giữa 2 kiến trúc này.</p><p><img src="/2021/01/05/Cach-thiet-lap-moi-truong-Docker-cho-server-Jupyter-cua-ban/docker.png" alt="So sánh kiến trúc giữa Docker và máy ảo"></p><p>Nhờ vào việc tận dụng tài nguyên có sẵn trong hệ điều hành của máy chính, Docker tiêu tốn ít RAM và dung lượng đĩa hơn so với máy ảo. Qua đó tạo điều kiện thuận lợi cho các nhà phát triển sử dụng Docker để việc phát triển phần mềm trở nên dễ dàng hơn, tình trạng code chạy ổn trên máy này nhưng bị bug trên máy kia được giảm thiểu vì giờ đây code đều chạy trên cùng 1 môi trường. Triển khai phần mềm cũng dễ dàng hơn, trước đây thì DevOps phải biết về các dependency của phần mềm để cài đặt trước khi triển khai, giờ thì chỉ cần Developer tạo 1 image chứa phần mềm và tất cả dependency rồi đưa nó cho DevOps, tới lượt DevOps thì chỉ cần <code>run</code> nó là xong.</p><p>Đối với Data Scientist, việc sử dụng Docker cũng giúp ích rất nhiều. Ví dụ bạn có 1 tool yêu cầu Python 3.7 để chạy nhưng bạn lại đang dùng Python 3.5 thì bạn không cần phải nâng cấp Python của máy mà chỉ cần chạy tool đó trong 1 container có Python 3.7 là xong. Hoặc là trong quá trình cài đặt các phần mềm trên máy, đôi lúc bạn sẽ gặp trường hợp lỗi do cấu hình sai gì đó, nếu mà bạn không tìm được cách sửa thì sẽ tiêu tốn khá nhiều thời gian. Ngược lại, khi bạn cài trên Docker thì chỉ cần xóa container đang chạy rồi khởi động lại cái khác là xong. Mọi thứ rất nhanh phải không nào!</p><p>Docker còn mang lại nhiều lợi ích hơn trong 1 team R&amp;D có nhiều Data Scientist. Bạn không cần phải quan tâm đến việc cài đặt hay cập nhật package này có ảnh hưởng đến thành viên khác trong team hay không, vì mọi thứ đã được <strong>isolated</strong> trong 1 container. Có thể bạn sẽ nghĩ rằng virtualenv của Python cho phép làm điều tương tự, nhưng Docker cho phép làm nhiều hơn thế không chỉ có mỗi quản lý Python package. Giả sử như bạn muốn dùng Java phiên bản mới hơn để chạy tool này nhưng đồng nghiệp của bạn lại đang dùng phiên bản cũ hơn không tương thích thì sao?</p><p>Tóm lại, Docker là 1 công cụ tuyệt vời đã, đang và sẽ ngày càng phát triển trong tương lai, đóng một vai trò quan trọng trong việc phát triển phần mềm của thế giới. Vì vậy, nếu bạn chưa rành về Docker thì mình khuyên bạn nên bắt đầu tìm hiểu nó để cảm nhận rõ được những lợi ích của nó nhé.</p><p>Nguồn tài liệu để học Docker:</p><ul><li><a href="https://docs.docker.com/get-started/overview/">Docker Documentation</a></li><li><a href="https://www.youtube.com/watch?v=1k8pox8mkxc">Video hướng dẫn về Docker rất bổ ích của anh Phạm Huy Hoàng</a></li></ul><p>Trước khi đi vào phần kế tiếp, bạn hãy chắc rằng mình đã nắm được những kiến thức cơ bản của Docker như image, container là gì rồi hãy bắt đầu nhé.</p><h2 id="Tao-Docker-image"><a href="#Tao-Docker-image" class="headerlink" title="Tạo Docker image"></a>Tạo Docker image</h2><p>OK. Trong phần này mình sẽ hướng dẫn cách tạo 1 image dùng để chạy server Jupyter.</p><p>Trong thư mục trống bất kỳ, tạo 1 file mới và đặt tên là <code>Dockerfile</code>, lưu ý là không được có đuôi extension. Mở file này bằng 1 trình editor và copy nội dung sau vào file:</p><figure class="highlight docker"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs docker"><span class="hljs-comment"># Có thể chọn image khác ở https://hub.docker.com/_/python</span><br><span class="hljs-keyword">FROM</span> python:<span class="hljs-number">3.7</span><br><br><span class="hljs-keyword">RUN</span><span class="language-bash"> pip install jupyterlab</span><br><span class="hljs-keyword">WORKDIR</span><span class="language-bash"> /code</span><br><span class="hljs-keyword">CMD</span><span class="language-bash"> [<span class="hljs-string">&quot;jupyter-lab&quot;</span>, <span class="hljs-string">&quot;--ip&quot;</span>, <span class="hljs-string">&quot;0.0.0.0&quot;</span>, <span class="hljs-string">&quot;--allow-root&quot;</span>]</span><br></code></pre></td></tr></table></figure><p>Sau đó, chạy lệnh trong terminal:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">docker build -t jupyter-server .<br></code></pre></td></tr></table></figure><p>Lệnh này sẽ build 1 image chứa Python 3.7 và Jupyter trong đó.</p><p>Sau khi build xong image, bây giờ bạn có thể sử dụng nó để chạy server Jupyter rồi. Để chạy server, chỉ cần chạy lệnh:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">docker run -it -p 8888:8888 jupyter-server<br></code></pre></td></tr></table></figure><p>Bạn sẽ thấy thông báo server Jupyter đã được khởi động kèm theo token. Mở browser truy cập vào địa chỉ <a href="http://localhost:8888/">http://localhost:8888</a> rồi nhập token đó vào, thế là bạn đã chạy được server Jupyter trên Docker rồi.</p><p><strong>Lưu ý</strong>: Tất cả các file bạn tạo trên server Jupyter này đều được nằm trong container, bạn sẽ không tìm thấy thư mục code của bạn trong hệ thống file của máy chính. <strong>Nếu bạn có lỡ xóa container này thì mọi nội dung bạn tạo trong nó cũng bị xóa theo</strong>. Để tránh điều này, bạn nên mount thư mục <code>/code</code> trong container lên 1 thư mục trong hệ thống file của máy chính. Để làm điều vậy, bạn chỉ cần thêm 1 tham số trước khi chạy container:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">docker run -it -p 8888:8888 -v &lt;path-to-your-directory&gt;:/code jupyter-server<br></code></pre></td></tr></table></figure><p>Thay thế <code>&lt;path-to-your-directory&gt;</code> thành đường dần đến thư mục mà bạn muốn để code ở đó. Tham số vừa thêm vào có tác dụng mount thư mục trên máy chính của bạn lên thư mục <code>/code</code> trong container. Hiểu đơn giản là từ bây giờ 2 thư mục này có thể đồng bộ với nhau, nếu bạn tạo 1 file trong thư mục này thì nó sẽ xuất hiện trong thư mục còn lại. Nếu container bị xóa thì nội dung trong thư mục bạn chọn để mount vào vẫn y như cũ.</p><h2 id="Cai-dat-thu-vien"><a href="#Cai-dat-thu-vien" class="headerlink" title="Cài đặt thư viện"></a>Cài đặt thư viện</h2><p>Bạn có thể cài thêm các thư viện cần thiết vào trong container đang chạy bằng 1 trong 3 cách sau đây</p><h3 id="Cach-1-Lenh-docker-exec"><a href="#Cach-1-Lenh-docker-exec" class="headerlink" title="Cách 1: Lệnh docker exec"></a>Cách 1: Lệnh docker exec</h3><p>Để dùng lệnh này, trước tiên bạn cần phải biết tên hoặc ID của container. Mở 1 terminal mới và nhập lệnh sau:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">docker ps<br></code></pre></td></tr></table></figure><p>Lệnh này sẽ in ra danh sách những container đang chạy trong Docker server, nội dung tương tự như sau:</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs text">CONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS              PORTS                    NAMES<br>b3e70a2ab109        jupyter-server      &quot;jupyter-lab --ip 0.…&quot;   8 minutes ago       Up 7 minutes        0.0.0.0:8888-&gt;8888/tcp   nifty_liskov<br></code></pre></td></tr></table></figure><p>Cột <code>CONTAINER ID</code> hiện ID của container của bạn, còn cột <code>NAMES</code> hiện tên của container. Mỗi container khi được tạo sẽ được cấp cho 1 ID và tên duy nhất trong số các container đang còn tồn tại trong Docker server. Copy 1 trong 2 field này từ màn hình terminal của bạn và nhập lệnh dưới đây:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">docker <span class="hljs-built_in">exec</span> -it &lt;paste-here&gt; bash<br></code></pre></td></tr></table></figure><p>Sau khi nhấn Enter, terminal của bạn sẽ trở thành terminal trong container. Giờ bạn có thể cài bất cứ thư viện nào trong đây. Ví dụ như:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">pip install numpy pandas<br></code></pre></td></tr></table></figure><h3 id="Cach-2-Dung-tinh-nang-shell-command-tren-Jupyter"><a href="#Cach-2-Dung-tinh-nang-shell-command-tren-Jupyter" class="headerlink" title="Cách 2: Dùng tính năng shell command trên Jupyter"></a>Cách 2: Dùng tính năng shell command trên Jupyter</h3><p>Jupyter cho phép ta chạy bất cứ lệnh nào trong notebook.</p><p>Để làm vậy, bạn cần phải thêm dấu chấm thang (!) vào trước lệnh shell rồi chạy notebook. Ví dụ:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">!pip install numpy<br></code></pre></td></tr></table></figure><p>Hình dưới đây là kết quả sau khi chạy lệnh trên trong notebook</p><p><img src="/2021/01/05/Cach-thiet-lap-moi-truong-Docker-cho-server-Jupyter-cua-ban/screenshot.png" alt="Chạy lệnh shell command trong notebook"></p><p>Cách này nhanh hơn rất nhiều so với cách 1.</p><h3 id="Cach-3-Dung-terminal-cua-Jupyter-Lab"><a href="#Cach-3-Dung-terminal-cua-Jupyter-Lab" class="headerlink" title="Cách 3: Dùng terminal của Jupyter Lab"></a>Cách 3: Dùng terminal của Jupyter Lab</h3><p>Trên thanh công cụ của Jupyter Lab, chọn <strong>File</strong> → <strong>New</strong> → <strong>Terminal</strong>. Một tab mới được mở ra và bạn có thể nhập lệnh vào terminal để cài thư viện.</p><p>Cách làm này chậm hơn cách thứ 2 nhưng mà phù hợp với những tác vụ như monitor bằng lệnh <code>top</code> hoặc <code>watch</code> hoặc <code>tail</code>.</p><h2 id="Tong-ket"><a href="#Tong-ket" class="headerlink" title="Tổng kết"></a>Tổng kết</h2><p>Như vậy là bạn đã có 1 Docker container chạy server Jupyter để phục vụ cho công việc Data Science. Trong container này, bạn có thể cài đặt bất cứ phần mềm nào mà không sợ ảnh hưởng đến hệ điều hành trên máy bạn. Mỗi khi muốn tắt server, bạn có thể vào terminal dùng để chạy server và nhấn <strong>Ctrl + C</strong> là xong.</p><p>Ngoài việc isolate nội dung thư mục, Docker còn cho phép bạn giới hạn tài nguyên cho container theo ý thích. Bạn có thể giới hạn số CPU mà container được sử dụng, hoặc lượng RAM tối đa được dùng để tránh trường hợp hết RAM gây đứng máy. Tìm hiểu ở <a href="https://docs.docker.com/config/containers/resource_constraints/">đây</a> để xem cách làm.</p><p>Còn 1 vấn đề mà mình chưa giải quyết là làm sao để sử dụng GPU trong Docker, nếu bạn đang làm dự án liên quan đến Deep Learning thì GPU cực kỳ cần thiết để tăng tốc quá trình huấn luyện mô hình. Vì vậy, mình sẽ giải quyết vần đề này trong bài viết theo.</p><p>Happy Coding!</p>]]></content>
    
    
    
    <tags>
      
      <tag>Docker</tag>
      
      <tag>Jupyter Notebook</tag>
      
      <tag>Jupyter Lab</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Làm quen với Kafka: Phần 1 - Chat với nhau trên console</title>
    <link href="/2021/01/01/Lam-quen-voi-Kafka-Phan-1-Chat-voi-nhau-tren-console/"/>
    <url>/2021/01/01/Lam-quen-voi-Kafka-Phan-1-Chat-voi-nhau-tren-console/</url>
    
    <content type="html"><![CDATA[<p>Trong 1 hệ thống theo kiến trúc Microservice, để xử lý 1 khối lượng dữ liệu lớn với sự tác động của nhiều service khác nhau, ta phải có cơ chế để các service này giao tiếp với nhau một cách hiệu quả, Kafka được sinh ra để làm nhiệm vụ đó. Trong phần đầu tiên của series “Làm quen với Kafka”, mình sẽ viết 1 ứng dụng Python dùng để chat với nhau trên màn hình console để hiểu được những tính năng cơ bản của Kafka.</p><p>Lưu ý đây chỉ là 1 ứng dụng làm cho vui để làm quen với Kafka thôi chứ không nên đưa vào thực tế nhé.</p><p><escape><a id="more"></a></escape></p><h2 id="Truoc-het-Kafka-la-gi"><a href="#Truoc-het-Kafka-la-gi" class="headerlink" title="Trước hết, Kafka là gì?"></a>Trước hết, Kafka là gì?</h2><p>Kafka là 1 nền tảng event streaming rất phổ biến hiện nay được phát triển bởi tổ chức Apache và là một phần mềm mã nguồn mở. Event streaming ở đây có nghĩa là việc lấy dữ liệu theo thời gian thực từ những nguồn như là cơ sở dữ liệu, cảm biến, thiết bị di động, dịch vụ đám mây và ứng dụng dưới dạng những luồng sự kiện; lưu những sự kiện này để sau đó có thể lấy lên lại và xử lý.</p><h3 id="Nghe-phuc-tap-qua-Tim-1-vi-du-cho-de-hieu-nao"><a href="#Nghe-phuc-tap-qua-Tim-1-vi-du-cho-de-hieu-nao" class="headerlink" title="Nghe phức tạp quá. Tìm 1 ví dụ cho dễ hiểu nào!"></a>Nghe phức tạp quá. Tìm 1 ví dụ cho dễ hiểu nào!</h3><p>Tưởng tượng bạn đang xem kênh Discovery trên TV của bạn. Những hình ảnh và âm thanh mà bạn thấy và nghe được đều được phát đi từ đài truyền hình của kênh này. Ở đây, đài truyền hình của kênh Discovery đóng vai trò là <strong>publisher</strong>, còn bạn - người xem là <strong>subscriber</strong> và kênh Discovery chính là <strong>topic</strong>.</p><p>Publisher có nhiệm vụ là phát đi thông tin vào 1 topic (kênh), thông tin trong trường hợp này là dữ liệu ở dạng hình ảnh và âm thanh. Subscriber có thể đăng ký để lắng nghe trên 1 topic (chọn kênh để xem) và nhận được thông tin mà publisher phát đi. Subscriber cũng có thể lắng nghe trên nhiều topic (xem nhiều kênh trên nhiều TV, nếu bạn giàu và rảnh :D).</p><p>Đối với publisher, việc ai nhận được thông tin không quan trọng, miễn là cứ có thông tin thì nó sẽ phát đi vào 1 hoặc nhiều topic cụ thể. Còn đối với subscriber, publisher nào phát không quan trọng, miễn là topic đó có thông tin thì cứ lấy ra mà xử lý.</p><h2 id="Viet-ung-dung-chat-tren-console"><a href="#Viet-ung-dung-chat-tren-console" class="headerlink" title="Viết ứng dụng chat trên console"></a>Viết ứng dụng chat trên console</h2><p>Kafka hoạt động theo cơ chế client-server, trong đó, server là 1 process chạy trên 1 máy tính và client có thể kết nối đến nó giống như cách bạn kết nối đến database, sử dụng địa chỉ IP và port cùng với username và password nếu có. Client có thể là publisher, consumer hoặc là admin.</p><p>Việc đầu tiên bạn cần phải làm đó là khởi động Kafka server trên 1 chiếc máy tính.</p><h3 id="Khoi-dong-Kafka-server"><a href="#Khoi-dong-Kafka-server" class="headerlink" title="Khởi động Kafka server"></a>Khởi động Kafka server</h3><ol><li><strong>Bước 1</strong>: Mở terminal lên vào nhập dòng lệnh sau để tải Kafka:<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">cd</span> ~/Downloads<br>wget https://downloads.apache.org/kafka/2.7.0/kafka_2.13-2.7.0.tgz<br></code></pre></td></tr></table></figure></li><li><strong>Bước 2</strong>: Giải nén file vừa tải về:<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">tar -xzf kafka_2.13-2.7.0.tgz<br><span class="hljs-built_in">cd</span> kafka_2.13-2.7.0<br></code></pre></td></tr></table></figure></li><li><strong>Bước 3</strong>: Khởi động ZooKeeper service:<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">bin/zookeeper-server-start.sh config/zookeeper.properties<br></code></pre></td></tr></table></figure></li><li><strong>Bước 4</strong>: Mở 1 terminal mới và nhập dòng lệnh sau đây để bắt đầu chạy Kafka server:<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">bin/kafka-server-start.sh config/server.properties<br></code></pre></td></tr></table></figure></li></ol><h3 id="Co-che-hoat-dong"><a href="#Co-che-hoat-dong" class="headerlink" title="Cơ chế hoạt động"></a>Cơ chế hoạt động</h3><p>Trước khi bắt tay vào viết ứng dụng này, mình sẽ nói 1 chút về cách nó hoạt động như sau:</p><ul><li>Mỗi user khi được tạo sẽ được cấp cho 1 định danh duy nhất, ở đây mình dùng tên của user cho đơn giản. Mỗi user cũng sẽ được cấp 1 topic duy nhất mang tên của chính user đó. Ví dụ: user có tên là user1 sẽ được cấp cho topic cũng tên là user1.</li><li>Mỗi user luôn subscribe vào topic của chính họ, và publish vào topic của các user khác.</li><li>Giả sử user A và user B đang chat với nhau, user A muốn gửi tin nhắn cho B thì sẽ publish nội dung tin nhắn vào topic B, sau đó user B đang subscribe trên topic của mình sẽ nhận được tin nhắn từ A, quá trình nhắn tin từ B tới A cũng diễn ra tương tụ.</li></ul><p><img src="/2021/01/01/Lam-quen-voi-Kafka-Phan-1-Chat-voi-nhau-tren-console/kafka-message.svg" alt="Minh họa cách thức giao tiếp giữa 2 user A và B"></p><h3 id="Code-nao"><a href="#Code-nao" class="headerlink" title="Code nào"></a>Code nào</h3><p>Để có thể giao tiếp được với Kafka server, bạn cần dùng thư viện kafka-python. Sử dụng pip để cài đặt thư viện này:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">pip install kafka-python<br></code></pre></td></tr></table></figure><p>Bạn có thể đọc document của thư viện này tại <a href="https://kafka-python.readthedocs.io/en/master/usage.html">đây</a>.</p><p>Trước tiên, mình thử publish vào 1 topic bằng đoạn code sau:</p><figure class="highlight python"><figcaption><span>publisher.py</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> kafka <span class="hljs-keyword">import</span> KafkaProducer<br><br>BOOTSTRAP_SERVERS = [<span class="hljs-string">&#x27;localhost:9092&#x27;</span>]<br>producer = KafkaProducer(bootstrap_servers=BOOTSTRAP_SERVERS,<br>                         value_serializer=<span class="hljs-keyword">lambda</span> value: <span class="hljs-built_in">bytes</span>(value, encoding=<span class="hljs-string">&#x27;utf-8&#x27;</span>))<br><br>username1 = <span class="hljs-built_in">input</span>(<span class="hljs-string">&#x27;What is your name? &#x27;</span>)<br>username2 = <span class="hljs-built_in">input</span>(<span class="hljs-string">&#x27;Who do want connect? &#x27;</span>)<br><br><span class="hljs-keyword">while</span> <span class="hljs-literal">True</span>:<br>    value = <span class="hljs-built_in">input</span>()<br>    producer.send(username2, value=value)<br>    producer.flush()<br></code></pre></td></tr></table></figure><p>Đoạn code này sẽ hỏi tên của bạn và tên của user mà bạn muốn nhắn tin, sau đó nó bắt đầu 1 vòng lặp forever để chờ bạn nhập tin nhắn và gửi tin nhắn đó đến topic của user kia.</p><p><code>BOOTSTRAP_SERVERS</code> chứa thông tin để kết nối đến server Kafka mà mình vừa khởi động ở trên, vì mình chạy Kafka trên máy của mình nên địa chỉ IP của server Kafka là localhost và port mặc định là 9092.</p><p>Một message trong Kafka có 2 trường: <code>key</code> và <code>value</code>. Bạn có thể truyền bất cứ dữ liệu nào vào trong 2 trường này. Ở đây mình chỉ cần gửi nội dung tin nhắn nên dùng trường <code>value</code> là đủ.</p><p>Dữ liệu trong 1 message phải có dạng <code>byte</code>. Vậy nên trước khi gửi mình phải chuyển tin nhắn từ dạng <code>string</code> sang <code>byte</code> bằng cách truyền tham số <code>value_serializer</code> cho 1 hàm lambda.</p><p>Test script này bằng lệnh trong terminal:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">python publisher.py<br></code></pre></td></tr></table></figure><p><img src="/2021/01/01/Lam-quen-voi-Kafka-Phan-1-Chat-voi-nhau-tren-console/Screenshot-2021-01-01-160825.png" alt="Chạy thử script chat.py với tên là user1 và user2"></p><p>Vì mình mới chỉ chạy ở bên phía user1 nên không có bất cứ phản hồi nào từ user2. Giờ mình sẽ viết code để user2 lắng nghe tin nhắn từ user1:</p><figure class="highlight python"><figcaption><span>subscriber.py</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> kafka <span class="hljs-keyword">import</span> KafkaConsumer<br><br>BOOTSTRAP_SERVERS = [<span class="hljs-string">&#x27;localhost:9092&#x27;</span>]<br>username2 = <span class="hljs-built_in">input</span>(<span class="hljs-string">&#x27;What is your name? &#x27;</span>)<br><br>consumer = KafkaConsumer(username2, auto_offset_reset=<span class="hljs-string">&#x27;latest&#x27;</span>,<br>                         bootstrap_servers=BOOTSTRAP_SERVERS,<br>                         value_deserializer=<span class="hljs-keyword">lambda</span> value: value.decode(<span class="hljs-string">&#x27;utf-8&#x27;</span>))<br><br><span class="hljs-keyword">for</span> msg <span class="hljs-keyword">in</span> consumer:<br>    <span class="hljs-built_in">print</span>(msg.value)<br></code></pre></td></tr></table></figure><p>Đoạn code trên khởi tạo 1 instance <code>KafkaConsumer</code> để subscribe vào topic của user2 và bắt đầu 1 vòng lặp for để lắng nghe trên topic này. Vòng lặp for này sẽ chờ message từ topic trong thời gian vô hạn và không bao giờ dừng lại trừ khi bạn dừng chương trình.</p><p>Tham số <code>value_deserializer</code> là 1 hàm được dùng khi consumer nhận được message từ topic để chuyển trường <code>value</code> của message từ dạng <code>byte</code> trở về dạng ban đầu của nó, trong trường hợp này là <code>string</code>.</p><p>Để chạy script này, mở một tab terminal mới và chạy lệnh:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">python subscriber.py<br></code></pre></td></tr></table></figure><p>Nhập tên user2 để bắt đầu lắng nghe.</p><p>Quay lại tab đang chạy publisher, thử nhập 1 message bất kỳ và quay lại tab đang chạy subscriber. Bạn sẽ thấy message mà mình vừa nhập hiện trên terminal của subscriber.</p><p><img src="/2021/01/01/Lam-quen-voi-Kafka-Phan-1-Chat-voi-nhau-tren-console/Screenshot-2021-01-01-161638.png" alt="Chạy thử script chat.py với tên là user1 và user2"></p><p>Như vậy là chúng ta đã thiết lập được giao tiếp 1 chiều giữa 2 user. Tiếp theo, mình sẽ làm cho mỗi user vừa publish vừa subscribe vào Kafka để có thể vừa gửi và nhập tin nhắn.</p><p>Như bạn thấy trong 2 đoạn code trên, cả 2 đều chứa 1 vòng lặp vô hạn. Điều này có nghĩa là khi user đang gửi tin nhắn thì không thể nhận tin nhắn và ngược lại, vì bản chất của 2 đoạn code trên là blocking - chương trình sẽ chờ trong vô hạn để hoàn thành 1 tác vụ rồi mới chuyển sang tác vụ kế tiếp.</p><p>Để giải quyết vấn đề này, mình sẽ sử dụng thread để tạo 1 thread chạy song song với thread chính. Thread chính có nhiệm vụ là gửi tin nhắn cho đối phương còn thread được tạo có nhiệm vụ nhận tin nhắn từ đối phương.</p><p>Trong Python, để làm việc với thread, mình sử dụng thư viện threading có sẵn. Cách sử dụng khá đơn giản, chỉ cần khởi tạo 1 instance <code>Thread</code> với 2 tham số: <code>target</code> là hàm sẽ chạy trong thread mới; và <code>args</code> là tham số truyền vào hàm <code>target</code>. Sau đó gọi method <code>start</code>. Ví dụ:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">thread = threading.Thread(target=foo, args=())<br>thread.start()<br></code></pre></td></tr></table></figure><p>Vậy trước khi bắt đầu vòng lặp while trong publisher, mình chỉ cần tạo 1 thread mới chạy hàm của subscriber là xong. Dưới đây là đoạn code hoàn chỉnh của chương trình:</p><figure class="highlight python"><figcaption><span>chat.py</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> threading<br><br><span class="hljs-keyword">from</span> kafka <span class="hljs-keyword">import</span> KafkaConsumer, KafkaProducer<br><br>BOOTSTRAP_SERVERS = [<span class="hljs-string">&#x27;localhost:9092&#x27;</span>]<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">subscribe</span>(<span class="hljs-params">topic</span>):<br>    consumer = KafkaConsumer(topic, auto_offset_reset=<span class="hljs-string">&#x27;latest&#x27;</span>,<br>                             bootstrap_servers=BOOTSTRAP_SERVERS,<br>                             value_deserializer=<span class="hljs-keyword">lambda</span> value: value.decode(<span class="hljs-string">&#x27;utf-8&#x27;</span>))<br>    <span class="hljs-keyword">for</span> msg <span class="hljs-keyword">in</span> consumer:<br>        <span class="hljs-built_in">print</span>(msg.value)<br><br>username1 = <span class="hljs-built_in">input</span>(<span class="hljs-string">&#x27;What is your name? &#x27;</span>)<br>username2 = <span class="hljs-built_in">input</span>(<span class="hljs-string">&#x27;Who do want connect? &#x27;</span>)<br><br>consumer_thread = threading.Thread(target=subscribe, args=(username2,))<br>consumer_thread.start()<br><br>producer = KafkaProducer(bootstrap_servers=BOOTSTRAP_SERVERS,<br>                         value_serializer=<span class="hljs-keyword">lambda</span> value: <span class="hljs-built_in">bytes</span>(value, encoding=<span class="hljs-string">&#x27;utf-8&#x27;</span>))<br><br><span class="hljs-keyword">while</span> <span class="hljs-literal">True</span>:<br>    key = username1<br>    value = <span class="hljs-built_in">input</span>()<br>    producer.send(username1, value=value)<br>    producer.flush()<br></code></pre></td></tr></table></figure><p>Bạn thử mở 2 tab terminal, cho mỗi terminal chạy script này. Tab 1 nhập lần lượt user1 và user2, tab 2 nhập ngược lại user2 và user1.</p><p>Khi bạn nhập 1 tin nhắn ở tab 1 và nhấn Enter thì tin nhắn đó sẽ được hiện trên tab 2, điều tương tự cũng diễn ra khi bạn nhập vào tab 2.</p><p>Bạn có thể xem code đầy đủ của bài viết này ở <a href="https://github.com/duydvu/kafka-tutorial">đây</a>.</p><p>Như vậy là chúng ta đã hoàn thành xong 1 ứng dụng đơn giản để chat trên console bằng Python và Kafka. Mặc dù vậy, nó vần còn thiếu nhiều tính năng quan trọng như:</p><ul><li>Chỉ cho 2 user nhắn tin với nhau trong 1 phiên riêng biệt. Hiện tại, nếu có nhiều hơn 2 user thì sẽ có trường hợp 1 user cùng nhắn tin với 2 user khác.</li><li>Chỉ cho phép user này nhắn tin với user kia khi được họ cho phép.</li></ul><p>Mình sẽ thực hiện những tính năng này trong phần 2 của series.</p><p>Happy Coding!</p>]]></content>
    
    
    
    <tags>
      
      <tag>Coding</tag>
      
      <tag>Kafka</tag>
      
      <tag>Python</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Cấu hình VS Code để lập trình trên server bằng Remote - SSH</title>
    <link href="/2020/12/26/Cau-hinh-VS-Code-de-code-tren-server/"/>
    <url>/2020/12/26/Cau-hinh-VS-Code-de-code-tren-server/</url>
    
    <content type="html"><![CDATA[<p>Trong bài viết này, mình sẽ hướng dẫn cho các bạn cách thiết lập môi trường lập trình trên server hơn thông qua extension Remote - SSH của VS Code.</p><p><escape><a id="more"></a></escape></p><p>Trước khi bắt đầu, mình sẽ trả lời cho câu hỏi:</p><h2 id="Tai-sao-phai-lap-trinh-tren-server"><a href="#Tai-sao-phai-lap-trinh-tren-server" class="headerlink" title="Tại sao phải lập trình trên server?"></a>Tại sao phải lập trình trên server?</h2><p>Đối với đa số lập trình viên, 1 chiếc laptop hoặc PC là đủ để phục vụ cho công việc của họ. Tuy nhiên, đối với Data Scientist thì đôi khi làm việc trên 1 thiết bị là chưa đủ. Bạn cần phải làm việc trên máy tính có cấu hình mạnh, bộ nhớ lớn để có thể load dữ liệu và huấn luyện mô hình, đặc biệt là các mô hình Deep Learning yêu cầu phải có 1 hoặc nhiều GPU và thời gian huấn luyện có khi lên tới hàng tuần. Những chiếc máy tính mạnh mẽ như vậy thường sẽ không vừa vặn với 1 chiếc laptop hoặc PC nên nếu làm việc trực tiếp thì sẽ khá khó khăn. Vì vậy, việc lập trình trên server sẽ giúp ích rất nhiều, ví dụ như:</p><ul><li>Bạn có thể huấn luyện mô hình mà vẫn có thể tắt laptop mang đi nơi khác.</li><li>Bạn có thể ra quán coffee với chiếc máy tính mỏng nhẹ mà vẫn làm việc được trên chiếc máy tính khủng.</li><li>Bạn có thể chia sẻ máy với đồng nghiệp để cùng tận dụng tài nguyên của máy.</li></ul><p>Hơn nữa, các dịch vụ điện toán đám mây như là AWS, GCP cung cấp dịch vụ tính toán giúp cho chúng ta có thể làm việc trên những chiếc máy tính mạnh mà không cần phải bỏ 1 số tiền lớn để mua hoặc thuê về, điều này cũng khiến cho việc lập trình trên server ngày càng trở nên phổ biến.</p><p>Có nhiều cách khác nhau để có thể lập trình được trên server, cách nhanh nhất là bật 1 trình soạn thảo văn bản như Vim hoặc Nano rồi bắt đầu code. Tuy nhiên, những trình soạn thảo này không cung cấp sẵn những tính năng hữu ích của 1 IDE như là syntax highlighting, autocompletion, debugger. Vim là 1 trình soạn thảo rất tuyệt vời vì nó cho phép gắn thêm plugin vào để thêm tính năng, nó cho phép bạn biến nó thành 1 IDE thực thụ thông qua việc cài đặt những plugin được cung cấp bởi rất nhiều lập trình viên khác. Tùy vào sở thích mà bạn có thể chọn Vim là công cụ chính cho việc lập trình trên server, mặc dù việc thao tác trên Vim khá phức tạp nhưng khi bạn đã quen với việc sử dụng nó rồi thì bạn sẽ thấy được sự mạnh mẽ và hiệu quả mà nó đem lại. Mình cũng hay sử dụng Vim cho những tác vụ edit đơn giản trên server vì nó rất nhanh và tiện lợi. Tạm gác Vim qua một bên, trong bài này mình sẽ chỉ tập trung vào cách cấu hình để bạn có thể lập trình trên server thông qua trình soạn thảo VS Code nổi tiếng của Microsoft (nếu bạn đã từng dùng Visual Studio rồi thì nên tránh nhầm lẫn nhé vì đây là 2 phần mềm khác nhau, Visual Studio là 1 IDE còn VS Code chỉ là 1 trình soạn thảo văn bản mà thôi!).</p><p>Bắt đầu nào!</p><h2 id="Cai-dat-extension-Remote-SSH"><a href="#Cai-dat-extension-Remote-SSH" class="headerlink" title="Cài đặt extension Remote - SSH"></a>Cài đặt extension Remote - SSH</h2><p>Mình giả định rằng bạn đã cài đặt sẵn VS Code trong máy rồi nên mình sẽ chỉ hướng dẫn sau khi bạn đã bật VS Code lên nhé.</p><p>Để cài đặt extension trên VS Code, bạn hãy nhấn vào biểu tượng <strong>Extensions</strong> ở thanh công cụ bên trái, sau đó, trên thanh tìm kiếm gõ cụm từ <em>“Remote - SSH”</em>.</p><p>Extension mà ta cần tìm sẽ xuất hiện trong kết quả tìm kiếm, nhấn vào đó rồi nhấn nút <strong>Install</strong> để bắt đầu quá trình cài đặt. Sau khi cài đặt xong, khởi động lại VS Code để load extension lên.</p><p><img src="/2020/12/26/Cau-hinh-VS-Code-de-code-tren-server/Screenshot-2020-12-26-120808.png" alt="Giao diện VS Code sau khi hoàn tất cài đặt Remote - SSH"></p><p>Tiếp theo, mình sẽ hướng dẫn cách cấu hình môi trường lập trình trên server.</p><h2 id="Cau-hinh-moi-truong-lap-trinh-tren-server"><a href="#Cau-hinh-moi-truong-lap-trinh-tren-server" class="headerlink" title="Cấu hình môi trường lập trình trên server"></a>Cấu hình môi trường lập trình trên server</h2><h3 id="Buoc-1-Tao-SSH-key"><a href="#Buoc-1-Tao-SSH-key" class="headerlink" title="Bước 1: Tạo SSH key"></a>Bước 1: Tạo SSH key</h3><p>Trước khi kết nối đến server thông qua VS Code, bạn cần phải tạo 1 SSH key để xác thực quyền kết nối của máy bạn với server mà không cần dùng mật khẩu.<br>Nếu bạn đã cấu hình SSH server bằng SSH key rồi thì hãy đến với <a href="#Buoc-3-Thiet-lap-moi-truong-SSH-tren-VS-Code">bước 3</a>.</p><p>Mở 1 terminal mới và nhập lệnh sau:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">ssh-keygen -t rsa -b 4096 -f ~/.ssh/id_rsa<br></code></pre></td></tr></table></figure><p>Câu lệnh trên sẽ trả về kết quả như dưới đây:</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs text">Generating public/private rsa key pair.<br>Enter passphrase (empty for no passphrase):<br></code></pre></td></tr></table></figure><p>Nhấn Enter 2 lần để hoàn tất việc tạo SSH key trên máy tính của bạn, key này được lưu tại <code>~/.ssh/id_rsa</code>.</p><h3 id="Buoc-2-Them-SSH-key-vao-danh-sach-authorized-keys-cua-server"><a href="#Buoc-2-Them-SSH-key-vao-danh-sach-authorized-keys-cua-server" class="headerlink" title="Bước 2: Thêm SSH key vào danh sách authorized keys của server"></a>Bước 2: Thêm SSH key vào danh sách authorized keys của server</h3><p>Tiếp theo, bạn cần phải SSH vào server để thêm SSH key mà bạn vừa tạo vào danh sách authorized keys của server. Bước này dùng để xác thực quyền truy cập vào server cho máy tính của bạn.</p><p>Đầu tiên, bạn cần copy public key sử dụng lệnh dưới đây:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">cat</span> ~/.ssh/id_rsa.pub<br></code></pre></td></tr></table></figure><p>Copy toàn bộ nội dung trả về của lệnh này.</p><p>Tiếp theo, kết nối SSH vào server bằng lệnh sau:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">ssh &lt;username&gt;@&lt;ip-address&gt;<br></code></pre></td></tr></table></figure><p>Thay <code>username</code> và <code>ip-address</code> thành giá trị tương ứng mà bạn có. Nhập mật khẩu để xác thực.</p><p>Sau đó, chèn nội dung của public key vào cuối file <code>~/.ssh/authorized_keys</code> bằng lệnh sau:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">echo</span> <span class="hljs-string">&quot;&lt;paste-your-public-key-content-here&gt;&quot;</span> &gt;&gt; ~/.ssh/authorized_keys<br></code></pre></td></tr></table></figure><p>Thay <code>paste-your-public-key-content-here</code> bằng nội dung của public key mà bạn vừa copy.</p><p>Như vậy là bạn đã hoàn tất việc xác thực SSH key với server, trong những lần ssh sau, bạn không cần phải cung cấp mật khẩu nữa giúp cho việc ssh vào server trở nên thuận tiện hơn.</p><p><strong>Lưu ý</strong>: Nếu ở trong bước 1, bạn sử dụng tên khác để tạo SSH key như <code>id_abc</code> thì bạn cần phải làm thêm 1 bước là thay đổi cấu hình SSH để nó biết được cần phải dùng key nào khi kết nối đến server của bạn.</p><p>Trong file <code>~/.ssh/config</code>, bạn cần thêm đoạn dưới đây vào cuối file:</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs text"># Chỉ thêm khi file key của bạn khác với mặc định (id_rsa, id_dsa, id_ecdsa, id_ed25519)<br>Host &lt;ip-address&gt;<br>  HostName &lt;ip-address&gt;<br>  User &lt;username&gt;<br>  Port 22<br>  IdentityFile ~/.ssh/id_abc<br></code></pre></td></tr></table></figure><h3 id="Buoc-3-Thiet-lap-moi-truong-SSH-tren-VS-Code"><a href="#Buoc-3-Thiet-lap-moi-truong-SSH-tren-VS-Code" class="headerlink" title="Bước 3: Thiết lập môi trường SSH trên VS Code"></a>Bước 3: Thiết lập môi trường SSH trên VS Code</h3><p>Sau khi đã có thể kết nối đến server thông qua SSH key, bạn hãy mở VS Code và làm theo các bước sau đây:</p><ol><li>Nhấn tổ hợp phím <strong>Ctrl + Shift + P</strong> để mở khung <strong>Command Palette</strong>.</li><li>Nhập <em>“Remote-SSH: Add New SSH Host”</em> rồi nhấn <strong>Enter</strong>.</li><li>Nhập câu lệnh SSH mà bạn sử dụng để SSH đến server: <code>ssh &lt;username&gt;@&lt;ip-address&gt;</code></li><li>Nhập đường dẫn đến file config: <code>~/.ssh/config</code></li></ol><p>VS Code sẽ hiện thống báo rằng server đã được thêm vào. Giờ bạn chọn biểu tượng Remote Explorer ở thanh công cụ bên trái, bạn sẽ thấy địa chỉ ip của server vừa thêm vào. Từ bây giờ, bạn có thể mở 1 folder bất kỳ trên server bằng cách nhấn nút <strong>Connect to Host in New Window</strong> ở kế bên địa chỉ ip của server.</p><p>Như vậy là bạn có thể bắt đầu lập trình trên server thông qua VS Code rồi đó.</p><p>Một lưu ý nhỏ là khi dùng VS Code trên server thì bạn cần phải cài extension <strong>trên server đó</strong> thì mới có thể dùng được, tức là nếu có extension nào bạn đã cài trên máy rồi thì vẫn phải cài lại trên server.</p><p>Happy coding!</p>]]></content>
    
    
    
    <tags>
      
      <tag>IDE</tag>
      
      <tag>Coding</tag>
      
      <tag>VScode</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Open-closed principle</title>
    <link href="/2020/08/23/Open-closed-principle/"/>
    <url>/2020/08/23/Open-closed-principle/</url>
    
    <content type="html"><![CDATA[<p>Open-closed principle là 1 trong các nguyên tắc của bộ nguyên tắc lập trình SOLID trong lập trình hướng đối tượng. Đây là 1 nguyên tắc rất quan trọng bởi nó giúp cho code của dự án dễ bảo trì và mở rộng, có thể thích ứng với những thay đổi trong môi trường Agile.</p><p>Nguyên văn phát biểu của nguyên tắc này như sau:</p><blockquote><p>“Các thực thể phần mềm (class, function,…) nên tạo điều kiện cho việc mở rộng, nhưng hạn chế cho việc thay đổi.”</p></blockquote><p><escape><a id="more"></a></escape></p><p>Có thể hiểu lợi ích của nguyên tắc này thông qua 1 ví dụ như sau, giả sử như bạn là một lập trình viên đang làm cho 1 công ty IT nọ. Bạn vào đó với vai trò phát triển phần mềm cho 1 dự án của 1 team trong công ty. Thật không may, mã nguồn của dự án đó nhiều đến nỗi bạn không kiểm soát được ảnh hưởng của những thành phần trong hệ thống đối với nhau. Nhưng công ty lại đòi hỏi bạn phải hiện thực 1 tính năng mới cho dự án trong 1 thời gian ngắn. Vậy làm cách nào bạn có thể hoàn thành công việc được giao đúng hạn? Bạn sợ rằng nếu bạn hiện thực tính năng mới theo yêu cầu nghĩa là bạn đang tạo ra 1 sự rủi ro khiển cho hệ thống không còn hoạt động giống như trước. Bạn liên tục đặt câu hỏi rằng liệu tính năng mới được thêm vào có làm phá vỡ những tính năng khác hiện có hay không. Nếu chuyện đó thật sự xảy ra thì nó không hẳn hoàn toàn là lỗi của bạn. Cái quan trọng nhất trong chuyện này là cách mà code của dự án đã được thiết kế như thế nào. Nếu code của dự án tuân theo open-closed principle thì bạn có thể hiện thực tính năng mới bằng cách viết thêm code cho dự án, tạo thêm class kế thừa từ class sẵn có trong dự án mà không cần phải thay đổi code có sẵn. Điều này giúp giảm thiểu rủi ro phá vỡ hệ thống đang hoạt động mà vẫn hoàn thành được tiến độ công việc của bạn. Trong khi đó, nếu dự án được thiết kế đi ngược lại open-closed principle thì bạn có thể phải thay đổi code của dự án. Rõ ràng là điều này tiềm ẩn nhiều rủi ro hơn và cũng khó hiện thực hơn trường hợp đầu tiên.</p><p>Như vậy, ta đã thấy được lợi ích của việc thiết kế code theo open-closed principle rồi. Vậy code như thế nào mới gọi là tuân theo nguyên tắc đó? Ta hãy tiếp tục tìm hiểu thông qua ví dụ Python dưới đây.</p><p>Mình đang làm 1 dự án xây dựng mô hình phân loại spam cho văn bản sử dụng Machine Learning. Để cho dễ hiểu, mình sẽ bỏ qua phần hiện thực của mô hình mà chỉ tập trung vào phần code để sử dụng mô hình mà thôi.</p><p>Giả sử như mình đã xây dựng xong 1 mô hình có input là 1 đoạn văn bản và output ra là 1 số hoặc 0 hoặc 1, 0 nghĩa là không phải spam còn 1 nghĩa là spam. Nhưng trước khi đưa nó vào chạy thực tế, mình cần phải đánh giá mô hình này có hoặc động tốt hay không bằng việc cho nó dự đoán 1 tập nhiều văn bản khác nhau và tính tỷ lệ phần trăm mà nó dự đoán đúng. Vậy mình sẽ hiện thực 1 hàm đánh giá mô hình như sau:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># Đây là hàm dùng để lấy output của mô hình</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">predict</span>(<span class="hljs-params">texts: <span class="hljs-type">List</span>[<span class="hljs-built_in">str</span>]</span>) -&gt; np.array:<br>    <span class="hljs-comment"># Hàm này sẽ dùng mô hình đã được huấn luyện để chạy rồi trả về kết quả của mô hình</span><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">evaluate_spam_model</span>(<span class="hljs-params">texts: <span class="hljs-type">List</span>[<span class="hljs-built_in">str</span>], truth_labels: np.array</span>) -&gt; <span class="hljs-built_in">float</span>:<br>    predicted_labels = predict(texts)<br>    num_correct_predictions = np.<span class="hljs-built_in">sum</span>(predicted_labels == truth_labels) <span class="hljs-comment"># Tính số lần mà mô hình dự đoán đúng</span><br>    num_total_predictions = <span class="hljs-built_in">len</span>(texts) <span class="hljs-comment"># Tổng số văn bản mà mô hình dự đoán.</span><br>    accuracy = num_correct_predictions / num_total_predictions <span class="hljs-comment"># Tính accuracy của mô hình</span><br>    <span class="hljs-keyword">return</span> accuracy<br></code></pre></td></tr></table></figure><p>Khi chạy hàm này, mình nhận thấy kết quả đánh giá của mô hình không đạt yêu cầu đề ra nên mình quyết định thử dùng 1 phương pháp mới để cải thiện độ chính xác của mô hình. Sau khi hiện thực lại xong, mình nhận thấy hàm <code>predict</code> không thể chạy được mô hình mới vì bạn đã dùng thư viện khác để hiện thực nó. Bạn thay đổi code của mình thành như sau:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">predict</span>(<span class="hljs-params">texts: <span class="hljs-type">List</span>[<span class="hljs-built_in">str</span>], model_name: <span class="hljs-built_in">str</span></span>) -&gt; np.array:<br>    <span class="hljs-keyword">if</span> model_name == <span class="hljs-string">&#x27;v1&#x27;</span>:<br>        <span class="hljs-comment"># Chạy mô hình đầu tiên</span><br>    <span class="hljs-keyword">elif</span> model_name == <span class="hljs-string">&#x27;v2&#x27;</span>:<br>        <span class="hljs-comment"># Chạy mô hình thứ hai</span><br>    <span class="hljs-keyword">else</span>:<br>        <span class="hljs-keyword">raise</span> Exception(<span class="hljs-string">&#x27;No such model.&#x27;</span>)<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">evaluate_spam_model</span>(<span class="hljs-params">texts: <span class="hljs-type">List</span>[<span class="hljs-built_in">str</span>], truth_labels: np.array, model_name: <span class="hljs-built_in">str</span></span>) -&gt; <span class="hljs-built_in">float</span>:<br>    predicted_labels = predict(texts, model_name)<br>    num_correct_predictions = np.<span class="hljs-built_in">sum</span>(predicted_labels == truth_labels) <span class="hljs-comment"># Tính số lần mà mô hình dự đoán đúng</span><br>    num_total_predictions = <span class="hljs-built_in">len</span>(texts) <span class="hljs-comment"># Tổng số văn bản mà mô hình dự đoán.</span><br>    accuracy = num_correct_predictions / num_total_predictions <span class="hljs-comment"># Tính accuracy của mô hình</span><br>    <span class="hljs-keyword">return</span> accuracy<br></code></pre></td></tr></table></figure><p>Ở đây ta có 2 vấn đề:</p><ol><li>Việc thêm code vào hàm <code>predict</code> làm tăng rủi ro sinh ra bug cho hàm này. Nếu như mình chỉ có 2 hoặc 3 mô hình thì không thành vấn đề. Nhưng giả sử khi mình có tới hàng chục mô hình khác nhau thì đồng nghĩa với việc hàm này sẽ vô cùng dài và khó đọc. Khi đó thì việc kiểm tra lỗi sẽ trở nên khó khăn hơn.</li><li>Việc thay đổi signature của hàm <code>predict</code> khiến cho những hàm sử dụng nó cũng thay đổi theo. Trong trường hợp này thì chỉ có 1 mình hàm <code>evaluate_spam_model</code> là phải thay đổi. Nhưng nếu như mình có hàm khác sử dụng hàm <code>evaluate_spam_model</code> thì sao? Ví dụ như hàm <code>report_spam_performance</code> sử dụng hàm <code>evaluate_spam_model</code> để chạy ra kết quả và output ra 1 report để mình xem. Như vậy, việc thay đổi signature của 1 hàm có thể dẫn đến việc thay đổi signature của toàn bộ hàm trực tiếp hoặc gián tiếp sử dụng nó.</li></ol><p>Rõ ràng là đoạn code trên không tuân theo open-closed principle. Vậy code tuân theo nguyên tắc này sẽ trông như thế nào? Hãy xem đoạn code dưới đây:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">SpamStrategy</span>(<span class="hljs-title class_ inherited__">ABC</span>): <span class="hljs-comment"># Khai báo class kế thừa Abstract Base Classes. Link: https://docs.python.org/3/library/abc.html#abc.ABC</span><br><span class="hljs-meta">    @abstractmethod</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">predict</span>(<span class="hljs-params">self, texts: <span class="hljs-type">List</span>[<span class="hljs-built_in">str</span>]</span>) -&gt; np.array:<br>        <span class="hljs-keyword">pass</span><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">SpamV1Strategy</span>(<span class="hljs-title class_ inherited__">SpamStrategy</span>):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">predict</span>(<span class="hljs-params">self, text: <span class="hljs-type">List</span>[<span class="hljs-built_in">str</span>]</span>) -&gt; np.array:<br>        <span class="hljs-comment"># Chạy mô hình thứ nhất</span><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">SpamV2Strategy</span>(<span class="hljs-title class_ inherited__">SpamStrategy</span>):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">predict</span>(<span class="hljs-params">self, text: <span class="hljs-type">List</span>[<span class="hljs-built_in">str</span>]</span>) -&gt; np.array:<br>        <span class="hljs-comment"># Chạy mô hình thứ hai</span><br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">evaluate_spam_model</span>(<span class="hljs-params">texts: <span class="hljs-type">List</span>[<span class="hljs-built_in">str</span>], truth_labels: np.array, strategy: SpamStrategy</span>):<br>    predicted_labels = strategy.predict(texts, model_name)<br>    num_correct_predictions = np.<span class="hljs-built_in">sum</span>(predicted_labels == truth_labels) <span class="hljs-comment"># Tính số lần mà mô hình dự đoán đúng</span><br>    num_total_predictions = <span class="hljs-built_in">len</span>(texts) <span class="hljs-comment"># Tổng số văn bản mà mô hình dự đoán.</span><br>    accuracy = num_correct_predictions / num_total_predictions <span class="hljs-comment"># Tính accuracy của mô hình</span><br>    <span class="hljs-keyword">return</span> accuracy<br></code></pre></td></tr></table></figure><p>Ở đây, mình khai báo 1 abstract class <code>SpamStrategy</code> có khai báo 1 hàm abstract là <code>predict</code>. Mỗi lần hiện thực 1 mô hình spam mới thì mình sẽ tạo thêm 1 class mới kế thừa từ class này rồi chạy hàm <code>evaluate_spam_model</code> bằng việc thay đổi tham số strategy. Như vậy, mỗi lần mình hiện thực thêm 1 mô hình mới thì đoạn code của những mô hình cũ (những class kế thừa từ <code>SpamStrategy</code>) không bị thay đổi. Nếu như mình nhận thấy mô hình mới không được tốt như mô hình cũ thì mình vẫn có thể dễ dàng chạy lại mô hình cũ chỉ bằng việc thay đổi tham số của hàm <code>evaluate_spam_model</code> mà thôi!</p><p>Thông qua ví dụ trên, chúng ta thấy được tầm quan trọng của việc thiết kế code theo open-closed principle. Đối với những dự án nhỏ, nguyên tắc này đôi khi là không cần thiết bởi nó khiến cho code trở nên dài dòng hơn. Nhưng khi dự án phình to ra với vô số hàm và class được thêm vào thì ta mới thấy rõ được tầm quan trọng của nguyên tác này.</p>]]></content>
    
    
    
    <tags>
      
      <tag>Python</tag>
      
      <tag>OOP</tag>
      
      <tag>Software Engineering</tag>
      
      <tag>SOLID</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Sự đối lập giữa Object và Data Structure</title>
    <link href="/2020/08/09/su-doi-lap-giua-object-va-data-structure/"/>
    <url>/2020/08/09/su-doi-lap-giua-object-va-data-structure/</url>
    
    <content type="html"><![CDATA[<p>Bài viết này là kiến thức mình học được khi đọc cuốn <em>Clean Code: A Handbook of Agile Software Craftsmanship</em>, mình muốn thông qua bài viết này có thể chia sẻ hiểu biết của mình với mọi người cũng như tự giúp bản thân nắm vững hơn những gì đã đọc được.</p><p>Trong lập trình hướng đối tượng, 2 khái niệm object và data structure có sự đối lập nhau rõ ràng mặc dù nghe thì chúng có vẻ hơi hơi giống nhau. Trong bài viết này, mình sẽ tìm hiểu và phân tích sự đối lập này thông qua 1 ví dụ thực tế.</p><p><escape><a id="more"></a></escape></p><h2 id="Su-khac-nhau-giua-Object-va-Data-Structure"><a href="#Su-khac-nhau-giua-Object-va-Data-Structure" class="headerlink" title="Sự khác nhau giữa Object và Data Structure"></a>Sự khác nhau giữa Object và Data Structure</h2><p>Object đóng gói toàn bộ dữ liệu của nó bên trong 1 class và chỉ cung cấp ra bên ngoài một hoặc nhiều hàm để người dùng gọi. Như vậy, chỉ có các hàm bên trong 1 class mới có thể quản lý dữ liệu của class đó. Ngược lại, data structure để phơi bày dữ liệu của nó và không có bất kỳ hàm nào có ý nghĩa.</p><p>Ta có thể thấy trong đoạn văn trên, object và data structure hoàn toàn đối lập nhau. Một bên thì giấu dữ liệu và phơi bày hàm, còn một bên thì phơi bày dữ liệu và không có hàm (coi như giấu).</p><h2 id="Vi-du"><a href="#Vi-du" class="headerlink" title="Ví dụ"></a>Ví dụ</h2><p>Mình hãy cùng xem xét 1 ví dụ như sau:<br>Dưới đây là 1 đoạn code viết theo hướng data structure. Mỗi shape chỉ đơn giản là 1 tập các thuộc tính riêng biệt của mỗi dạng hình học. Class Geometry có nhiệm vụ tính toán các giá trị chẳng hạn như diện tích dựa trên 3 shape này.</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">Square</span> &#123;<br>    <span class="hljs-keyword">public</span> Point topLeft;<br>    <span class="hljs-keyword">public</span> <span class="hljs-type">double</span> side;<br>&#125;<br><br><span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">Rectangle</span> &#123;<br>    <span class="hljs-keyword">public</span> Point topLeft;<br>    <span class="hljs-keyword">public</span> <span class="hljs-type">double</span> height;<br>    <span class="hljs-keyword">public</span> <span class="hljs-type">double</span> width;<br>&#125;<br><br><span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">Circle</span> &#123;<br>    <span class="hljs-keyword">public</span> Point center;<br>    <span class="hljs-keyword">public</span> <span class="hljs-type">double</span> radius;<br>&#125;<br><br><span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">Geometry</span> &#123;<br>    <span class="hljs-keyword">public</span> <span class="hljs-type">double</span> <span class="hljs-title function_">area</span><span class="hljs-params">(Object shape)</span> <span class="hljs-keyword">throws</span> NoSuchShapeException &#123;<br>        <span class="hljs-keyword">if</span> (shape <span class="hljs-keyword">instanceof</span> Square) &#123;<br>            <span class="hljs-type">Square</span> <span class="hljs-variable">s</span> <span class="hljs-operator">=</span> (Square)shape;<br>            <span class="hljs-keyword">return</span> s.side * s.side;<br>        &#125;<br>        <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> (shape <span class="hljs-keyword">instanceof</span> Rectangle) &#123;<br>            <span class="hljs-type">Rectangle</span> <span class="hljs-variable">r</span> <span class="hljs-operator">=</span> (Rectangle)shape;<br>            <span class="hljs-keyword">return</span> r.height * r.width;<br>        &#125;<br>        <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> (shape <span class="hljs-keyword">instanceof</span> Circle) &#123;<br>            <span class="hljs-type">Circle</span> <span class="hljs-variable">c</span> <span class="hljs-operator">=</span> (Circle)shape;<br>            <span class="hljs-keyword">return</span> Math.PI * c.radius * c.radius;<br>        &#125;<br>        <span class="hljs-keyword">throw</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">NoSuchShapeException</span>();<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>Còn dưới đây là 1 đoạn code được viết theo hướng OOP, mỗi shape bắt buộc phải thừa kế từ class Shape và tự hiện thực các hàm của Shape.</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">Square</span> <span class="hljs-keyword">implements</span> <span class="hljs-title class_">Shape</span> &#123;<br>    <span class="hljs-keyword">private</span> Point topLeft;<br>    <span class="hljs-keyword">private</span> <span class="hljs-type">double</span> side;<br><br>    <span class="hljs-keyword">public</span> <span class="hljs-type">double</span> <span class="hljs-title function_">area</span><span class="hljs-params">()</span> &#123;<br>        <span class="hljs-keyword">return</span> side * side;<br>    &#125;<br>&#125;<br><br><span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">Rectangle</span> <span class="hljs-keyword">implements</span> <span class="hljs-title class_">Shape</span> &#123;<br>    <span class="hljs-keyword">private</span> Point topLeft;<br>    <span class="hljs-keyword">private</span> <span class="hljs-type">double</span> height;<br>    <span class="hljs-keyword">private</span> <span class="hljs-type">double</span> width;<br><br>    <span class="hljs-keyword">public</span> <span class="hljs-type">double</span> <span class="hljs-title function_">area</span><span class="hljs-params">()</span> &#123;<br>        <span class="hljs-keyword">return</span> height * width;<br>    &#125;<br>&#125;<br><br><span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">Circle</span> <span class="hljs-keyword">implements</span> <span class="hljs-title class_">Shape</span> &#123;<br>    <span class="hljs-keyword">private</span> Point center;<br>    <span class="hljs-keyword">private</span> <span class="hljs-type">double</span> radius;<br><br>    <span class="hljs-keyword">public</span> <span class="hljs-type">double</span> <span class="hljs-title function_">area</span><span class="hljs-params">()</span> &#123;<br>        <span class="hljs-keyword">return</span> Math.PI * radius * radius;<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>Giả sử như chúng ta muốn thêm 1 shape mới vào code (Triangle chẳng hạn), đối với đoạn code đầu tiên (code theo data structure) thì ta cần khai báo thêm 1 data structure mới tên là Triangle và thay đổi toàn bộ hàm có trong class Geometry (trong trường hợp này chỉ có 1 hàm area). Tuy nhiên, trong 1 trường hợp khác, khi ta chỉ muốn thêm 1 hàm mới để tính chu vi của shape, ta chỉ cần khai báo 1 hàm tên là perimeter trong class Geometry và mọi thay đổi chỉ gói gọn trong hàm này mà thôi.<br>Bây giờ mình sẽ dùng đoạn code thứ hai (sử dụng OOP) để áp dụng vào trường hợp trên. Việc thêm 1 shape mới trở nên dễ dàng hơn rất nhiều so với sử dụng data structure, chỉ cần tạo 1 class mới tên là Triangle và hiện thực các hàm cần thiết của class Shape mà không làm ảnh hưởng đến các Shape còn lại. Trong khi đó, nếu thêm hàm perimeter vào class Shape thì đòi hỏi ta phải thay đổi toàn bộ code của mọi class thừa kế từ Shape.</p><p>Như vậy có thể thấy rằng:<br><strong>Đối với lập trình sử dụng data structure, việc thêm 1 hàm mới trở nên dễ dàng mà không cần thay đổi code trong những data structure khác nhưng lại khó để thêm 1 data structure mới vì phải thay đổi toàn bộ hàm có sẵn. Ở chiều ngược lại, lập trình theo hướng đối tượng khiến cho việc thêm 1 class mới dễ dàng mà không cần thay đổi những class khác nhưng lại khó để thêm 1 hàm mới vì toàn bộ class khác phải thay đổi theo.</strong></p>]]></content>
    
    
    
    <tags>
      
      <tag>OOP</tag>
      
      <tag>Software Engineering</tag>
      
      <tag>Data structure</tag>
      
      <tag>Java</tag>
      
    </tags>
    
  </entry>
  
  
  
  
</search>
